{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46cc13998cd04a59bf1dc98531cfbdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af0ce93ebbaa4a1abe2e78e8f064eb55",
              "IPY_MODEL_0b77ce1a11534bbb9f9017757bb0ec53",
              "IPY_MODEL_dbf091c56f1c498a883deae30cebf0cc"
            ],
            "layout": "IPY_MODEL_bb82a14e732b42089d060fde192ae739"
          }
        },
        "af0ce93ebbaa4a1abe2e78e8f064eb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896d2d88e59c4c44a671ec4417fe808e",
            "placeholder": "​",
            "style": "IPY_MODEL_a049090537764c5292be3c588d16715e",
            "value": "open_clip_pytorch_model.bin: 100%"
          }
        },
        "0b77ce1a11534bbb9f9017757bb0ec53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2294cff47c2c42a999193a701ed7912d",
            "max": 783705670,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdcc8a56e0dd4d108a6136d5bf8264c4",
            "value": 783705670
          }
        },
        "dbf091c56f1c498a883deae30cebf0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a108a031d26b428fb1fa6b9d78060e6a",
            "placeholder": "​",
            "style": "IPY_MODEL_a21aee2204c7401ebff03685f20e286a",
            "value": " 784M/784M [00:03&lt;00:00, 215MB/s]"
          }
        },
        "bb82a14e732b42089d060fde192ae739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896d2d88e59c4c44a671ec4417fe808e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a049090537764c5292be3c588d16715e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2294cff47c2c42a999193a701ed7912d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcc8a56e0dd4d108a6136d5bf8264c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a108a031d26b428fb1fa6b9d78060e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a21aee2204c7401ebff03685f20e286a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "456d9dc5c6684ac596eb6d8756b81311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc1e4d6113864cef88503d27bd57f679",
              "IPY_MODEL_58136452b8bd48b1b119e9a7dd0f4573",
              "IPY_MODEL_659179e62aed43deb8ce6e277d2eb2b9"
            ],
            "layout": "IPY_MODEL_fd306396042c48ba9ef5da09dae8cb0e"
          }
        },
        "bc1e4d6113864cef88503d27bd57f679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90bdf261d7ad4408b8053817f6fb2227",
            "placeholder": "​",
            "style": "IPY_MODEL_8bbcec3a0ff544f691920abb8d743f2f",
            "value": "open_clip_config.json: 100%"
          }
        },
        "58136452b8bd48b1b119e9a7dd0f4573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a94c26655f61422b9a6486e494dea718",
            "max": 707,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d91d2d449e84b03a6b137d64e1a1aed",
            "value": 707
          }
        },
        "659179e62aed43deb8ce6e277d2eb2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40210429a7764139b1a9324246144784",
            "placeholder": "​",
            "style": "IPY_MODEL_c7251fa644964113aad9e3ccdcc8b3d4",
            "value": " 707/707 [00:00&lt;00:00, 69.0kB/s]"
          }
        },
        "fd306396042c48ba9ef5da09dae8cb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90bdf261d7ad4408b8053817f6fb2227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbcec3a0ff544f691920abb8d743f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a94c26655f61422b9a6486e494dea718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d91d2d449e84b03a6b137d64e1a1aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40210429a7764139b1a9324246144784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7251fa644964113aad9e3ccdcc8b3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4e3dcc47f446f7a4572ac507fa3c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_766d9d72c04d4fb985a0a145b47b6d40",
              "IPY_MODEL_367d1d25c51c45939ab663bf828e383c",
              "IPY_MODEL_b2e337c82b6a472ba130532a0f259bcd"
            ],
            "layout": "IPY_MODEL_6ce62fff225b46f3a6eb9987a4b45910"
          }
        },
        "766d9d72c04d4fb985a0a145b47b6d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80be703ba44f43e38cb781c5b16218fb",
            "placeholder": "​",
            "style": "IPY_MODEL_7df6b8ad9ef94db9833dca1074f65ef1",
            "value": "config.json: 100%"
          }
        },
        "367d1d25c51c45939ab663bf828e383c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b59e653012747d59f5b3728ff77f827",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d18198811d44c639192910e129eeea3",
            "value": 385
          }
        },
        "b2e337c82b6a472ba130532a0f259bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97cb66231904705b3d710d99dee6fc0",
            "placeholder": "​",
            "style": "IPY_MODEL_a84d5a2bb8ad4d4289d8949279676fca",
            "value": " 385/385 [00:00&lt;00:00, 36.1kB/s]"
          }
        },
        "6ce62fff225b46f3a6eb9987a4b45910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80be703ba44f43e38cb781c5b16218fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df6b8ad9ef94db9833dca1074f65ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b59e653012747d59f5b3728ff77f827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d18198811d44c639192910e129eeea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d97cb66231904705b3d710d99dee6fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84d5a2bb8ad4d4289d8949279676fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alim98/MPI/blob/main/Final_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!wget -O downloaded_file.zip \"https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "\n",
        "# !pip -q install transformers scikit-learn matplotlib seaborn torch torchvision umap-learn openpyxl imageio\n",
        "\n",
        "\n",
        "!wget -O vesicle_cloud__syn_interface__mitochondria_annotation.zip \"https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "\n",
        "!unzip -q downloaded_file.zip\n",
        "!unzip -q vesicle_cloud__syn_interface__mitochondria_annotation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zDpMkf8ni_4",
        "outputId": "a4043b25-2572-4ff1-cf82-6c4a8b13f5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 12:42:02--  https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.118.132, 2404:6800:4003:c05::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.118.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1264688649 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘downloaded_file.zip’\n",
            "\n",
            "downloaded_file.zip 100%[===================>]   1.18G  56.3MB/s    in 21s     \n",
            "\n",
            "2025-01-17 12:42:25 (58.1 MB/s) - ‘downloaded_file.zip’ saved [1264688649/1264688649]\n",
            "\n",
            "--2025-01-17 12:42:25--  https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.118.132, 2404:6800:4003:c05::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.118.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14246564 (14M) [application/octet-stream]\n",
            "Saving to: ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’\n",
            "\n",
            "vesicle_cloud__syn_ 100%[===================>]  13.59M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-01-17 12:42:56 (120 MB/s) - ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’ saved [14246564/14246564]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCoK5WpnmvlN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import io\n",
        "import argparse\n",
        "import multiprocessing\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio.v3 as iio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "\n",
        "# import wandb  # Uncomment if using Weights & Biases for logging\n",
        "\n",
        "\n",
        "class SimpleVideoProcessor:\n",
        "    def __init__(self, size=(224, 224), mean=(0.485, 0.456, 0.406),\n",
        "                 std=(0.229, 0.224, 0.225)):\n",
        "        \"\"\"\n",
        "        Initializes the processor with resizing and normalization transforms.\n",
        "\n",
        "        Args:\n",
        "            size (tuple): Desired output size (height, width).\n",
        "            mean (tuple): Mean for normalization.\n",
        "            std (tuple): Standard deviation for normalization.\n",
        "        \"\"\"\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),          # Convert NumPy array to PIL Image\n",
        "            transforms.Resize(size),          # Resize to desired size\n",
        "            transforms.ToTensor(),            # Convert PIL Image to Tensor\n",
        "            transforms.Normalize(mean=mean, std=std),  # Normalize\n",
        "        ])\n",
        "\n",
        "    def __call__(self, frames, return_tensors=None):\n",
        "        \"\"\"\n",
        "        Processes a list of frames.\n",
        "\n",
        "        Args:\n",
        "            frames (List[np.ndarray]): List of frames as NumPy arrays.\n",
        "            return_tensors (str, optional): Type of tensors to return. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            dict or torch.Tensor: Dictionary containing processed pixel values or tensor.\n",
        "        \"\"\"\n",
        "        # Apply transformations to each frame\n",
        "        processed_frames = [self.transform(frame) for frame in frames]\n",
        "\n",
        "        # Stack frames to create a tensor of shape (num_frames, 3, H, W)\n",
        "        pixel_values = torch.stack(processed_frames)\n",
        "\n",
        "        if return_tensors == \"pt\":\n",
        "            return {\"pixel_values\": pixel_values}\n",
        "        else:\n",
        "            return pixel_values\n",
        "\n",
        "\n",
        "def load_volumes(bbox_name: str, raw_base_dir: str, seg_base_dir: str, add_mask_base_dir: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Load raw volume, segmentation volume, and additional mask volume for a bounding box.\n",
        "\n",
        "    Args:\n",
        "        bbox_name (str): Name of the bounding box directory (e.g., 'bbox1').\n",
        "        raw_base_dir (str): Base directory for raw data.\n",
        "        seg_base_dir (str): Base directory for segmentation data.\n",
        "        add_mask_base_dir (str): Base directory for additional masks.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (raw_vol, seg_vol, add_mask_vol) each as np.ndarray\n",
        "    \"\"\"\n",
        "    raw_dir = os.path.join(raw_base_dir, bbox_name)\n",
        "    seg_dir = os.path.join(seg_base_dir, bbox_name)\n",
        "\n",
        "    # Transform 'bbox1' to 'bbox_1' for additional masks\n",
        "    if bbox_name.startswith(\"bbox\"):\n",
        "        bbox_num = bbox_name.replace(\"bbox\", \"\")\n",
        "        add_mask_dir = os.path.join(add_mask_base_dir, f\"bbox_{bbox_num}\")\n",
        "    else:\n",
        "        add_mask_dir = os.path.join(add_mask_base_dir, bbox_name)\n",
        "\n",
        "    raw_tif_files = sorted(glob.glob(os.path.join(raw_dir, 'slice_*.tif')))\n",
        "    seg_tif_files = sorted(glob.glob(os.path.join(seg_dir, 'slice_*.tif')))\n",
        "    add_mask_tif_files = sorted(glob.glob(os.path.join(add_mask_dir, 'slice_*.tif')))\n",
        "\n",
        "    if len(raw_tif_files) == 0:\n",
        "        print(f\"No raw files found for {bbox_name} in {raw_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    if len(seg_tif_files) == 0:\n",
        "        print(f\"No segmentation files found for {bbox_name} in {seg_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    if len(add_mask_tif_files) == 0:\n",
        "        print(f\"No additional mask files found for {bbox_name} in {add_mask_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    if not (len(raw_tif_files) == len(seg_tif_files) == len(add_mask_tif_files)):\n",
        "        print(f\"Mismatch in number of raw, seg, and additional mask slices for {bbox_name}. Skipping.\")\n",
        "        return None, None, None\n",
        "\n",
        "    try:\n",
        "        raw_vol = np.stack([iio.imread(f) for f in raw_tif_files], axis=0)  # shape: (Z, Y, X)\n",
        "        seg_vol = np.stack([iio.imread(f).astype(np.uint32) for f in seg_tif_files], axis=0)\n",
        "        add_mask_vol = np.stack([iio.imread(f).astype(np.uint32) for f in add_mask_tif_files], axis=0)\n",
        "        return raw_vol, seg_vol, add_mask_vol\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading volumes for {bbox_name}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def create_segmented_cube(\n",
        "    raw_vol: np.ndarray,\n",
        "    seg_vol: np.ndarray,\n",
        "    add_mask_vol: np.ndarray,\n",
        "    central_coord: Tuple[int, int, int],\n",
        "    side1_coord: Tuple[int, int, int],\n",
        "    side2_coord: Tuple[int, int, int],\n",
        "    segmentation_type: int,\n",
        "    subvolume_size: int = 80,\n",
        "    alpha: float = 0.3\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Constructs an 80x80x80 segmented 3D cube around the specified synapse coordinates\n",
        "    and overlays selected segmentation masks on the raw data with specified transparency for each slice.\n",
        "\n",
        "    Args:\n",
        "        raw_vol (np.ndarray): Raw volumetric data.\n",
        "        seg_vol (np.ndarray): Segmentation volumetric data.\n",
        "        add_mask_vol (np.ndarray): Additional mask volumetric data.\n",
        "        central_coord (tuple): Central coordinate (x, y, z).\n",
        "        side1_coord (tuple): Side 1 coordinate (x, y, z).\n",
        "        side2_coord (tuple): Side 2 coordinate (x, y, z).\n",
        "        segmentation_type (int): Type of segmentation overlay (0-5).\n",
        "        subvolume_size (int, optional): Size of the subvolume. Defaults to 80.\n",
        "        alpha (float, optional): Transparency factor. Defaults to 0.3.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Overlaid cube of shape (height, width, 3, depth).\n",
        "    \"\"\"\n",
        "\n",
        "    def create_segment_masks(segmentation_volume, s1_coord, s2_coord):\n",
        "        x1, y1, z1 = s1_coord\n",
        "        x2, y2, z2 = s2_coord\n",
        "        # Validate within volume\n",
        "        if not (0 <= z1 < segmentation_volume.shape[0] and\n",
        "                0 <= y1 < segmentation_volume.shape[1] and\n",
        "                0 <= x1 < segmentation_volume.shape[2]):\n",
        "            raise ValueError(\"Side1 coordinates are out of bounds.\")\n",
        "\n",
        "        if not (0 <= z2 < segmentation_volume.shape[0] and\n",
        "                0 <= y2 < segmentation_volume.shape[1] and\n",
        "                0 <= x2 < segmentation_volume.shape[2]):\n",
        "            raise ValueError(\"Side2 coordinates are out of bounds.\")\n",
        "\n",
        "        seg_id_1 = segmentation_volume[z1, y1, x1]\n",
        "        seg_id_2 = segmentation_volume[z2, y2, x2]\n",
        "\n",
        "        # If seg_id == 0, it means no segment at that voxel\n",
        "        if seg_id_1 == 0:\n",
        "            mask_1 = np.zeros_like(segmentation_volume, dtype=bool)\n",
        "        else:\n",
        "            mask_1 = (segmentation_volume == seg_id_1)\n",
        "\n",
        "        if seg_id_2 == 0:\n",
        "            mask_2 = np.zeros_like(segmentation_volume, dtype=bool)\n",
        "        else:\n",
        "            mask_2 = (segmentation_volume == seg_id_2)\n",
        "\n",
        "        return mask_1, mask_2\n",
        "\n",
        "    # Build masks\n",
        "    mask_1_full, mask_2_full = create_segment_masks(seg_vol, side1_coord, side2_coord)\n",
        "    mask_3_full = (add_mask_vol > 0)  # Assuming binary masks; adjust if necessary\n",
        "\n",
        "    # Define subvolume bounds\n",
        "    half_size = subvolume_size // 2\n",
        "    cx, cy, cz = central_coord\n",
        "\n",
        "    x_start, x_end = max(cx - half_size, 0), min(cx + half_size, raw_vol.shape[2])\n",
        "    y_start, y_end = max(cy - half_size, 0), min(cy + half_size, raw_vol.shape[1])\n",
        "    z_start, z_end = max(cz - half_size, 0), min(cz + half_size, raw_vol.shape[0])\n",
        "\n",
        "    # Extract subvolumes\n",
        "    sub_raw = raw_vol[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_mask_1 = mask_1_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_mask_2 = mask_2_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_mask_3 = mask_3_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "\n",
        "    # Pad if smaller than subvolume_size\n",
        "    pad_z = subvolume_size - sub_raw.shape[0]\n",
        "    pad_y = subvolume_size - sub_raw.shape[1]\n",
        "    pad_x = subvolume_size - sub_raw.shape[2]\n",
        "\n",
        "    if pad_z > 0 or pad_y > 0 or pad_x > 0:\n",
        "        sub_raw = np.pad(sub_raw, ((0, pad_z), (0, pad_y), (0, pad_x)),\n",
        "                         mode='constant', constant_values=0)\n",
        "        sub_mask_1 = np.pad(sub_mask_1, ((0, pad_z), (0, pad_y), (0, pad_x)),\n",
        "                            mode='constant', constant_values=False)\n",
        "        sub_mask_2 = np.pad(sub_mask_2, ((0, pad_z), (0, pad_y), (0, pad_x)),\n",
        "                            mode='constant', constant_values=False)\n",
        "        sub_mask_3 = np.pad(sub_mask_3, ((0, pad_z), (0, pad_y), (0, pad_x)),\n",
        "                            mode='constant', constant_values=False)\n",
        "\n",
        "    # Slice to exact shape\n",
        "    sub_raw = sub_raw[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_mask_1 = sub_mask_1[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_mask_2 = sub_mask_2[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_mask_3 = sub_mask_3[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "\n",
        "    # We'll build an overlaid cube: shape => (H, W, 3, D)\n",
        "    overlaid_cube = np.zeros((subvolume_size, subvolume_size, 3, subvolume_size), dtype=np.uint8)\n",
        "\n",
        "    # Define colors\n",
        "    side1_color = np.array([1, 0, 0], dtype=np.float32)           # Red\n",
        "    side2_color = np.array([0, 0, 1], dtype=np.float32)           # Blue\n",
        "    vesicles_color = np.array([0, 1, 0], dtype=np.float32)        # Green\n",
        "\n",
        "    for z in range(subvolume_size):\n",
        "        # Normalize raw slice to [0, 1]\n",
        "        raw_slice = sub_raw[z].astype(np.float32)\n",
        "        mn, mx = raw_slice.min(), raw_slice.max()\n",
        "        if mx > mn:\n",
        "            raw_slice = (raw_slice - mn) / (mx - mn)\n",
        "        else:\n",
        "            raw_slice = raw_slice - mn  # all zeros if mn=mx\n",
        "\n",
        "        raw_rgb = np.stack([raw_slice]*3, axis=-1)  # shape (H, W, 3)\n",
        "\n",
        "        # Initialize colored masks\n",
        "        mask1_rgb = np.zeros_like(raw_rgb)\n",
        "        mask2_rgb = np.zeros_like(raw_rgb)\n",
        "        mask3_rgb = np.zeros_like(raw_rgb)\n",
        "\n",
        "        # Overlay masks based on segmentation_type\n",
        "        if segmentation_type in [1, 3, 5]:\n",
        "            mask1_rgb[sub_mask_1[z]] = side1_color\n",
        "        if segmentation_type in [2, 3, 5]:\n",
        "            mask2_rgb[sub_mask_2[z]] = side2_color\n",
        "        if segmentation_type in [4, 5]:\n",
        "            mask3_rgb[sub_mask_3[z]] = vesicles_color\n",
        "\n",
        "        # Combine masks\n",
        "        combined_masks = mask1_rgb + mask2_rgb + mask3_rgb\n",
        "        # Ensure that combined masks do not exceed 1\n",
        "        combined_masks = np.clip(combined_masks, 0, 1)\n",
        "\n",
        "        # Blend raw image with masks\n",
        "        overlaid_image = (1 - alpha) * raw_rgb + alpha * combined_masks\n",
        "        overlaid_image = np.clip(overlaid_image, 0, 1)\n",
        "\n",
        "        # Convert to uint8\n",
        "        overlaid_image = (overlaid_image * 255).astype(np.uint8)\n",
        "        overlaid_cube[:, :, :, z] = overlaid_image\n",
        "\n",
        "    return overlaid_cube\n",
        "\n",
        "class VideoMAEDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class that uses segmented volumes (side1 & side2) and additional masks for VideoMAE pre-training.\n",
        "    \"\"\"\n",
        "    def __init__(self, vol_data_list: List[Tuple[np.ndarray, np.ndarray, np.ndarray]],\n",
        "                 synapse_df: pd.DataFrame,\n",
        "                 processor,\n",
        "                 segmentation_type: int,\n",
        "                 subvol_size: int = 80,\n",
        "                 num_frames: int = 16,\n",
        "                 alpha: float = 0.3):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vol_data_list (List[Tuple[np.ndarray, np.ndarray, np.ndarray]]): List of (raw_vol, seg_vol, add_mask_vol).\n",
        "            synapse_df (pd.DataFrame): DataFrame with synapse coordinates (central, side1, side2).\n",
        "            processor: Processor for VideoMAE.\n",
        "            segmentation_type (int): Type of segmentation overlay (0-5).\n",
        "            subvol_size (int): Size of the sub-volume to extract.\n",
        "            num_frames (int): Number of frames for the model.\n",
        "            alpha (float): Blending alpha for segmentation.\n",
        "        \"\"\"\n",
        "        self.vol_data_list = vol_data_list\n",
        "        self.synapse_df = synapse_df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.segmentation_type = segmentation_type\n",
        "        self.subvol_size = subvol_size\n",
        "        self.num_frames = num_frames\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.synapse_df)\n",
        "class VideoMAEDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class that uses segmented volumes (side1 & side2) and additional masks for VideoMAE pre-training.\n",
        "    \"\"\"\n",
        "    def __init__(self, vol_data_dict: dict,\n",
        "                 synapse_df: pd.DataFrame,\n",
        "                 processor,\n",
        "                 segmentation_type: int,\n",
        "                 subvol_size: int = 80,\n",
        "                 num_frames: int = 16,\n",
        "                 alpha: float = 0.3):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vol_data_dict (dict): Dictionary with keys as bbox_name and values as tuples (raw_vol, seg_vol, add_mask_vol).\n",
        "            synapse_df (pd.DataFrame): DataFrame with synapse coordinates (central, side1, side2).\n",
        "            processor: Processor for VideoMAE.\n",
        "            segmentation_type (int): Type of segmentation overlay (0-5).\n",
        "            subvol_size (int): Size of the sub-volume to extract.\n",
        "            num_frames (int): Number of frames for the model.\n",
        "            alpha (float): Blending alpha for segmentation.\n",
        "        \"\"\"\n",
        "        self.vol_data_dict = vol_data_dict  # Changed to dictionary\n",
        "        self.synapse_df = synapse_df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.segmentation_type = segmentation_type\n",
        "        self.subvol_size = subvol_size\n",
        "        self.num_frames = num_frames\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.synapse_df)\n",
        "    def __getitem__(self, idx):\n",
        "        syn_info = self.synapse_df.iloc[idx]\n",
        "        bbox_name = syn_info['bbox_name']  # Use bbox_name instead of bbox_index\n",
        "\n",
        "        # Unpack the volumes using bbox_name instead of bbox_index\n",
        "        raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
        "\n",
        "        if raw_vol is None or seg_vol is None or add_mask_vol is None:\n",
        "            # Return dummy data if volumes not found\n",
        "            pixel_values = torch.zeros((self.num_frames, 3, self.subvol_size, self.subvol_size), dtype=torch.float32)\n",
        "            return pixel_values, syn_info, bbox_name\n",
        "\n",
        "        # Coordinates\n",
        "        central_coord = (\n",
        "            int(syn_info['central_coord_1']),\n",
        "            int(syn_info['central_coord_2']),\n",
        "            int(syn_info['central_coord_3'])\n",
        "        )\n",
        "        side1_coord = (\n",
        "            int(syn_info['side_1_coord_1']),\n",
        "            int(syn_info['side_1_coord_2']),\n",
        "            int(syn_info['side_1_coord_3'])\n",
        "        )\n",
        "        side2_coord = (\n",
        "            int(syn_info['side_2_coord_1']),\n",
        "            int(syn_info['side_2_coord_2']),\n",
        "            int(syn_info['side_2_coord_3'])\n",
        "        )\n",
        "\n",
        "        # Create the overlaid segmented cube with the additional mask based on segmentation_type\n",
        "        overlaid_cube = create_segmented_cube(\n",
        "            raw_vol=raw_vol,\n",
        "            seg_vol=seg_vol,\n",
        "            add_mask_vol=add_mask_vol,\n",
        "            central_coord=central_coord,\n",
        "            side1_coord=side1_coord,\n",
        "            side2_coord=side2_coord,\n",
        "            segmentation_type=self.segmentation_type,\n",
        "            subvolume_size=self.subvol_size,\n",
        "            alpha=self.alpha\n",
        "        )  # shape: (80, 80, 3, 80)\n",
        "\n",
        "        # We interpret the last dimension (depth) as frames\n",
        "        frames = []\n",
        "        for z in range(overlaid_cube.shape[3]):  # 80 slices\n",
        "            frame_rgb = overlaid_cube[..., z]  # (80, 80, 3)\n",
        "            frames.append(frame_rgb)\n",
        "\n",
        "        # Now reduce or expand to self.num_frames\n",
        "        total_slices = len(frames)  # 80\n",
        "        if total_slices < self.num_frames:\n",
        "            while len(frames) < self.num_frames:\n",
        "                frames.append(frames[-1])\n",
        "        elif total_slices > self.num_frames:\n",
        "            indices = np.linspace(0, total_slices - 1, self.num_frames, dtype=int)\n",
        "            frames = [frames[i] for i in indices]\n",
        "\n",
        "        # Process using the VideoMAEImageProcessor\n",
        "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
        "        pixel_values = inputs[\"pixel_values\"].squeeze(0)  # (num_frames, 3, H, W)\n",
        "        pixel_values = pixel_values.float()\n",
        "\n",
        "        # Return pixel values, the corresponding DataFrame row, and the bbox name\n",
        "        return pixel_values, syn_info, bbox_name  # Return the pixel values, DataFrame row, and bbox_name\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"\n",
        "    Parse command-line arguments for configurable paths and training parameters.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"VideoMAE Pre-training Script with Segmented Videos and Additional Masks\")\n",
        "\n",
        "    # Data directories\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw', help='Path to raw data directory')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg', help='Path to segmentation data directory')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='', help='Path to additional masks directory')\n",
        "    parser.add_argument('--bbox_name', type=str, default='bbox1', help='Name of the bounding box directory')\n",
        "    parser.add_argument('--excel_file', type=str, default='', help='Excel file with synapse coordinates')\n",
        "    # Output and logging directories\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs', help='Directory to save CSV outputs')\n",
        "    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints', help='Directory to save model checkpoints')\n",
        "    parser.add_argument('--log_dir', type=str, default='logs', help='Directory for TensorBoard logs')\n",
        "\n",
        "    # Training parameters\n",
        "    parser.add_argument('--batch_size', type=int, default=2, help='Batch size for training')\n",
        "    parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
        "    parser.add_argument('--learning_rate', type=float, default=1e-4, help='Learning rate for optimizer')\n",
        "    parser.add_argument('--weight_decay', type=float, default=1e-2, help='Weight decay for optimizer')\n",
        "    parser.add_argument('--subvol_size', type=int, default=80, help='Size of the sub-volume to extract')\n",
        "    parser.add_argument('--num_frames', type=int, default=16, help='Number of frames per video clip')\n",
        "    parser.add_argument('--mask_ratio', type=float, default=0.75, help='Mask ratio for VideoMAE')\n",
        "    parser.add_argument('--patience', type=int, default=3, help='Patience for early stopping')\n",
        "    parser.add_argument('--resume_checkpoint', type=str, default=None, help='Path to resume checkpoint')\n",
        "\n",
        "    # GIF saving parameters\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs', help='Directory to save sample GIFs')\n",
        "    parser.add_argument('--num_gifs', type=int, default=10, help='Number of sample GIFs to save')\n",
        "    parser.add_argument('--alpha', type=float, default=0.3, help='Transparency factor for segmentation overlay')\n",
        "    # New argument for segmentation type\n",
        "    parser.add_argument('--segmentation_type', type=int, default=5, choices=range(0, 6),\n",
        "                        help='Type of segmentation overlay:\\n'\n",
        "                             '0 = Raw image\\n'\n",
        "                             '1 = Raw + Side1\\n'\n",
        "                             '2 = Raw + Side2\\n'\n",
        "                             '3 = Raw + Side1 + Side2\\n'\n",
        "                             '4 = Raw + Vesicles\\n'\n",
        "                             '5 = Raw + Side1 + Side2 + Vesicles')\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "# def main(args):\n",
        "#     \"\"\"\n",
        "#     Main function to process the data and generate cubes.\n",
        "#     Args:\n",
        "#         args: Command-line arguments parsed by argparse.\n",
        "#     Returns:\n",
        "#         List[torch.Tensor]: List of processed cubes.\n",
        "#     \"\"\"\n",
        "#     # Initialize processor\n",
        "#     processor = SimpleVideoProcessor(size=(224, 224))\n",
        "\n",
        "#     # Load volumes\n",
        "#     raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "#         bbox_name=args.bbox_name,\n",
        "#         raw_base_dir=args.raw_base_dir,\n",
        "#         seg_base_dir=args.seg_base_dir,\n",
        "#         add_mask_base_dir=args.add_mask_base_dir\n",
        "#     )\n",
        "\n",
        "#     if raw_vol is None or seg_vol is None or add_mask_vol is None:\n",
        "#         raise ValueError(f\"Failed to load volumes for {args.bbox_name}\")\n",
        "\n",
        "#     # Create a dictionary to map bbox_name to corresponding volumes\n",
        "#     vol_data_dict = {args.bbox_name: (raw_vol, seg_vol, add_mask_vol)}\n",
        "\n",
        "#     # Load synapse DataFrame\n",
        "#     excel_file = os.path.join(args.excel_file, f\"{args.bbox_name}.xlsx\")\n",
        "#     print(f\"Loading synapse data from {excel_file}...\")\n",
        "#     syn_df = pd.read_excel(excel_file)\n",
        "#     syn_df['bbox_name'] = args.bbox_name  # Add bbox_name to the DataFrame\n",
        "\n",
        "#     # Create dataset\n",
        "#     dataset = VideoMAEDataset(\n",
        "#         vol_data_dict=vol_data_dict,  # Pass the dictionary\n",
        "#         synapse_df=syn_df,\n",
        "#         processor=processor,\n",
        "#         segmentation_type=args.segmentation_type,\n",
        "#         subvol_size=args.subvol_size,\n",
        "#         num_frames=args.num_frames,\n",
        "#         alpha=args.alpha\n",
        "#     )\n",
        "\n",
        "#     # Process cubes\n",
        "#     cubes = []\n",
        "#     for idx in range(len(dataset)):\n",
        "#         pixel_values, sys_info = dataset[idx]\n",
        "#         cubes.append(pixel_values)\n",
        "#         print(sys_info)  # Output the synapse information with bbox_name\n",
        "#     return cubes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# args = parse_args()\n",
        "# cubes = main(args)\n",
        "# print(f\"Processed {len(cubes)} cubes successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0fSkd98_9g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGa0hj0Z797q",
        "outputId": "65f6f75c-6c06-48f7-c808-3d3e041c8487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.30.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.20.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->open_clip_torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.12.14)\n",
            "Downloading open_clip_torch-2.30.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 open_clip_torch-2.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from open_clip import create_model_from_pretrained\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def main(args):\n",
        "    # Initialize processor\n",
        "    processor = SimpleVideoProcessor(size=(224, 224))\n",
        "\n",
        "    # List of all bboxes\n",
        "    bboxes = [f\"bbox{i}\" for i in range(1, 8)]  # bbox1 to bbox7\n",
        "\n",
        "    # Load volumes for all bboxes\n",
        "    vol_data_dict = {}\n",
        "    for bbox_name in bboxes:\n",
        "        raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "            bbox_name=bbox_name,\n",
        "            raw_base_dir=args.raw_base_dir,\n",
        "            seg_base_dir=args.seg_base_dir,\n",
        "            add_mask_base_dir=args.add_mask_base_dir\n",
        "        )\n",
        "        if raw_vol is not None and seg_vol is not None and add_mask_vol is not None:\n",
        "            vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "        else:\n",
        "            print(f\"Skipping {bbox_name} due to missing volumes.\")\n",
        "\n",
        "    # Load synapse data for all bboxes\n",
        "    synapse_dfs = []\n",
        "    for bbox_name in bboxes:\n",
        "        excel_file_path = os.path.join(args.excel_file, f\"{bbox_name}.xlsx\")\n",
        "        if os.path.exists(excel_file_path):\n",
        "            df = pd.read_excel(excel_file_path)\n",
        "            df['bbox_name'] = bbox_name  # Add bbox_name column\n",
        "            synapse_dfs.append(df)\n",
        "        else:\n",
        "            print(f\"Excel file not found for {bbox_name}. Skipping.\")\n",
        "    syn_df = pd.concat(synapse_dfs, ignore_index=True)\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = VideoMAEDataset(\n",
        "        vol_data_dict=vol_data_dict,\n",
        "        synapse_df=syn_df,\n",
        "        processor=processor,\n",
        "        segmentation_type=args.segmentation_type,\n",
        "        subvol_size=args.subvol_size,\n",
        "        num_frames=args.num_frames,\n",
        "        alpha=args.alpha\n",
        "    )\n",
        "\n",
        "    # Process cubes and collect synapse data\n",
        "    cubes = []\n",
        "    syn_info_list = []  # List to collect synapse information\n",
        "\n",
        "    for idx in range(len(dataset)):\n",
        "        pixel_values, syn_info,bbox_name = dataset[idx]\n",
        "        cubes.append(pixel_values)\n",
        "\n",
        "        # Collect synapse info\n",
        "        syn_info_list.append(syn_info)\n",
        "\n",
        "    # Merge all synapse info into a single DataFrame\n",
        "    merged_syn_info = pd.DataFrame(syn_info_list)\n",
        "\n",
        "    print(f\"Processed {len(cubes)} cubes successfully.\")\n",
        "    return cubes, merged_syn_info\n",
        "\n",
        "\n",
        "# Running the feature extraction with BiomedCLIP\n",
        "args = parse_args()\n",
        "cubes, syn_df = main(args)\n",
        "\n",
        "# Load BiomedCLIP Model\n",
        "model, preprocess = create_model_from_pretrained(\"hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device).eval()\n",
        "\n",
        "# Initialize empty list to store combined feature data\n",
        "all_combined_features = []\n",
        "\n",
        "# Extract features for each cube and combine with syn_df\n",
        "with torch.no_grad():\n",
        "    for idx, cube in enumerate(cubes):  # Iterate over all cubes\n",
        "        frame_features = []\n",
        "        for frame in cube.to(device):  # Iterate through all frames in the current cube\n",
        "            frame = frame.unsqueeze(0)  # Add batch dimension\n",
        "            features = model.encode_image(frame)\n",
        "            features = features / features.norm(dim=-1, keepdim=True)  # Normalize features\n",
        "            frame_features.append(features)\n",
        "\n",
        "        # Compute mean of frame features for the current cube\n",
        "        frame_features = torch.stack(frame_features)\n",
        "        cube_features = frame_features.mean(dim=0)  # Shape: (1, feature_dim)\n",
        "        # Convert the features to a flat NumPy array\n",
        "        syn_info = syn_df.iloc[idx].to_dict()  # Get synapse info for this cube\n",
        "\n",
        "        flattened_features = cube_features.cpu().numpy().flatten()\n",
        "\n",
        "        # Create a dictionary for the features with dynamic column names\n",
        "        feature_dict = {f\"feat_{i+1}\": val for i, val in enumerate(flattened_features)}\n",
        "\n",
        "        # Combine the synapse info with the individual features\n",
        "        combined_data = {\n",
        "            **syn_info,  # Include all synapse info\n",
        "            **feature_dict  # Add individual feature columns\n",
        "        }\n",
        "\n",
        "        # Append to the list of all combined features\n",
        "        all_combined_features.append(combined_data)\n",
        "\n",
        "        # # Combine cube features with corresponding synapse info\n",
        "        # combined_data = {\n",
        "        #     **syn_info,  # Include all synapse info\n",
        "        #     \"cube_features\": cube_features.cpu().numpy().flatten()  # Add flattened features\n",
        "        # }\n",
        "        # all_combined_features.append(combined_data)\n",
        "\n",
        "# Convert combined features to DataFrame\n",
        "combined_features_df = pd.DataFrame(all_combined_features)\n",
        "\n",
        "# Save the combined features to a CSV file (optional)\n",
        "combined_features_df.to_csv(\"combined_features.csv\", index=False)\n",
        "\n",
        "print(\"Feature extraction and combination completed successfully.\")"
      ],
      "metadata": {
        "id": "kY9X8z__sqhy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "46cc13998cd04a59bf1dc98531cfbdfd",
            "af0ce93ebbaa4a1abe2e78e8f064eb55",
            "0b77ce1a11534bbb9f9017757bb0ec53",
            "dbf091c56f1c498a883deae30cebf0cc",
            "bb82a14e732b42089d060fde192ae739",
            "896d2d88e59c4c44a671ec4417fe808e",
            "a049090537764c5292be3c588d16715e",
            "2294cff47c2c42a999193a701ed7912d",
            "cdcc8a56e0dd4d108a6136d5bf8264c4",
            "a108a031d26b428fb1fa6b9d78060e6a",
            "a21aee2204c7401ebff03685f20e286a",
            "456d9dc5c6684ac596eb6d8756b81311",
            "bc1e4d6113864cef88503d27bd57f679",
            "58136452b8bd48b1b119e9a7dd0f4573",
            "659179e62aed43deb8ce6e277d2eb2b9",
            "fd306396042c48ba9ef5da09dae8cb0e",
            "90bdf261d7ad4408b8053817f6fb2227",
            "8bbcec3a0ff544f691920abb8d743f2f",
            "a94c26655f61422b9a6486e494dea718",
            "2d91d2d449e84b03a6b137d64e1a1aed",
            "40210429a7764139b1a9324246144784",
            "c7251fa644964113aad9e3ccdcc8b3d4",
            "4b4e3dcc47f446f7a4572ac507fa3c46",
            "766d9d72c04d4fb985a0a145b47b6d40",
            "367d1d25c51c45939ab663bf828e383c",
            "b2e337c82b6a472ba130532a0f259bcd",
            "6ce62fff225b46f3a6eb9987a4b45910",
            "80be703ba44f43e38cb781c5b16218fb",
            "7df6b8ad9ef94db9833dca1074f65ef1",
            "2b59e653012747d59f5b3728ff77f827",
            "5d18198811d44c639192910e129eeea3",
            "d97cb66231904705b3d710d99dee6fc0",
            "a84d5a2bb8ad4d4289d8949279676fca"
          ]
        },
        "outputId": "3db54353-cb6d-40ba-d20d-9abe131f37cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 509 cubes successfully.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46cc13998cd04a59bf1dc98531cfbdfd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_pytorch_model.bin:   0%|          | 0.00/784M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "456d9dc5c6684ac596eb6d8756b81311",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b4e3dcc47f446f7a4572ac507fa3c46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction and combination completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "OI7spiByHRTB",
        "outputId": "e1832363-9d14-4593-9b9d-09454b92033a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       non_spine_synapsed_056\n",
              "1                          171\n",
              "2                          260\n",
              "3                          350\n",
              "4                          171\n",
              "                 ...          \n",
              "1733                       245\n",
              "1734                       232\n",
              "1735                       196\n",
              "1736                       245\n",
              "1737                     bbox2\n",
              "Length: 1738, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>non_spine_synapsed_056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1733</th>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1734</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1735</th>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>bbox2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1738 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}