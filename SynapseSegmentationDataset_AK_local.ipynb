{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alim98/MPI/blob/main/SynapseSegmentationDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daa58lj6b7qc"
   },
   "source": [
    "# Essential downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7SY--kjukgj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxdYaS94LBSI",
    "outputId": "47df249a-f4c4-40d8-bb8c-8b6702b8cde3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJzj48_y4iya",
    "outputId": "f0d97e07-2109-47f7-e4f5-38d87c020d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping ploty as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting plotly==5.3.1\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly==5.3.1) (9.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly==5.3.1) (1.17.0)\n",
      "Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/23.9 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: plotly\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 5.24.1\n",
      "    Uninstalling plotly-5.24.1:\n",
      "      Successfully uninstalled plotly-5.24.1\n",
      "Successfully installed plotly-5.3.1\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall ploty\n",
    "#!pip install plotly==5.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIIIxarwTVT0",
    "outputId": "2baec991-dd9f-430b-adea-170a60fac019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-24 11:39:33--  https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
      "2607:f8b0:4006:81f::2001, 142.250.72.97(drive.usercontent.google.com)... \n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|2607:f8b0:4006:81f::2001|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 1264688649 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘downloaded_file.zip’\n",
      "\n",
      "downloaded_file.zip 100%[===================>]   1.18G  19.3MB/s    in 67s     \n",
      "\n",
      "2025-02-24 11:40:43 (17.9 MB/s) - ‘downloaded_file.zip’ saved [1264688649/1264688649]\n",
      "\n",
      "--2025-02-24 11:40:43--  https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 2607:f8b0:4006:81f::2001, 142.250.72.97\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|2607:f8b0:4006:81f::2001|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14246564 (14M) [application/octet-stream]\n",
      "Saving to: ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’\n",
      "\n",
      "vesicle_cloud__syn_ 100%[===================>]  13.59M   274KB/s    in 40s     \n",
      "\n",
      "2025-02-24 11:41:54 (345 KB/s) - ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’ saved [14246564/14246564]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O downloaded_file.zip \"https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
    "!wget -O vesicle_cloud__syn_interface__mitochondria_annotation.zip \"https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
    "\n",
    "!unzip -q downloaded_file.zip\n",
    "!unzip -q vesicle_cloud__syn_interface__mitochondria_annotation.zip\n",
    "\n",
    "#!pip install transformers scikit-learn matplotlib seaborn torch torchvision umap-learn git+https://github.com/funkelab/funlib.learn.torch.git\n",
    "#!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-iwYc6iryNA"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Synapse Dataset Processing\n",
    "\n",
    "This repository provides a tool for processing 3D volume data of synapse structures for segmentation, visualization, and analysis. The tool allows users to load, segment, and process raw and segmented image data and generate 3D visualizations of synapse structures.\n",
    "\n",
    "The code processes multiple bounding boxes, each containing raw, segmentation, and additional mask data. Users can customize the segmentation overlay and generate visualizations in the form of segmented 3D cubes.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Load raw, segmentation, and additional mask data from directories.\n",
    "- Customize segmentation overlays for different synapse structures (e.g., vesicles, clefts, mitochondria).\n",
    "- Process multiple bounding boxes in parallel.\n",
    "- Generate 3D cubes with customizable segmentation.\n",
    "- Alpha blending for better visualization of the data.\n",
    "- Ability to save generated GIFs for visual inspection.\n",
    "- Efficient processing pipelines for handling large synapse datasets.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Before using the tool, make sure you have the following Python packages installed:\n",
    "\n",
    "```bash\n",
    "pip install numpy pandas imageio tqdm torch torchvision scipy\n",
    "```\n",
    "\n",
    "## Arguments Overview\n",
    "\n",
    "To run the script, use the following arguments to configure the dataset processing:\n",
    "\n",
    "### `--raw_base_dir` (Required)\n",
    "- **Description**: Directory containing the raw image data files (e.g., `.tif` slices).\n",
    "- **Type**: `str`\n",
    "- **Default**: `'raw'`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --raw_base_dir /path/to/raw/data\n",
    "    ```\n",
    "\n",
    "### `--seg_base_dir` (Required)\n",
    "- **Description**: Directory containing segmentation data files for pre and post-synaptic structures (e.g., `.tif` slices).\n",
    "- **Type**: `str`\n",
    "- **Default**: `'seg'`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --seg_base_dir /path/to/segmentation/data\n",
    "    ```\n",
    "\n",
    "### `--add_mask_base_dir` (Optional)\n",
    "- **Description**: Directory containing additional mask files for vesicles, clefts, and mitochondria (e.g., `.tif` slices).\n",
    "- **Type**: `str`\n",
    "- **Default**: `''` (empty string, optional)\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --add_mask_base_dir /path/to/additional/masks\n",
    "    ```\n",
    "\n",
    "### `--bbox_name` (Required)\n",
    "- **Description**: List of bounding box names to process. Each bounding box corresponds to a set of data files (raw, segmentation, and masks).\n",
    "- **Type**: `list[str]`\n",
    "- **Default**: `['bbox1']`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --bbox_name bbox1 bbox2 bbox3\n",
    "    ```\n",
    "\n",
    "### `--excel_file` (Required)\n",
    "- **Description**: Path to the directory containing Excel files with synapse information. The data from these Excel files will be used for synapse annotations.\n",
    "- **Type**: `str`\n",
    "- **Default**: `''` (required path to a directory)\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --excel_file /path/to/excel/files\n",
    "    ```\n",
    "\n",
    "### `--csv_output_dir` (Optional)\n",
    "- **Description**: Directory to save CSV outputs, such as processed data summaries.\n",
    "- **Type**: `str`\n",
    "- **Default**: `'csv_outputs'`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --csv_output_dir /path/to/csv/outputs\n",
    "    ```\n",
    "\n",
    "### `--size` (Optional)\n",
    "- **Description**: Target size for the frames. This will resize the frames to this size before processing.\n",
    "- **Type**: `tuple[int, int]`\n",
    "- **Default**: `(80, 80)`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --size 128 128\n",
    "    ```\n",
    "\n",
    "### `--subvol_size` (Optional)\n",
    "- **Description**: Subvolume size for extracting regions from the full volume. This size determines the 3D crop of the data.\n",
    "- **Type**: `int`\n",
    "- **Default**: `80`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --subvol_size 128\n",
    "    ```\n",
    "\n",
    "### `--num_frames` (Optional)\n",
    "- **Description**: Number of frames to extract from the data.\n",
    "- **Type**: `int`\n",
    "- **Default**: `80`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --num_frames 16\n",
    "    ```\n",
    "\n",
    "### `--save_gifs_dir` (Optional)\n",
    "- **Description**: Directory to save generated GIFs for each segmentation type.\n",
    "- **Type**: `str`\n",
    "- **Default**: `'gifs'`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --save_gifs_dir /path/to/save/gifs\n",
    "    ```\n",
    "\n",
    "### `--alpha` (Optional)\n",
    "- **Description**: Alpha blending factor for combining the raw image and the mask. This controls how much the unmasked areas are blended with a black overlay.\n",
    "- **Type**: `float`\n",
    "- **Default**: `0.5`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --alpha 0.7\n",
    "    ```\n",
    "\n",
    "### `--segmentation_type` (Required)\n",
    "- **Description**: Defines which type of segmentation overlay to apply to the raw data. This option determines which mask type will be used for overlaying the raw image.\n",
    "- **Type**: `int`\n",
    "- **Choices**:\n",
    "    - `0`: Raw image only (no overlay).\n",
    "    - `1`: Presynapse region.\n",
    "    - `2`: Postsynapse region.\n",
    "    - `3`: Both presynapse and postsynapse.\n",
    "    - `4`: Vesicles + Cleft (closest only).\n",
    "    - `5`: All structures (vesicles, clefts, mitochondria, and both synaptic sides).\n",
    "    - `6`: Vesicle cloud (closest).\n",
    "    - `7`: Cleft regions only.\n",
    "    - `8`: Mitochondria regions only.\n",
    "    - `9`: Vesicle + Cleft combined (closest).\n",
    "- **Default**: `6`\n",
    "- **Example**:\n",
    "    ```bash\n",
    "    --segmentation_type 3\n",
    "    ```\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "Here is an example of how to run the script with the necessary arguments:\n",
    "\n",
    "```bash\n",
    "python data_loader.py \\\n",
    "    --raw_base_dir /path/to/raw/data \\\n",
    "    --seg_base_dir /path/to/segmentation/data \\\n",
    "    --add_mask_base_dir /path/to/additional/masks \\\n",
    "    --bbox_name bbox1 bbox2 \\\n",
    "    --excel_file /path/to/excel/files \\\n",
    "    --csv_output_dir /path/to/csv/outputs \\\n",
    "    --save_gifs_dir /path/to/save/gifs \\\n",
    "    --segmentation_type 2 \\\n",
    "    --alpha 0.5\n",
    "```\n",
    "\n",
    "## Segmentation Type Handling\n",
    "\n",
    "The segmentation logic is based on the `segmentation_type` argument. It determines how to combine masks and create the desired visualization.\n",
    "\n",
    "### Segmentation Logic:\n",
    "\n",
    "- **`0`**: Raw image (no overlay)\n",
    "- **`1`**: Presynapse region (based on overlap of vesicles with side1 or side2).\n",
    "- **`2`**: Postsynapse region (based on overlap of vesicles with side1 or side2).\n",
    "- **`3`**: Both presynapssde and postsynapse regions (overlay of both).\n",
    "- **`4`**: Vesicles and clefts (closest components).\n",
    "- **`5`**: All structures (vesicles, clefts, and both synaptic sides).\n",
    "- **`6`**: Vesicle cloud (closest to target).\n",
    "- **`7`**: Cleft regions (closest to target).\n",
    "- **`8`**: Mitochondria regions (closest to target).\n",
    "- **`9`**: Combined vesicle + cleft (closest to target).\n",
    "- **`10`**: presynapse + cleft (closest to target).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gq_5sVGQQiyo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import io\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from typing import List, Tuple\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio.v3 as iio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from tqdm import tqdm\n",
    "class Synapse3DProcessor:\n",
    "    def __init__(self, size=(80, 80), mean=(0.485,), std=(0.229,)):\n",
    "        # Use Grayscale without converting to 3-channel RGB\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(size),\n",
    "            transforms.Grayscale(num_output_channels=1),  # Changed to 1 channel (grayscale)\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __call__(self, frames, return_tensors=None):\n",
    "        processed_frames = [self.transform(frame) for frame in frames]\n",
    "        pixel_values = torch.stack(processed_frames)\n",
    "        if return_tensors == \"pt\":\n",
    "            return {\"pixel_values\": pixel_values}\n",
    "        else:\n",
    "            return pixel_values\n",
    "\n",
    "def load_volumes(bbox_name: str, raw_base_dir: str, seg_base_dir: str, add_mask_base_dir: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    raw_dir = os.path.join(raw_base_dir, bbox_name)\n",
    "    seg_dir = os.path.join(seg_base_dir, bbox_name)\n",
    "    if bbox_name.startswith(\"bbox\"):\n",
    "        bbox_num = bbox_name.replace(\"bbox\", \"\")\n",
    "        add_mask_dir = os.path.join(add_mask_base_dir, f\"bbox_{bbox_num}\")\n",
    "    else:\n",
    "        add_mask_dir = os.path.join(add_mask_base_dir, bbox_name)\n",
    "    raw_tif_files = sorted(glob.glob(os.path.join(raw_dir, 'slice_*.tif')))\n",
    "    seg_tif_files = sorted(glob.glob(os.path.join(seg_dir, 'slice_*.tif')))\n",
    "    add_mask_tif_files = sorted(glob.glob(os.path.join(add_mask_dir, 'slice_*.tif')))\n",
    "    if not (len(raw_tif_files) == len(seg_tif_files) == len(add_mask_tif_files)):\n",
    "        return None, None, None\n",
    "    try:\n",
    "        raw_vol = np.stack([iio.imread(f) for f in raw_tif_files], axis=0)\n",
    "        seg_vol = np.stack([iio.imread(f).astype(np.uint32) for f in seg_tif_files], axis=0)\n",
    "        add_mask_vol = np.stack([iio.imread(f).astype(np.uint32) for f in add_mask_tif_files], axis=0)\n",
    "        return raw_vol, seg_vol, add_mask_vol\n",
    "    except Exception as e:\n",
    "        return None, None, None\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Synapse Dataset\")\n",
    "    parser.add_argument('--raw_base_dir', type=str, default='data/raw')\n",
    "    parser.add_argument('--seg_base_dir', type=str, default='data/seg')\n",
    "    parser.add_argument('--add_mask_base_dir', type=str, default='data/')\n",
    "    parser.add_argument('--bbox_name', type=str, default=['bbox1'], nargs='+')\n",
    "    parser.add_argument('--excel_file', type=str, default='data/')\n",
    "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
    "    parser.add_argument('--size', type=tuple, default=(80, 80))\n",
    "    parser.add_argument('--subvol_size', type=int, default=80)\n",
    "    parser.add_argument('--num_frames', type=int, default=80)\n",
    "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
    "    parser.add_argument('--alpha', type=float, default=0.5)\n",
    "    parser.add_argument('--segmentation_type', type=int, default=6, choices=range(0, 13),\n",
    "                        help='Type of segmentation overlay')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "def get_closest_component_mask(full_mask, z_start, z_end, y_start, y_end, x_start, x_end, target_coord):\n",
    "    sub_mask = full_mask[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "    labeled_sub_mask, num_features = label(sub_mask)\n",
    "    if num_features == 0:\n",
    "        return np.zeros_like(full_mask, dtype=bool)\n",
    "    else:\n",
    "        # For each label (vesicle cloud), find the nearest pixel to the target_coord\n",
    "        cx, cy, cz = target_coord\n",
    "        min_distance = float('inf')  # Initialize minimum distance as infinity\n",
    "        closest_label = None\n",
    "\n",
    "        for label_num in range(1, num_features + 1):  # labels are 1-based, not 0\n",
    "            # Get the coordinates of all pixels that belong to this label (vesicle cloud)\n",
    "            vesicle_coords = np.column_stack(np.where(labeled_sub_mask == label_num))\n",
    "\n",
    "            # Compute the distance of each pixel in the vesicle cloud to the target coordinate\n",
    "            distances = np.sqrt(\n",
    "                (vesicle_coords[:, 0] + z_start - cz) ** 2 +\n",
    "                (vesicle_coords[:, 1] + y_start - cy) ** 2 +\n",
    "                (vesicle_coords[:, 2] + x_start - cx) ** 2\n",
    "            )\n",
    "\n",
    "            # Find the pixel with the minimum distance\n",
    "            min_dist_for_vesicle = np.min(distances)\n",
    "            if min_dist_for_vesicle < min_distance:\n",
    "                min_distance = min_dist_for_vesicle\n",
    "                closest_label = label_num\n",
    "\n",
    "        # Now, create a mask for the closest vesicle cloud\n",
    "        if closest_label is not None:\n",
    "            filtered_sub_mask = (labeled_sub_mask == closest_label)\n",
    "            combined_mask = np.zeros_like(full_mask, dtype=bool)\n",
    "            combined_mask[z_start:z_end, y_start:y_end, x_start:x_end] = filtered_sub_mask\n",
    "            return combined_mask\n",
    "        else:\n",
    "            return np.zeros_like(full_mask, dtype=bool)\n",
    "\n",
    "def create_segmented_cube(\n",
    "    raw_vol: np.ndarray,\n",
    "    seg_vol: np.ndarray,\n",
    "    add_mask_vol: np.ndarray,\n",
    "    central_coord: Tuple[int, int, int],\n",
    "    side1_coord: Tuple[int, int, int],\n",
    "    side2_coord: Tuple[int, int, int],\n",
    "    segmentation_type: int,\n",
    "    subvolume_size: int = 80,\n",
    "    alpha: float = 0.3,\n",
    "    bbox_name: str = \"\",\n",
    ") -> np.ndarray:\n",
    "    bbox_num = bbox_name.replace(\"bbox\", \"\").strip()\n",
    "    if bbox_num in {'2', '5',}:\n",
    "        mito_label = 1\n",
    "        vesicle_label = 3\n",
    "        cleft_label2 = 4\n",
    "        cleft_label = 2\n",
    "    elif bbox_num == '7':\n",
    "        mito_label = 1\n",
    "        vesicle_label = 2\n",
    "        cleft_label2 = 3\n",
    "        cleft_label = 4\n",
    "    elif bbox_num == '4':\n",
    "        mito_label = 3\n",
    "        vesicle_label = 2\n",
    "        cleft_label2 = 4\n",
    "        cleft_label = 1\n",
    "    elif bbox_num == '3':\n",
    "        # print(\"bbox_num3\")\n",
    "        mito_label = 6\n",
    "        vesicle_label = 7\n",
    "        cleft_label2 = 8\n",
    "        cleft_label = 9\n",
    "    else:  # For bbox1, 3, 6, etc.\n",
    "        mito_label = 5\n",
    "        vesicle_label = 6\n",
    "        cleft_label = 7\n",
    "        cleft_label2 = 7\n",
    "\n",
    "    # --- Always calculate subvolume bounds FIRST ---\n",
    "    half_size = subvolume_size // 2\n",
    "    cx, cy, cz = central_coord\n",
    "    x_start = max(cx - half_size, 0)\n",
    "    x_end = min(cx + half_size, raw_vol.shape[2])\n",
    "    y_start = max(cy - half_size, 0)\n",
    "    y_end = min(cy + half_size, raw_vol.shape[1])\n",
    "    z_start = max(cz - half_size, 0)\n",
    "    z_end = min(cz + half_size, raw_vol.shape[0])\n",
    "\n",
    "    # --- Vesicle filtering (critical for presynapse determination) ---\n",
    "    vesicle_full_mask = (add_mask_vol == vesicle_label)\n",
    "    vesicle_mask = get_closest_component_mask(\n",
    "        vesicle_full_mask,\n",
    "        z_start, z_end,\n",
    "        y_start, y_end,\n",
    "        x_start, x_end,\n",
    "        (cx, cy, cz)\n",
    "    )\n",
    "\n",
    "    # --- Side masks ---\n",
    "    def create_segment_masks(segmentation_volume, s1_coord, s2_coord):\n",
    "        x1, y1, z1 = s1_coord\n",
    "        x2, y2, z2 = s2_coord\n",
    "        seg_id_1 = segmentation_volume[z1, y1, x1]\n",
    "        seg_id_2 = segmentation_volume[z2, y2, x2]\n",
    "        mask_1 = (segmentation_volume == seg_id_1) if seg_id_1 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
    "        mask_2 = (segmentation_volume == seg_id_2) if seg_id_2 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
    "        return mask_1, mask_2\n",
    "\n",
    "    mask_1_full, mask_2_full = create_segment_masks(seg_vol, side1_coord, side2_coord)\n",
    "\n",
    "    # --- Determine pre-synapse side using filtered vesicles ---\n",
    "    overlap_side1 = np.sum(np.logical_and(mask_1_full, vesicle_mask))\n",
    "    overlap_side2 = np.sum(np.logical_and(mask_2_full, vesicle_mask))\n",
    "    presynapse_side = 1 if overlap_side1 > overlap_side2 else 2\n",
    "    if segmentation_type == 0: # Raw data\n",
    "        combined_mask_full = np.ones_like(add_mask_vol, dtype=bool)\n",
    "    elif segmentation_type == 1:  # Presynapse\n",
    "        combined_mask_full = mask_1_full if presynapse_side == 1 else mask_2_full\n",
    "    elif segmentation_type == 2:  # Postsynapse\n",
    "        combined_mask_full = mask_2_full if presynapse_side == 1 else mask_1_full\n",
    "    elif segmentation_type == 3:  # Both sides\n",
    "        combined_mask_full = np.logical_or(mask_1_full, mask_2_full)\n",
    "    elif segmentation_type == 4:  # Vesicles + Cleft (closest only)\n",
    "        vesicle_closest = get_closest_component_mask(\n",
    "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        cleft_closest = get_closest_component_mask(\n",
    "            ((add_mask_vol == cleft_label)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        cleft_closest2 = get_closest_component_mask(\n",
    "            ((add_mask_vol == cleft_label2)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        combined_mask_full = np.logical_or(vesicle_closest, np.logical_or(cleft_closest,cleft_closest2))\n",
    "    elif segmentation_type == 5:  # (closest vesicles/cleft + sides)\n",
    "        vesicle_closest = get_closest_component_mask(\n",
    "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        cleft_closest = get_closest_component_mask(\n",
    "            (add_mask_vol == cleft_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        combined_mask_extra = np.logical_or(vesicle_closest, cleft_closest)\n",
    "        combined_mask_full = np.logical_or(mask_1_full, np.logical_or(mask_2_full, combined_mask_extra))\n",
    "    elif segmentation_type == 6:  # Vesicle cloud (closest)\n",
    "        combined_mask_full = get_closest_component_mask(\n",
    "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "    elif segmentation_type == 7:  # Cleft (closest)\n",
    "        cleft_closest = get_closest_component_mask(\n",
    "            ((add_mask_vol == cleft_label)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        cleft_closest2 = get_closest_component_mask(\n",
    "            ((add_mask_vol == cleft_label2)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        combined_mask_full =  np.logical_or(cleft_closest,cleft_closest2)\n",
    "    elif segmentation_type == 8:  # Mitochondria (closest)\n",
    "        combined_mask_full = get_closest_component_mask(\n",
    "            (add_mask_vol == mito_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "    elif segmentation_type == 10:  #  +Cleft +pre\n",
    "        cleft_closest = get_closest_component_mask(\n",
    "            (add_mask_vol == cleft_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        pre_mask_full = mask_1_full if presynapse_side == 1 else mask_2_full\n",
    "\n",
    "        combined_mask_full = np.logical_or(cleft_closest,pre_mask_full)\n",
    "\n",
    "    elif segmentation_type == 9:  # cleft+vesicle\n",
    "        vesicle_closest = get_closest_component_mask(\n",
    "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "        cleft_closest = get_closest_component_mask(\n",
    "            (add_mask_vol == cleft_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
    "        )\n",
    "\n",
    "        combined_mask_full = np.logical_or(cleft_closest,vesicle_closest)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported segmentation type: {segmentation_type}\")\n",
    "\n",
    "    # --- Subvolume extraction and processing ---\n",
    "    sub_raw = raw_vol[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "    sub_combined_mask = combined_mask_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "\n",
    "    # Padding if needed\n",
    "    pad_z = subvolume_size - sub_raw.shape[0]\n",
    "    pad_y = subvolume_size - sub_raw.shape[1]\n",
    "    pad_x = subvolume_size - sub_raw.shape[2]\n",
    "    if pad_z > 0 or pad_y > 0 or pad_x > 0:\n",
    "        sub_raw = np.pad(sub_raw, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=0)\n",
    "        sub_combined_mask = np.pad(sub_combined_mask, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=False)\n",
    "\n",
    "    sub_raw = sub_raw[:subvolume_size, :subvolume_size, :subvolume_size]\n",
    "    sub_combined_mask = sub_combined_mask[:subvolume_size, :subvolume_size, :subvolume_size]\n",
    "\n",
    "    # Vectorized normalization\n",
    "    sub_raw = sub_raw.astype(np.float32)\n",
    "    mins = np.min(sub_raw, axis=(1, 2), keepdims=True)\n",
    "    maxs = np.max(sub_raw, axis=(1, 2), keepdims=True)\n",
    "    ranges = np.where(maxs > mins, maxs - mins, 1.0)\n",
    "    normalized = (sub_raw - mins) / ranges\n",
    "\n",
    "    # Define gray color (0.5 for grayscale)\n",
    "    gray_color = 0.6  # For grayscale\n",
    "\n",
    "    # Vectorized blending with gray color\n",
    "    raw_rgb = np.repeat(normalized[..., np.newaxis], 3, axis=-1)  # Convert to RGB\n",
    "    mask_factor = sub_combined_mask[..., np.newaxis]  # Adding an extra dimension to make it (80, 80, 80, 1)\n",
    "\n",
    "    if alpha < 1:\n",
    "        blended_part = alpha * gray_color + (1 - alpha) * raw_rgb  # Blend with gray\n",
    "    else:\n",
    "        # When alpha is 1, apply gray only to unmasked areas (grayscale), keep raw_rgb in masked areas\n",
    "        blended_part = gray_color * (1 - mask_factor) + raw_rgb * mask_factor\n",
    "\n",
    "    # Now, overlaid_image will be computed as follows\n",
    "    overlaid_image = raw_rgb * mask_factor + (1 - mask_factor) * blended_part\n",
    "\n",
    "    # Convert to uint8 and transpose dimensions\n",
    "    overlaid_cube = np.transpose(overlaid_image, (1, 2, 3, 0))  # Keep it grayscale\n",
    "\n",
    "    return overlaid_cube\n",
    "\n",
    "class SynapseDataset(Dataset):\n",
    "    def __init__(self, vol_data_dict: dict, synapse_df: pd.DataFrame, processor,\n",
    "                 segmentation_type: int, subvol_size: int = 80, num_frames: int = 16,\n",
    "                 alpha: float = 0.3):\n",
    "        self.vol_data_dict = vol_data_dict\n",
    "        self.synapse_df = synapse_df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.segmentation_type = segmentation_type\n",
    "        self.subvol_size = subvol_size\n",
    "        self.num_frames = num_frames\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Compute and add presynapse sides on initialization\n",
    "        self.add_presynapse_sides()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.synapse_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        syn_info = self.synapse_df.iloc[idx]\n",
    "        bbox_name = syn_info['bbox_name']\n",
    "        raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
    "        if raw_vol is None:\n",
    "            return torch.zeros((self.num_frames, 1, self.subvol_size, self.subvol_size), dtype=torch.float32), syn_info, bbox_name\n",
    "\n",
    "        central_coord = (int(syn_info['central_coord_1']), int(syn_info['central_coord_2']), int(syn_info['central_coord_3']))\n",
    "        side1_coord = (int(syn_info['side_1_coord_1']), int(syn_info['side_1_coord_2']), int(syn_info['side_1_coord_3']))\n",
    "        side2_coord = (int(syn_info['side_2_coord_1']), int(syn_info['side_2_coord_2']), int(syn_info['side_2_coord_3']))\n",
    "\n",
    "        overlaid_cube = create_segmented_cube(\n",
    "            raw_vol=raw_vol,\n",
    "            seg_vol=seg_vol,\n",
    "            add_mask_vol=add_mask_vol,\n",
    "            central_coord=central_coord,\n",
    "            side1_coord=side1_coord,\n",
    "            side2_coord=side2_coord,\n",
    "            segmentation_type=self.segmentation_type,\n",
    "            subvolume_size=self.subvol_size,\n",
    "            alpha=self.alpha,\n",
    "            bbox_name=bbox_name,\n",
    "        )\n",
    "        frames = [overlaid_cube[..., z] for z in range(overlaid_cube.shape[3])]\n",
    "        if len(frames) < self.num_frames:\n",
    "            frames += [frames[-1]] * (self.num_frames - len(frames))\n",
    "        elif len(frames) > self.num_frames:\n",
    "            indices = np.linspace(0, len(frames)-1, self.num_frames, dtype=int)\n",
    "            frames = [frames[i] for i in indices]\n",
    "\n",
    "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
    "        return inputs[\"pixel_values\"].squeeze(0).float(), syn_info, bbox_name\n",
    "\n",
    "    def create_segment_masks(self, segmentation_volume, s1_coord, s2_coord):\n",
    "        \"\"\"\n",
    "        Creates boolean masks for the two synaptic sides.\n",
    "        \"\"\"\n",
    "        x1, y1, z1 = s1_coord\n",
    "        x2, y2, z2 = s2_coord\n",
    "        seg_id_1 = segmentation_volume[z1, y1, x1]\n",
    "        seg_id_2 = segmentation_volume[z2, y2, x2]\n",
    "        mask_1 = (segmentation_volume == seg_id_1) if seg_id_1 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
    "        mask_2 = (segmentation_volume == seg_id_2) if seg_id_2 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
    "        return mask_1, mask_2\n",
    "\n",
    "    def add_presynapse_sides(self):\n",
    "        \"\"\"\n",
    "        Computes the presynapse side for all samples using the vesicle mask and adds it as a column in self.synapse_df.\n",
    "        \"\"\"\n",
    "        presynapse_sides = []\n",
    "\n",
    "        for idx in range(len(self.synapse_df)):\n",
    "            syn_info = self.synapse_df.iloc[idx]\n",
    "            bbox_name = syn_info['bbox_name']\n",
    "            raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
    "\n",
    "            if raw_vol is None:\n",
    "                presynapse_sides.append(None)  # Append None for missing data\n",
    "                continue\n",
    "\n",
    "            # Extract coordinates\n",
    "            central_coord = (int(syn_info['central_coord_1']), int(syn_info['central_coord_2']), int(syn_info['central_coord_3']))\n",
    "            side1_coord = (int(syn_info['side_1_coord_1']), int(syn_info['side_1_coord_2']), int(syn_info['side_1_coord_3']))\n",
    "            side2_coord = (int(syn_info['side_2_coord_1']), int(syn_info['side_2_coord_2']), int(syn_info['side_2_coord_3']))\n",
    "\n",
    "            # Extract side masks using the refactored method\n",
    "            mask_1_full, mask_2_full = self.create_segment_masks(seg_vol, side1_coord, side2_coord)\n",
    "\n",
    "            # Get the correct vesicle label based on bbox\n",
    "            bbox_num = bbox_name.replace(\"bbox\", \"\").strip()\n",
    "            if bbox_num in {'2', '5'}:\n",
    "                vesicle_label = 3\n",
    "            elif bbox_num == '7':\n",
    "                vesicle_label = 2\n",
    "            elif bbox_num == '4':\n",
    "                vesicle_label = 2\n",
    "            elif bbox_num == '3':\n",
    "                vesicle_label = 7\n",
    "            else:  # Default case (e.g., bbox1, bbox6, etc.)\n",
    "                vesicle_label = 6\n",
    "\n",
    "            # Extract vesicle mask\n",
    "            subvolume_size = self.subvol_size\n",
    "            half_size = subvolume_size // 2\n",
    "            cx, cy, cz = central_coord\n",
    "            x_start, x_end = max(cx - half_size, 0), min(cx + half_size, raw_vol.shape[2])\n",
    "            y_start, y_end = max(cy - half_size, 0), min(cy + half_size, raw_vol.shape[1])\n",
    "            z_start, z_end = max(cz - half_size, 0), min(cz + half_size, raw_vol.shape[0])\n",
    "\n",
    "            vesicle_full_mask = (add_mask_vol == vesicle_label)\n",
    "            vesicle_mask = get_closest_component_mask(\n",
    "                vesicle_full_mask,\n",
    "                z_start, z_end, y_start, y_end, x_start, x_end,\n",
    "                (cx, cy, cz)\n",
    "            )\n",
    "\n",
    "            # Compute overlap with vesicle mask\n",
    "            overlap_side1 = np.sum(np.logical_and(mask_1_full, vesicle_mask))\n",
    "            overlap_side2 = np.sum(np.logical_and(mask_2_full, vesicle_mask))\n",
    "\n",
    "            # Assign presynapse side\n",
    "            presynapse_side = 1 if overlap_side1 > overlap_side2 else 2\n",
    "            presynapse_sides.append(presynapse_side)\n",
    "\n",
    "        # Add the computed presynapse sides as a new column in the DataFrame\n",
    "        self.synapse_df[\"presynapse_side\"] = presynapse_sides\n",
    "\n",
    "        \n",
    "# Add unique IDs to fixed_samples\n",
    "fixed_samples = [\n",
    "    {\"id\": 1, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_004\", \"slice_number\": 25},\n",
    "    {\"id\": 2, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_006\", \"slice_number\": 40},\n",
    "    {\"id\": 4, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-28_Cora_Wolter_031\", \"slice_number\": 43},\n",
    "    {\"id\": 3, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-28_Cora_Wolter_051\", \"slice_number\": 28},\n",
    "    {\"id\": 5, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_036\", \"slice_number\": 41},\n",
    "    {\"id\": 6, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_018\", \"slice_number\": 41},\n",
    "    {\"id\": 7, \"bbox_name\": \"bbox4\", \"Var1\": \"explorative_2024-08-03_Ali_Karimi_023\", \"slice_number\": 28},\n",
    "    {\"id\": 8, \"bbox_name\": \"bbox5\", \"Var1\": \"non_spine_synapse_033\", \"slice_number\": 48},\n",
    "    {\"id\": 9, \"bbox_name\": \"bbox5\", \"Var1\": \"non_spine_synapse_045\", \"slice_number\": 40},\n",
    "    {\"id\": 10, \"bbox_name\": \"bbox6\", \"Var1\": \"spine_synapse_070\", \"slice_number\": 37},\n",
    "    {\"id\": 11, \"bbox_name\": \"bbox6\", \"Var1\": \"spine_synapse_021\", \"slice_number\": 30},\n",
    "    {\"id\": 12, \"bbox_name\": \"bbox7\", \"Var1\": \"non_spine_synapse_013\", \"slice_number\": 25},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "c5LgD5ff1KY7"
   },
   "outputs": [],
   "source": [
    "bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
    "\n",
    "args.bbox_name=bbox_name\n",
    "args.segmentation_type=10\n",
    "vol_data_dict = {}\n",
    "for bbox_name in args.bbox_name:\n",
    "    raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
    "        bbox_name=bbox_name,\n",
    "        raw_base_dir=args.raw_base_dir,\n",
    "        seg_base_dir=args.seg_base_dir,\n",
    "        add_mask_base_dir=args.add_mask_base_dir\n",
    "    )\n",
    "    if raw_vol is not None:\n",
    "        vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
    "\n",
    "syn_df = pd.concat([\n",
    "    pd.read_excel(os.path.join(args.excel_file, f\"{bbox}.xlsx\")).assign(bbox_name=bbox)\n",
    "    for bbox in args.bbox_name if os.path.exists(os.path.join(args.excel_file, f\"{bbox}.xlsx\"))\n",
    "])\n",
    "\n",
    "processor = Synapse3DProcessor(size=args.size)\n",
    "\n",
    "\n",
    "dataset = SynapseDataset(\n",
    "    vol_data_dict=vol_data_dict,\n",
    "    synapse_df=syn_df,\n",
    "    processor=processor,\n",
    "    segmentation_type=args.segmentation_type,\n",
    "    subvol_size=args.subvol_size,\n",
    "    num_frames=args.num_frames,\n",
    "    alpha=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_output_path = \"data/synapse_df_with_side.csv\"\n",
    "dataset.synapse_df.to_csv(csv_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 575, 575)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_mask_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>central_coord_1</th>\n",
       "      <th>central_coord_2</th>\n",
       "      <th>central_coord_3</th>\n",
       "      <th>side_1_coord_1</th>\n",
       "      <th>side_1_coord_2</th>\n",
       "      <th>side_1_coord_3</th>\n",
       "      <th>side_2_coord_1</th>\n",
       "      <th>side_2_coord_2</th>\n",
       "      <th>side_2_coord_3</th>\n",
       "      <th>bbox_name</th>\n",
       "      <th>presynapse_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non_spine_synapsed_056</td>\n",
       "      <td>171</td>\n",
       "      <td>260</td>\n",
       "      <td>350</td>\n",
       "      <td>171</td>\n",
       "      <td>268</td>\n",
       "      <td>359</td>\n",
       "      <td>171</td>\n",
       "      <td>260</td>\n",
       "      <td>340</td>\n",
       "      <td>bbox1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_spine_synapse_057</td>\n",
       "      <td>223</td>\n",
       "      <td>113</td>\n",
       "      <td>425</td>\n",
       "      <td>223</td>\n",
       "      <td>112</td>\n",
       "      <td>438</td>\n",
       "      <td>223</td>\n",
       "      <td>114</td>\n",
       "      <td>407</td>\n",
       "      <td>bbox1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non_spine_synapse_058</td>\n",
       "      <td>280</td>\n",
       "      <td>102</td>\n",
       "      <td>377</td>\n",
       "      <td>280</td>\n",
       "      <td>94</td>\n",
       "      <td>400</td>\n",
       "      <td>280</td>\n",
       "      <td>108</td>\n",
       "      <td>364</td>\n",
       "      <td>bbox1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non_spine_synapse_063</td>\n",
       "      <td>455</td>\n",
       "      <td>131</td>\n",
       "      <td>162</td>\n",
       "      <td>455</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>455</td>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>bbox1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non_spine_synapse_062</td>\n",
       "      <td>138</td>\n",
       "      <td>121</td>\n",
       "      <td>302</td>\n",
       "      <td>135</td>\n",
       "      <td>113</td>\n",
       "      <td>298</td>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>312</td>\n",
       "      <td>bbox1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Var1  central_coord_1  central_coord_2  central_coord_3  \\\n",
       "0  non_spine_synapsed_056              171              260              350   \n",
       "1   non_spine_synapse_057              223              113              425   \n",
       "2   non_spine_synapse_058              280              102              377   \n",
       "3   non_spine_synapse_063              455              131              162   \n",
       "4   non_spine_synapse_062              138              121              302   \n",
       "\n",
       "   side_1_coord_1  side_1_coord_2  side_1_coord_3  side_2_coord_1  \\\n",
       "0             171             268             359             171   \n",
       "1             223             112             438             223   \n",
       "2             280              94             400             280   \n",
       "3             455             134             181             455   \n",
       "4             135             113             298             140   \n",
       "\n",
       "   side_2_coord_2  side_2_coord_3 bbox_name  presynapse_side  \n",
       "0             260             340     bbox1                1  \n",
       "1             114             407     bbox1                2  \n",
       "2             108             364     bbox1                1  \n",
       "3             127             145     bbox1                2  \n",
       "4             127             312     bbox1                2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.synapse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>central_coord_1</th>\n",
       "      <th>central_coord_2</th>\n",
       "      <th>central_coord_3</th>\n",
       "      <th>side_1_coord_1</th>\n",
       "      <th>side_1_coord_2</th>\n",
       "      <th>side_1_coord_3</th>\n",
       "      <th>side_2_coord_1</th>\n",
       "      <th>side_2_coord_2</th>\n",
       "      <th>side_2_coord_3</th>\n",
       "      <th>bbox_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non_spine_synapsed_056</td>\n",
       "      <td>171</td>\n",
       "      <td>260</td>\n",
       "      <td>350</td>\n",
       "      <td>171</td>\n",
       "      <td>268</td>\n",
       "      <td>359</td>\n",
       "      <td>171</td>\n",
       "      <td>260</td>\n",
       "      <td>340</td>\n",
       "      <td>bbox1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_spine_synapse_057</td>\n",
       "      <td>223</td>\n",
       "      <td>113</td>\n",
       "      <td>425</td>\n",
       "      <td>223</td>\n",
       "      <td>112</td>\n",
       "      <td>438</td>\n",
       "      <td>223</td>\n",
       "      <td>114</td>\n",
       "      <td>407</td>\n",
       "      <td>bbox1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non_spine_synapse_058</td>\n",
       "      <td>280</td>\n",
       "      <td>102</td>\n",
       "      <td>377</td>\n",
       "      <td>280</td>\n",
       "      <td>94</td>\n",
       "      <td>400</td>\n",
       "      <td>280</td>\n",
       "      <td>108</td>\n",
       "      <td>364</td>\n",
       "      <td>bbox1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non_spine_synapse_063</td>\n",
       "      <td>455</td>\n",
       "      <td>131</td>\n",
       "      <td>162</td>\n",
       "      <td>455</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>455</td>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>bbox1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non_spine_synapse_062</td>\n",
       "      <td>138</td>\n",
       "      <td>121</td>\n",
       "      <td>302</td>\n",
       "      <td>135</td>\n",
       "      <td>113</td>\n",
       "      <td>298</td>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>312</td>\n",
       "      <td>bbox1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>non_spine_synapse_005</td>\n",
       "      <td>383</td>\n",
       "      <td>303</td>\n",
       "      <td>229</td>\n",
       "      <td>378</td>\n",
       "      <td>294</td>\n",
       "      <td>229</td>\n",
       "      <td>388</td>\n",
       "      <td>312</td>\n",
       "      <td>229</td>\n",
       "      <td>bbox7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>non_spine_synapse_004</td>\n",
       "      <td>389</td>\n",
       "      <td>294</td>\n",
       "      <td>229</td>\n",
       "      <td>381</td>\n",
       "      <td>288</td>\n",
       "      <td>229</td>\n",
       "      <td>398</td>\n",
       "      <td>294</td>\n",
       "      <td>229</td>\n",
       "      <td>bbox7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>non_spine_synapse_003</td>\n",
       "      <td>216</td>\n",
       "      <td>248</td>\n",
       "      <td>123</td>\n",
       "      <td>225</td>\n",
       "      <td>249</td>\n",
       "      <td>123</td>\n",
       "      <td>207</td>\n",
       "      <td>247</td>\n",
       "      <td>123</td>\n",
       "      <td>bbox7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>non_spine_synapse_002</td>\n",
       "      <td>348</td>\n",
       "      <td>183</td>\n",
       "      <td>113</td>\n",
       "      <td>356</td>\n",
       "      <td>184</td>\n",
       "      <td>113</td>\n",
       "      <td>340</td>\n",
       "      <td>182</td>\n",
       "      <td>113</td>\n",
       "      <td>bbox7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>non_spine_synapse_001</td>\n",
       "      <td>336</td>\n",
       "      <td>344</td>\n",
       "      <td>102</td>\n",
       "      <td>347</td>\n",
       "      <td>343</td>\n",
       "      <td>102</td>\n",
       "      <td>324</td>\n",
       "      <td>343</td>\n",
       "      <td>102</td>\n",
       "      <td>bbox7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Var1  central_coord_1  central_coord_2  central_coord_3  \\\n",
       "0   non_spine_synapsed_056              171              260              350   \n",
       "1    non_spine_synapse_057              223              113              425   \n",
       "2    non_spine_synapse_058              280              102              377   \n",
       "3    non_spine_synapse_063              455              131              162   \n",
       "4    non_spine_synapse_062              138              121              302   \n",
       "..                     ...              ...              ...              ...   \n",
       "60   non_spine_synapse_005              383              303              229   \n",
       "61   non_spine_synapse_004              389              294              229   \n",
       "62   non_spine_synapse_003              216              248              123   \n",
       "63   non_spine_synapse_002              348              183              113   \n",
       "64   non_spine_synapse_001              336              344              102   \n",
       "\n",
       "    side_1_coord_1  side_1_coord_2  side_1_coord_3  side_2_coord_1  \\\n",
       "0              171             268             359             171   \n",
       "1              223             112             438             223   \n",
       "2              280              94             400             280   \n",
       "3              455             134             181             455   \n",
       "4              135             113             298             140   \n",
       "..             ...             ...             ...             ...   \n",
       "60             378             294             229             388   \n",
       "61             381             288             229             398   \n",
       "62             225             249             123             207   \n",
       "63             356             184             113             340   \n",
       "64             347             343             102             324   \n",
       "\n",
       "    side_2_coord_2  side_2_coord_3 bbox_name  \n",
       "0              260             340     bbox1  \n",
       "1              114             407     bbox1  \n",
       "2              108             364     bbox1  \n",
       "3              127             145     bbox1  \n",
       "4              127             312     bbox1  \n",
       "..             ...             ...       ...  \n",
       "60             312             229     bbox7  \n",
       "61             294             229     bbox7  \n",
       "62             247             123     bbox7  \n",
       "63             182             113     bbox7  \n",
       "64             343             102     bbox7  \n",
       "\n",
       "[509 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "daa58lj6b7qc"
   ],
   "gpuType": "L4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
