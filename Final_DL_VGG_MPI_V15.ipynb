{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alim98/MPI/blob/main/Final_DL_VGG_MPI_V15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daa58lj6b7qc"
      },
      "source": [
        "# Essential downloads"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7SY--kjukgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lxdYaS94LBSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47df249a-f4c4-40d8-bb8c-8b6702b8cde3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJzj48_y4iya",
        "outputId": "f0d97e07-2109-47f7-e4f5-38d87c020d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping ploty as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting plotly==5.3.1\n",
            "  Downloading plotly-5.3.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly==5.3.1) (9.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly==5.3.1) (1.17.0)\n",
            "Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/23.9 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "Successfully installed plotly-5.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall ploty\n",
        "!pip install plotly==5.3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AIIIxarwTVT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2baec991-dd9f-430b-adea-170a60fac019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-18 10:18:18--  https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.130.132, 2404:6800:4003:c01::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.130.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1264688649 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘downloaded_file.zip’\n",
            "\n",
            "downloaded_file.zip 100%[===================>]   1.18G  60.1MB/s    in 19s     \n",
            "\n",
            "2025-02-18 10:18:40 (64.8 MB/s) - ‘downloaded_file.zip’ saved [1264688649/1264688649]\n",
            "\n",
            "--2025-02-18 10:18:40--  https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.130.132, 2404:6800:4003:c01::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.130.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14246564 (14M) [application/octet-stream]\n",
            "Saving to: ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’\n",
            "\n",
            "vesicle_cloud__syn_ 100%[===================>]  13.59M  34.3MB/s    in 0.4s    \n",
            "\n",
            "2025-02-18 10:19:12 (34.3 MB/s) - ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’ saved [14246564/14246564]\n",
            "\n",
            "Collecting git+https://github.com/funkelab/funlib.learn.torch.git\n",
            "  Cloning https://github.com/funkelab/funlib.learn.torch.git to /tmp/pip-req-build-ppw8cyc7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/funkelab/funlib.learn.torch.git /tmp/pip-req-build-ppw8cyc7\n",
            "  Resolved https://github.com/funkelab/funlib.learn.torch.git to commit 049729151c7a2c0320a446dc9d3244ac830f7ea8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting umap-learn\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.61.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: funlib.learn.torch\n",
            "  Building wheel for funlib.learn.torch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funlib.learn.torch: filename=funlib.learn.torch-0.1.0-py3-none-any.whl size=13995 sha256=5ace576f697beeb5704caee2b47612ab0a4601577be84f308796cec8329c5e2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-51voe1cd/wheels/ae/7f/7b/ecbd355ccdfbd2bb0ab4f76ea45f60a02a572c88c1f4761e8d\n",
            "Successfully built funlib.learn.torch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pynndescent, nvidia-cusolver-cu12, umap-learn, funlib.learn.torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed funlib.learn.torch-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pynndescent-0.5.13 umap-learn-0.5.7\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "!wget -O downloaded_file.zip \"https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "!wget -O vesicle_cloud__syn_interface__mitochondria_annotation.zip \"https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "\n",
        "!unzip -q downloaded_file.zip\n",
        "!unzip -q vesicle_cloud__syn_interface__mitochondria_annotation.zip\n",
        "\n",
        "!pip install transformers scikit-learn matplotlib seaborn torch torchvision umap-learn git+https://github.com/funkelab/funlib.learn.torch.git\n",
        "!pip install openpyxl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-iwYc6iryNA"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Synapse Dataset Processing\n",
        "\n",
        "This repository provides a tool for processing 3D volume data of synapse structures for segmentation, visualization, and analysis. The tool allows users to load, segment, and process raw and segmented image data and generate 3D visualizations of synapse structures.\n",
        "\n",
        "The code processes multiple bounding boxes, each containing raw, segmentation, and additional mask data. Users can customize the segmentation overlay and generate visualizations in the form of segmented 3D cubes.\n",
        "\n",
        "## Features\n",
        "\n",
        "- Load raw, segmentation, and additional mask data from directories.\n",
        "- Customize segmentation overlays for different synapse structures (e.g., vesicles, clefts, mitochondria).\n",
        "- Process multiple bounding boxes in parallel.\n",
        "- Generate 3D cubes with customizable segmentation.\n",
        "- Alpha blending for better visualization of the data.\n",
        "- Ability to save generated GIFs for visual inspection.\n",
        "- Efficient processing pipelines for handling large synapse datasets.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "Before using the tool, make sure you have the following Python packages installed:\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas imageio tqdm torch torchvision scipy\n",
        "```\n",
        "\n",
        "## Arguments Overview\n",
        "\n",
        "To run the script, use the following arguments to configure the dataset processing:\n",
        "\n",
        "### `--raw_base_dir` (Required)\n",
        "- **Description**: Directory containing the raw image data files (e.g., `.tif` slices).\n",
        "- **Type**: `str`\n",
        "- **Default**: `'raw'`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --raw_base_dir /path/to/raw/data\n",
        "    ```\n",
        "\n",
        "### `--seg_base_dir` (Required)\n",
        "- **Description**: Directory containing segmentation data files for pre and post-synaptic structures (e.g., `.tif` slices).\n",
        "- **Type**: `str`\n",
        "- **Default**: `'seg'`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --seg_base_dir /path/to/segmentation/data\n",
        "    ```\n",
        "\n",
        "### `--add_mask_base_dir` (Optional)\n",
        "- **Description**: Directory containing additional mask files for vesicles, clefts, and mitochondria (e.g., `.tif` slices).\n",
        "- **Type**: `str`\n",
        "- **Default**: `''` (empty string, optional)\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --add_mask_base_dir /path/to/additional/masks\n",
        "    ```\n",
        "\n",
        "### `--bbox_name` (Required)\n",
        "- **Description**: List of bounding box names to process. Each bounding box corresponds to a set of data files (raw, segmentation, and masks).\n",
        "- **Type**: `list[str]`\n",
        "- **Default**: `['bbox1']`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --bbox_name bbox1 bbox2 bbox3\n",
        "    ```\n",
        "\n",
        "### `--excel_file` (Required)\n",
        "- **Description**: Path to the directory containing Excel files with synapse information. The data from these Excel files will be used for synapse annotations.\n",
        "- **Type**: `str`\n",
        "- **Default**: `''` (required path to a directory)\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --excel_file /path/to/excel/files\n",
        "    ```\n",
        "\n",
        "### `--csv_output_dir` (Optional)\n",
        "- **Description**: Directory to save CSV outputs, such as processed data summaries.\n",
        "- **Type**: `str`\n",
        "- **Default**: `'csv_outputs'`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --csv_output_dir /path/to/csv/outputs\n",
        "    ```\n",
        "\n",
        "### `--size` (Optional)\n",
        "- **Description**: Target size for the frames. This will resize the frames to this size before processing.\n",
        "- **Type**: `tuple[int, int]`\n",
        "- **Default**: `(80, 80)`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --size 128 128\n",
        "    ```\n",
        "\n",
        "### `--subvol_size` (Optional)\n",
        "- **Description**: Subvolume size for extracting regions from the full volume. This size determines the 3D crop of the data.\n",
        "- **Type**: `int`\n",
        "- **Default**: `80`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --subvol_size 128\n",
        "    ```\n",
        "\n",
        "### `--num_frames` (Optional)\n",
        "- **Description**: Number of frames to extract from the data.\n",
        "- **Type**: `int`\n",
        "- **Default**: `80`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --num_frames 16\n",
        "    ```\n",
        "\n",
        "### `--save_gifs_dir` (Optional)\n",
        "- **Description**: Directory to save generated GIFs for each segmentation type.\n",
        "- **Type**: `str`\n",
        "- **Default**: `'gifs'`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --save_gifs_dir /path/to/save/gifs\n",
        "    ```\n",
        "\n",
        "### `--alpha` (Optional)\n",
        "- **Description**: Alpha blending factor for combining the raw image and the mask. This controls how much the unmasked areas are blended with a black overlay.\n",
        "- **Type**: `float`\n",
        "- **Default**: `0.5`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --alpha 0.7\n",
        "    ```\n",
        "\n",
        "### `--segmentation_type` (Required)\n",
        "- **Description**: Defines which type of segmentation overlay to apply to the raw data. This option determines which mask type will be used for overlaying the raw image.\n",
        "- **Type**: `int`\n",
        "- **Choices**:\n",
        "    - `0`: Raw image only (no overlay).\n",
        "    - `1`: Presynapse region.\n",
        "    - `2`: Postsynapse region.\n",
        "    - `3`: Both presynapse and postsynapse.\n",
        "    - `4`: Vesicles + Cleft (closest only).\n",
        "    - `5`: All structures (vesicles, clefts, mitochondria, and both synaptic sides).\n",
        "    - `6`: Vesicle cloud (closest).\n",
        "    - `7`: Cleft regions only.\n",
        "    - `8`: Mitochondria regions only.\n",
        "    - `9`: Vesicle + Cleft combined (closest).\n",
        "- **Default**: `6`\n",
        "- **Example**:\n",
        "    ```bash\n",
        "    --segmentation_type 3\n",
        "    ```\n",
        "\n",
        "## Example Usage\n",
        "\n",
        "Here is an example of how to run the script with the necessary arguments:\n",
        "\n",
        "```bash\n",
        "python data_loader.py \\\n",
        "    --raw_base_dir /path/to/raw/data \\\n",
        "    --seg_base_dir /path/to/segmentation/data \\\n",
        "    --add_mask_base_dir /path/to/additional/masks \\\n",
        "    --bbox_name bbox1 bbox2 \\\n",
        "    --excel_file /path/to/excel/files \\\n",
        "    --csv_output_dir /path/to/csv/outputs \\\n",
        "    --save_gifs_dir /path/to/save/gifs \\\n",
        "    --segmentation_type 2 \\\n",
        "    --alpha 0.5\n",
        "```\n",
        "\n",
        "## Segmentation Type Handling\n",
        "\n",
        "The segmentation logic is based on the `segmentation_type` argument. It determines how to combine masks and create the desired visualization.\n",
        "\n",
        "### Segmentation Logic:\n",
        "\n",
        "- **`0`**: Raw image (no overlay)\n",
        "- **`1`**: Presynapse region (based on overlap of vesicles with side1 or side2).\n",
        "- **`2`**: Postsynapse region (based on overlap of vesicles with side1 or side2).\n",
        "- **`3`**: Both presynapssde and postsynapse regions (overlay of both).\n",
        "- **`4`**: Vesicles and clefts (closest components).\n",
        "- **`5`**: All structures (vesicles, clefts, mitochondria, and both synaptic sides).\n",
        "- **`6`**: Vesicle cloud (closest to target).\n",
        "- **`7`**: Cleft regions (closest to target).\n",
        "- **`8`**: Mitochondria regions (closest to target).\n",
        "- **`9`**: Combined vesicle + cleft (closest to target).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gq_5sVGQQiyo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import io\n",
        "import argparse\n",
        "import multiprocessing\n",
        "from typing import List, Tuple\n",
        "import imageio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio.v3 as iio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from scipy.ndimage import label, center_of_mass\n",
        "from tqdm import tqdm\n",
        "class Synapse3DProcessor:\n",
        "    def __init__(self, size=(80, 80), mean=(0.485,), std=(0.229,)):\n",
        "        # Use Grayscale without converting to 3-channel RGB\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize(size),\n",
        "            transforms.Grayscale(num_output_channels=1),  # Changed to 1 channel (grayscale)\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(mean=mean, std=std),\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __call__(self, frames, return_tensors=None):\n",
        "        processed_frames = [self.transform(frame) for frame in frames]\n",
        "        pixel_values = torch.stack(processed_frames)\n",
        "        if return_tensors == \"pt\":\n",
        "            return {\"pixel_values\": pixel_values}\n",
        "        else:\n",
        "            return pixel_values\n",
        "\n",
        "def load_volumes(bbox_name: str, raw_base_dir: str, seg_base_dir: str, add_mask_base_dir: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    raw_dir = os.path.join(raw_base_dir, bbox_name)\n",
        "    seg_dir = os.path.join(seg_base_dir, bbox_name)\n",
        "    if bbox_name.startswith(\"bbox\"):\n",
        "        bbox_num = bbox_name.replace(\"bbox\", \"\")\n",
        "        add_mask_dir = os.path.join(add_mask_base_dir, f\"bbox_{bbox_num}\")\n",
        "    else:\n",
        "        add_mask_dir = os.path.join(add_mask_base_dir, bbox_name)\n",
        "    raw_tif_files = sorted(glob.glob(os.path.join(raw_dir, 'slice_*.tif')))\n",
        "    seg_tif_files = sorted(glob.glob(os.path.join(seg_dir, 'slice_*.tif')))\n",
        "    add_mask_tif_files = sorted(glob.glob(os.path.join(add_mask_dir, 'slice_*.tif')))\n",
        "    if not (len(raw_tif_files) == len(seg_tif_files) == len(add_mask_tif_files)):\n",
        "        return None, None, None\n",
        "    try:\n",
        "        raw_vol = np.stack([iio.imread(f) for f in raw_tif_files], axis=0)\n",
        "        seg_vol = np.stack([iio.imread(f).astype(np.uint32) for f in seg_tif_files], axis=0)\n",
        "        add_mask_vol = np.stack([iio.imread(f).astype(np.uint32) for f in add_mask_tif_files], axis=0)\n",
        "        return raw_vol, seg_vol, add_mask_vol\n",
        "    except Exception as e:\n",
        "        return None, None, None\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Synapse Dataset\")\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='')\n",
        "    parser.add_argument('--bbox_name', type=str, default=['bbox1'], nargs='+')\n",
        "    parser.add_argument('--excel_file', type=str, default='')\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
        "    parser.add_argument('--size', type=tuple, default=(80, 80))\n",
        "    parser.add_argument('--subvol_size', type=int, default=80)\n",
        "    parser.add_argument('--num_frames', type=int, default=80)\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
        "    parser.add_argument('--alpha', type=float, default=0.5)\n",
        "    parser.add_argument('--segmentation_type', type=int, default=6, choices=range(0, 13),\n",
        "                        help='Type of segmentation overlay')\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "def get_closest_component_mask(full_mask, z_start, z_end, y_start, y_end, x_start, x_end, target_coord):\n",
        "    sub_mask = full_mask[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    labeled_sub_mask, num_features = label(sub_mask)\n",
        "    if num_features == 0:\n",
        "        return np.zeros_like(full_mask, dtype=bool)\n",
        "    else:\n",
        "        # For each label (vesicle cloud), find the nearest pixel to the target_coord\n",
        "        cx, cy, cz = target_coord\n",
        "        min_distance = float('inf')  # Initialize minimum distance as infinity\n",
        "        closest_label = None\n",
        "\n",
        "        for label_num in range(1, num_features + 1):  # labels are 1-based, not 0\n",
        "            # Get the coordinates of all pixels that belong to this label (vesicle cloud)\n",
        "            vesicle_coords = np.column_stack(np.where(labeled_sub_mask == label_num))\n",
        "\n",
        "            # Compute the distance of each pixel in the vesicle cloud to the target coordinate\n",
        "            distances = np.sqrt(\n",
        "                (vesicle_coords[:, 0] + z_start - cz) ** 2 +\n",
        "                (vesicle_coords[:, 1] + y_start - cy) ** 2 +\n",
        "                (vesicle_coords[:, 2] + x_start - cx) ** 2\n",
        "            )\n",
        "\n",
        "            # Find the pixel with the minimum distance\n",
        "            min_dist_for_vesicle = np.min(distances)\n",
        "            if min_dist_for_vesicle < min_distance:\n",
        "                min_distance = min_dist_for_vesicle\n",
        "                closest_label = label_num\n",
        "\n",
        "        # Now, create a mask for the closest vesicle cloud\n",
        "        if closest_label is not None:\n",
        "            filtered_sub_mask = (labeled_sub_mask == closest_label)\n",
        "            combined_mask = np.zeros_like(full_mask, dtype=bool)\n",
        "            combined_mask[z_start:z_end, y_start:y_end, x_start:x_end] = filtered_sub_mask\n",
        "            return combined_mask\n",
        "        else:\n",
        "            return np.zeros_like(full_mask, dtype=bool)\n",
        "\n",
        "def create_segmented_cube(\n",
        "    raw_vol: np.ndarray,\n",
        "    seg_vol: np.ndarray,\n",
        "    add_mask_vol: np.ndarray,\n",
        "    central_coord: Tuple[int, int, int],\n",
        "    side1_coord: Tuple[int, int, int],\n",
        "    side2_coord: Tuple[int, int, int],\n",
        "    segmentation_type: int,\n",
        "    subvolume_size: int = 80,\n",
        "    alpha: float = 0.3,\n",
        "    bbox_name: str = \"\",\n",
        ") -> np.ndarray:\n",
        "    bbox_num = bbox_name.replace(\"bbox\", \"\").strip()\n",
        "    if bbox_num in {'2', '5',}:\n",
        "        mito_label = 1\n",
        "        vesicle_label = 3\n",
        "        cleft_label2 = 4\n",
        "        cleft_label = 2\n",
        "    elif bbox_num == '7':\n",
        "        mito_label = 1\n",
        "        vesicle_label = 2\n",
        "        cleft_label2 = 3\n",
        "        cleft_label = 4\n",
        "    elif bbox_num == '4':\n",
        "        mito_label = 3\n",
        "        vesicle_label = 2\n",
        "        cleft_label2 = 4\n",
        "        cleft_label = 1\n",
        "    elif bbox_num == '3':\n",
        "        # print(\"bbox_num3\")\n",
        "        mito_label = 6\n",
        "        vesicle_label = 7\n",
        "        cleft_label2 = 8\n",
        "        cleft_label = 9\n",
        "    else:  # For bbox1, 3, 6, etc.\n",
        "        mito_label = 5\n",
        "        vesicle_label = 6\n",
        "        cleft_label = 7\n",
        "        cleft_label2 = 7\n",
        "\n",
        "    # --- Always calculate subvolume bounds FIRST ---\n",
        "    half_size = subvolume_size // 2\n",
        "    cx, cy, cz = central_coord\n",
        "    x_start = max(cx - half_size, 0)\n",
        "    x_end = min(cx + half_size, raw_vol.shape[2])\n",
        "    y_start = max(cy - half_size, 0)\n",
        "    y_end = min(cy + half_size, raw_vol.shape[1])\n",
        "    z_start = max(cz - half_size, 0)\n",
        "    z_end = min(cz + half_size, raw_vol.shape[0])\n",
        "\n",
        "    # --- Vesicle filtering (critical for presynapse determination) ---\n",
        "    vesicle_full_mask = (add_mask_vol == vesicle_label)\n",
        "    vesicle_mask = get_closest_component_mask(\n",
        "        vesicle_full_mask,\n",
        "        z_start, z_end,\n",
        "        y_start, y_end,\n",
        "        x_start, x_end,\n",
        "        (cx, cy, cz)\n",
        "    )\n",
        "\n",
        "    # --- Side masks ---\n",
        "    def create_segment_masks(segmentation_volume, s1_coord, s2_coord):\n",
        "        x1, y1, z1 = s1_coord\n",
        "        x2, y2, z2 = s2_coord\n",
        "        seg_id_1 = segmentation_volume[z1, y1, x1]\n",
        "        seg_id_2 = segmentation_volume[z2, y2, x2]\n",
        "        mask_1 = (segmentation_volume == seg_id_1) if seg_id_1 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
        "        mask_2 = (segmentation_volume == seg_id_2) if seg_id_2 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
        "        return mask_1, mask_2\n",
        "\n",
        "    mask_1_full, mask_2_full = create_segment_masks(seg_vol, side1_coord, side2_coord)\n",
        "\n",
        "    # --- Determine pre-synapse side using filtered vesicles ---\n",
        "    overlap_side1 = np.sum(np.logical_and(mask_1_full, vesicle_mask))\n",
        "    overlap_side2 = np.sum(np.logical_and(mask_2_full, vesicle_mask))\n",
        "    presynapse_side = 1 if overlap_side1 > overlap_side2 else 2\n",
        "    # print(f\"overlap_side1={overlap_side1}_overlap_side2={overlap_side2}_side1_coord:{side1_coord}_side1_coord:{side2_coord}\")\n",
        "    # --- Segmentation type handling ---\n",
        "    if segmentation_type == 0: # Raw data\n",
        "        combined_mask_full = np.ones_like(add_mask_vol, dtype=bool)\n",
        "    elif segmentation_type == 1:  # Presynapse\n",
        "        combined_mask_full = mask_1_full if presynapse_side == 1 else mask_2_full\n",
        "    elif segmentation_type == 2:  # Postsynapse\n",
        "        combined_mask_full = mask_2_full if presynapse_side == 1 else mask_1_full\n",
        "    elif segmentation_type == 3:  # Both sides\n",
        "        combined_mask_full = np.logical_or(mask_1_full, mask_2_full)\n",
        "    elif segmentation_type == 4:  # Vesicles + Cleft (closest only)\n",
        "        vesicle_closest = get_closest_component_mask(\n",
        "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        cleft_closest = get_closest_component_mask(\n",
        "            ((add_mask_vol == cleft_label)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        cleft_closest2 = get_closest_component_mask(\n",
        "            ((add_mask_vol == cleft_label2)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        combined_mask_full = np.logical_or(vesicle_closest, np.logical_or(cleft_closest,cleft_closest2))\n",
        "    elif segmentation_type == 5:  # (closest vesicles/cleft + sides)\n",
        "        vesicle_closest = get_closest_component_mask(\n",
        "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        cleft_closest = get_closest_component_mask(\n",
        "            (add_mask_vol == cleft_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        combined_mask_extra = np.logical_or(vesicle_closest, cleft_closest)\n",
        "        combined_mask_full = np.logical_or(mask_1_full, np.logical_or(mask_2_full, combined_mask_extra))\n",
        "    elif segmentation_type == 6:  # Vesicle cloud (closest)\n",
        "        combined_mask_full = get_closest_component_mask(\n",
        "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "    elif segmentation_type == 7:  # Cleft (closest)\n",
        "        cleft_closest = get_closest_component_mask(\n",
        "            ((add_mask_vol == cleft_label)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        cleft_closest2 = get_closest_component_mask(\n",
        "            ((add_mask_vol == cleft_label2)), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        combined_mask_full =  np.logical_or(cleft_closest,cleft_closest2)\n",
        "    elif segmentation_type == 8:  # Mitochondria (closest)\n",
        "        combined_mask_full = get_closest_component_mask(\n",
        "            (add_mask_vol == mito_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "    elif segmentation_type == 10:  #  +Cleft +pre\n",
        "        # vesicle_closest = get_closest_component_mask(\n",
        "        #     (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        # )\n",
        "        cleft_closest = get_closest_component_mask(\n",
        "            (add_mask_vol == cleft_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        pre_mask_full = mask_1_full if presynapse_side == 1 else mask_2_full\n",
        "\n",
        "        combined_mask_full = np.logical_or(cleft_closest,pre_mask_full)\n",
        "\n",
        "    elif segmentation_type == 9:  # cleft+vesicle\n",
        "        vesicle_closest = get_closest_component_mask(\n",
        "            (add_mask_vol == vesicle_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        cleft_closest = get_closest_component_mask(\n",
        "            (add_mask_vol == cleft_label), z_start, z_end, y_start, y_end, x_start, x_end, (cx, cy, cz)\n",
        "        )\n",
        "        # pre_mask_full = mask_1_full if presynapse_side == 1 else mask_2_full\n",
        "\n",
        "        combined_mask_full = np.logical_or(cleft_closest,vesicle_closest)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported segmentation type: {segmentation_type}\")\n",
        "\n",
        "    # --- Subvolume extraction and processing ---\n",
        "    sub_raw = raw_vol[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_combined_mask = combined_mask_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "\n",
        "    # Padding if needed\n",
        "    pad_z = subvolume_size - sub_raw.shape[0]\n",
        "    pad_y = subvolume_size - sub_raw.shape[1]\n",
        "    pad_x = subvolume_size - sub_raw.shape[2]\n",
        "    if pad_z > 0 or pad_y > 0 or pad_x > 0:\n",
        "        sub_raw = np.pad(sub_raw, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=0)\n",
        "        sub_combined_mask = np.pad(sub_combined_mask, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=False)\n",
        "\n",
        "    sub_raw = sub_raw[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_combined_mask = sub_combined_mask[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "\n",
        "    # Vectorized normalization\n",
        "    sub_raw = sub_raw.astype(np.float32)\n",
        "    mins = np.min(sub_raw, axis=(1, 2), keepdims=True)\n",
        "    maxs = np.max(sub_raw, axis=(1, 2), keepdims=True)\n",
        "    ranges = np.where(maxs > mins, maxs - mins, 1.0)\n",
        "    normalized = (sub_raw - mins) / ranges\n",
        "\n",
        "    # Define gray color (0.5 for grayscale)\n",
        "    gray_color = 0.6  # For grayscale\n",
        "\n",
        "    # Vectorized blending with gray color\n",
        "    raw_rgb = np.repeat(normalized[..., np.newaxis], 3, axis=-1)  # Convert to RGB\n",
        "    mask_factor = sub_combined_mask[..., np.newaxis]  # Adding an extra dimension to make it (80, 80, 80, 1)\n",
        "\n",
        "    # Blend only when alpha is less than 1\n",
        "    if alpha < 1:\n",
        "        blended_part = alpha * gray_color + (1 - alpha) * raw_rgb  # Blend with gray\n",
        "    else:\n",
        "        # When alpha is 1, apply gray only to unmasked areas (grayscale), keep raw_rgb in masked areas\n",
        "        blended_part = gray_color * (1 - mask_factor) + raw_rgb * mask_factor\n",
        "\n",
        "    # Now, overlaid_image will be computed as follows\n",
        "    overlaid_image = raw_rgb * mask_factor + (1 - mask_factor) * blended_part\n",
        "\n",
        "    # Convert to uint8 and transpose dimensions\n",
        "    overlaid_cube = np.transpose(overlaid_image, (1, 2, 3, 0))  # Keep it grayscale\n",
        "\n",
        "    return overlaid_cube\n",
        "\n",
        "class SynapseDataset(Dataset):\n",
        "    def __init__(self, vol_data_dict: dict, synapse_df: pd.DataFrame, processor,\n",
        "                 segmentation_type: int, subvol_size: int = 80, num_frames: int = 16,\n",
        "                 alpha: float = 0.3):\n",
        "        self.vol_data_dict = vol_data_dict\n",
        "        self.synapse_df = synapse_df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.segmentation_type = segmentation_type\n",
        "        self.subvol_size = subvol_size\n",
        "        self.num_frames = num_frames\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.synapse_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        syn_info = self.synapse_df.iloc[idx]\n",
        "        bbox_name = syn_info['bbox_name']\n",
        "        raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
        "        if raw_vol is None:\n",
        "            return torch.zeros((self.num_frames, 1, self.subvol_size, self.subvol_size), dtype=torch.float32), syn_info, bbox_name\n",
        "\n",
        "        central_coord = (int(syn_info['central_coord_1']), int(syn_info['central_coord_2']), int(syn_info['central_coord_3']))\n",
        "        side1_coord = (int(syn_info['side_1_coord_1']), int(syn_info['side_1_coord_2']), int(syn_info['side_1_coord_3']))\n",
        "        side2_coord = (int(syn_info['side_2_coord_1']), int(syn_info['side_2_coord_2']), int(syn_info['side_2_coord_3']))\n",
        "\n",
        "        overlaid_cube = create_segmented_cube(\n",
        "            raw_vol=raw_vol,\n",
        "            seg_vol=seg_vol,\n",
        "            add_mask_vol=add_mask_vol,\n",
        "            central_coord=central_coord,\n",
        "            side1_coord=side1_coord,\n",
        "            side2_coord=side2_coord,\n",
        "            segmentation_type=self.segmentation_type,\n",
        "            subvolume_size=self.subvol_size,\n",
        "            alpha=self.alpha,\n",
        "            bbox_name=bbox_name,  # Pass bbox_name here\n",
        "        )\n",
        "        frames = [overlaid_cube[..., z] for z in range(overlaid_cube.shape[3])]\n",
        "        if len(frames) < self.num_frames:\n",
        "            frames += [frames[-1]] * (self.num_frames - len(frames))\n",
        "        elif len(frames) > self.num_frames:\n",
        "            indices = np.linspace(0, len(frames)-1, self.num_frames, dtype=int)\n",
        "            frames = [frames[i] for i in indices]\n",
        "\n",
        "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
        "        return inputs[\"pixel_values\"].squeeze(0).float(), syn_info, bbox_name\n",
        "\n",
        "# Add unique IDs to fixed_samples\n",
        "fixed_samples = [\n",
        "    {\"id\": 1, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_004\", \"slice_number\": 25},\n",
        "    # {\"id\": 2, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_050\", \"slice_number\": 39},\n",
        "    {\"id\": 2, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_006\", \"slice_number\": 40},\n",
        "    {\"id\": 4, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-28_Cora_Wolter_031\", \"slice_number\": 43},\n",
        "    {\"id\": 3, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-28_Cora_Wolter_051\", \"slice_number\": 28},\n",
        "    # {\"id\": 4, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-28_Cora_Wolter_051\", \"slice_number\": 28},\n",
        "    # bbox3__5_193\n",
        "    # {\"id\": 5, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_035\", \"slice_number\": 35},\n",
        "    {\"id\": 5, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_036\", \"slice_number\": 41},\n",
        "    {\"id\": 6, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_018\", \"slice_number\": 41},\n",
        "    {\"id\": 7, \"bbox_name\": \"bbox4\", \"Var1\": \"explorative_2024-08-03_Ali_Karimi_023\", \"slice_number\": 28},\n",
        "    {\"id\": 8, \"bbox_name\": \"bbox5\", \"Var1\": \"non_spine_synapse_033\", \"slice_number\": 48},\n",
        "    {\"id\": 9, \"bbox_name\": \"bbox5\", \"Var1\": \"non_spine_synapse_045\", \"slice_number\": 40},\n",
        "    {\"id\": 10, \"bbox_name\": \"bbox6\", \"Var1\": \"spine_synapse_070\", \"slice_number\": 37},\n",
        "    {\"id\": 11, \"bbox_name\": \"bbox6\", \"Var1\": \"spine_synapse_021\", \"slice_number\": 30},\n",
        "    {\"id\": 12, \"bbox_name\": \"bbox7\", \"Var1\": \"non_spine_synapse_013\", \"slice_number\": 25},\n",
        "]\n",
        "\n",
        "# bbox4_explorative_2024-08-03_Ali_Karimi_023_5_237"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5LgD5ff1KY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo6hFTwOpMj8"
      },
      "source": [
        "#Iterate all over data and generate report (Extract Features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y--WYGnuD56"
      },
      "source": [
        "## VGG Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "psRXBoJwpNx0"
      },
      "outputs": [],
      "source": [
        "# import imageio\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from scipy import ndimage\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def visualize_sample_attention(model, dataset, sample_idx=0, output_dir=\"attention_gifs\", layer_index=30):\n",
        "#     \"\"\"\n",
        "#     Visualize attention for a specific sample from your dataset\n",
        "#     Returns GIF path and metadata for the visualized sample\n",
        "#     \"\"\"\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model = model.to(device).eval()\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#     # Get sample from your dataset\n",
        "#     pixel_values, syn_info, bbox_name = dataset[sample_idx]\n",
        "\n",
        "#     # Convert to model input format\n",
        "#     input_tensor = pixel_values.permute(1, 0, 2, 3).unsqueeze(0).to(device)  # [1, C, D, H, W]\n",
        "\n",
        "#     # Setup activation hook\n",
        "#     activation = {}\n",
        "#     def get_activation(name):\n",
        "#         def hook(model, input, output):\n",
        "#             activation[name] = output.detach()\n",
        "#         return hook\n",
        "\n",
        "#     hook = model.features[layer_index].register_forward_hook(get_activation('conv'))\n",
        "\n",
        "#     # Forward pass\n",
        "#     with torch.no_grad():\n",
        "#         _ = model.features(input_tensor)\n",
        "\n",
        "#     hook.remove()\n",
        "\n",
        "#     # Process activations\n",
        "#     activations = activation['conv'][0].cpu().numpy()  # [C, D, H, W]\n",
        "#     attention_map = np.mean(activations, axis=0)  # Average across channels\n",
        "#     attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())\n",
        "\n",
        "#     # Get original data from dataset\n",
        "#     original_vol = pixel_values.numpy().transpose(1, 0, 2, 3)  # [C, D, H, W]\n",
        "\n",
        "#     # Resize attention map to match original volume if needed\n",
        "#     if attention_map.shape != original_vol.shape[1:]:\n",
        "#         zoom_factors = [\n",
        "#             original_vol.shape[1]/attention_map.shape[0],\n",
        "#             original_vol.shape[2]/attention_map.shape[1],\n",
        "#             original_vol.shape[3]/attention_map.shape[2]\n",
        "#         ]\n",
        "#         attention_map = ndimage.zoom(attention_map, zoom_factors, order=1)\n",
        "\n",
        "#     # Create overlay frames\n",
        "#     frames = []\n",
        "#     for z in range(original_vol.shape[1]):\n",
        "#         fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "#         # Original slice\n",
        "#         ax[0].imshow(original_vol[0, z], cmap='gray')\n",
        "#         ax[0].set_title(f'Original Slice Z{z}\\n{bbox_name}')\n",
        "#         ax[0].axis('off')\n",
        "\n",
        "#         # Overlay attention\n",
        "#         ax[1].imshow(original_vol[0, z], cmap='gray')\n",
        "#         im = ax[1].imshow(attention_map[z], cmap='jet', alpha=0.5)\n",
        "#         plt.colorbar(im, ax=ax[1], fraction=0.046, pad=0.04)\n",
        "#         ax[1].set_title(f'Attention Map (Layer {layer_index})\\n{syn_info[\"Var1\"]}')\n",
        "#         ax[1].axis('off')\n",
        "\n",
        "#         # Save frame\n",
        "#         fig.canvas.draw()\n",
        "#         frame = np.array(fig.canvas.renderer._renderer)\n",
        "#         frames.append(frame)\n",
        "#         plt.close(fig)\n",
        "\n",
        "#     # Save GIF with metadata in filename\n",
        "#     gif_name = f\"{bbox_name}_syn{syn_info['Var1']}_layer{layer_index}.gif\"\n",
        "#     gif_path = os.path.join(output_dir, gif_name)\n",
        "#     imageio.mimsave(gif_path, frames, duration=0.2)\n",
        "\n",
        "#     return gif_path, syn_info\n",
        "\n",
        "\n",
        "# def visualize_multiple_samples(model, dataset, num_samples=5, layer_index=33):\n",
        "#     \"\"\"Visualize attention for multiple random samples with layer index\"\"\"\n",
        "#     results = []\n",
        "#     for _ in tqdm(range(num_samples)):\n",
        "#         sample_idx = np.random.randint(0, len(dataset))\n",
        "#         gif_path, syn_info = visualize_sample_attention(\n",
        "#             model, dataset, sample_idx, layer_index=layer_index\n",
        "#         )\n",
        "#         results.append((gif_path, syn_info))\n",
        "#     return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHrHcEqmquz8",
        "outputId": "b19c3d17-64bc-4314-a42d-eb9a79c8e403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded VGG3D checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-f26335547575>:133: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class Vgg3D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=(80, 80, 80),\n",
        "        fmaps=24,\n",
        "        downsample_factors=[(2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)],\n",
        "        fmap_inc=(2, 2, 2, 2),\n",
        "        n_convolutions=(4, 2, 2, 2),\n",
        "        output_classes=7,\n",
        "        input_fmaps=1,\n",
        "    ):\n",
        "        super(Vgg3D, self).__init__()\n",
        "\n",
        "        # Validate input parameters\n",
        "        if len(downsample_factors) != len(fmap_inc):\n",
        "            raise ValueError(\"fmap_inc needs to have same length as downsample factors\")\n",
        "        if len(n_convolutions) != len(fmap_inc):\n",
        "            raise ValueError(\"n_convolutions needs to have the same length as downsample factors\")\n",
        "        if np.any(np.array(n_convolutions) < 1):\n",
        "            raise ValueError(\"Each layer must have at least one convolution\")\n",
        "\n",
        "        current_fmaps = input_fmaps\n",
        "        current_size = np.array(input_size)\n",
        "\n",
        "        # Feature extraction layers\n",
        "        layers = []\n",
        "        for i, (df, nc) in enumerate(zip(downsample_factors, n_convolutions)):\n",
        "            # Convolution block\n",
        "            layers += [\n",
        "                nn.Conv3d(current_fmaps, fmaps, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm3d(fmaps),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "\n",
        "            # Additional convolutions\n",
        "            for _ in range(nc - 1):\n",
        "                layers += [\n",
        "                    nn.Conv3d(fmaps, fmaps, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm3d(fmaps),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                ]\n",
        "\n",
        "            # Downsampling\n",
        "            layers.append(nn.MaxPool3d(df))\n",
        "\n",
        "            # Update feature map size\n",
        "            current_fmaps = fmaps\n",
        "            fmaps *= fmap_inc[i]\n",
        "\n",
        "            # Update spatial dimensions\n",
        "            current_size = np.floor(current_size / np.array(df))\n",
        "            # logger.info(f\"Block {i+1}: features {current_fmaps}, size {current_size}\")\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        # Classifier (not used for feature extraction)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(current_size)) * current_fmaps, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, output_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        x = self.features(x)\n",
        "        if return_features:\n",
        "            return x  # Return raw features before flattening\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "def extract_features(model, dataset, args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=2,\n",
        "        num_workers=2,\n",
        "        collate_fn=lambda b: (\n",
        "            torch.stack([item[0] for item in b]),  # Pixel values\n",
        "            [item[1] for item in b],               # Synapse info\n",
        "            [item[2] for item in b]                # Bbox names\n",
        "        )\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    metadata = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            pixels, info, names = batch\n",
        "            inputs = pixels.permute(0, 2, 1, 3, 4).to(device)  # Reshape for 3D convolution\n",
        "\n",
        "            batch_features = model.features(inputs)\n",
        "            pooled_features = nn.AdaptiveAvgPool3d((1, 1, 1))(batch_features)\n",
        "\n",
        "            # Flatten and convert to numpy immediately\n",
        "            features.append(pooled_features.cpu().numpy().squeeze())\n",
        "            metadata.extend(zip(names, info))\n",
        "\n",
        "    # Combine all batch features\n",
        "    features = np.concatenate(features, axis=0)\n",
        "\n",
        "    # Create metadata DataFrame\n",
        "    metadata_df = pd.DataFrame([\n",
        "        {\"bbox\": name, **info.to_dict()}\n",
        "        for name, info in metadata\n",
        "    ])\n",
        "\n",
        "    # Create feature columns\n",
        "    feature_columns = [f'feat_{i+1}' for i in range(features.shape[1])]\n",
        "    features_df = pd.DataFrame(features, columns=feature_columns)\n",
        "\n",
        "    # Combine with metadata\n",
        "    combined_df = pd.concat([metadata_df, features_df], axis=1)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# Load model from checkpoint\n",
        "def load_model_from_checkpoint(model, checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    # Load the state_dict into the model\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # If the checkpoint includes the optimizer state, you can load that as well\n",
        "    # model.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  # if needed\n",
        "\n",
        "    # Set the model to evaluation mode (disable dropout, batch norm updates, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Paths and directories\n",
        "checkpoint_url = \"https://dl.dropboxusercontent.com/scl/fo/mfejaomhu43aa6oqs6zsf/AKMAAgT7OrUtruR0AQXZBy0/hemibrain_production.checkpoint.20220225?rlkey=6cmwxdvehy4ylztvsbgkfnrfc&dl=0\"\n",
        "checkpoint_path = 'hemibrain_production.checkpoint'\n",
        "\n",
        "# Download the checkpoint if it doesn't exist\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    os.system(f\"wget -O {checkpoint_path} '{checkpoint_url}'\")\n",
        "    print(\"Downloaded VGG3D checkpoint.\")\n",
        "else:\n",
        "    print(\"VGG3D checkpoint already exists.\")\n",
        "\n",
        "model = Vgg3D(input_size=(80, 80, 80), fmaps=24, output_classes=7, input_fmaps=1)\n",
        "model = load_model_from_checkpoint(model, 'hemibrain_production.checkpoint')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OaDat1oSq476"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def process_features(df):\n",
        "    feature_cols = [c for c in df.columns if c.startswith('feat_')]\n",
        "    features = df[feature_cols].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    return features_scaled\n",
        "\n",
        "def reduce_dimensions(features_scaled):\n",
        "\n",
        "    # Direct UMAP\n",
        "    umap_direct = umap.UMAP(n_components=2, random_state=42)\n",
        "    umap_direct_result = umap_direct.fit_transform(features_scaled)\n",
        "\n",
        "    return umap_direct_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgZqP3RDTugT"
      },
      "source": [
        "## Sample attention and stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "2uvpd_ab4Jzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec77ba4-f3ca-413f-9491-a12ea54d8389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _ConnectionBase.__del__ at 0x7e63139d5080>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 133, in __del__\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "Exception ignored in: <function _ConnectionBase.__del__ at 0x7e63139d5080>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 133, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ]
        }
      ],
      "source": [
        "!pip install kaleido\n",
        "import kaleido #required\n",
        "kaleido.__version__ #0.2.1\n",
        "\n",
        "import plotly\n",
        "plotly.__version__ #5.5.0\n",
        "\n",
        "#now this works:\n",
        "import plotly.graph_objects as go\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy import ndimage\n",
        "import umap\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from PIL import Image\n",
        "import io\n",
        "import plotly.io as pio\n",
        "\n",
        "def create_plots(features_df, seg_type, alpha, fixed_samples):\n",
        "    # Segmentation type descriptions\n",
        "    seg_type_descriptions = {\n",
        "        0: \"Raw data\",\n",
        "        1: \"Presynapse\",\n",
        "        2: \"Postsynapse\",\n",
        "        3: \"Both sides\",\n",
        "        4: \"Vesicles + Cleft (closest only)\",\n",
        "        5: \"(closest vesicles/cleft + sides)\",\n",
        "        6: \"Vesicle cloud (closest)\",\n",
        "        7: \"Cleft (closest)\",\n",
        "        8: \"Mitochondria (closest)\",\n",
        "        9: \"Vesicle + Cleft\",\n",
        "        10: \"Cleft + Pre\"\n",
        "    }\n",
        "\n",
        "    # Process features and compute UMAP\n",
        "    feature_cols = [c for c in features_df.columns if c.startswith('feat_')]\n",
        "    features = features_df[feature_cols].values\n",
        "    features_scaled = StandardScaler().fit_transform(features)\n",
        "\n",
        "    # Compute UMAP only once\n",
        "    reducer = umap.UMAP(random_state=42)\n",
        "    umap_results = reducer.fit_transform(features_scaled)\n",
        "\n",
        "    # Add UMAP coordinates to DataFrame\n",
        "    features_df['umap_x'] = umap_results[:, 0]\n",
        "    features_df['umap_y'] = umap_results[:, 1]\n",
        "\n",
        "    # Fetch the description for the given seg_type\n",
        "    seg_description = seg_type_descriptions.get(seg_type, \"Unknown segmentation type\")\n",
        "\n",
        "    # Create Plotly figure\n",
        "    color_mapping = {\n",
        "        'bbox1': '#FF0000', 'bbox2': '#00FFFF', 'bbox3': '#FFA500',\n",
        "        'bbox4': '#800080', 'bbox5': '#808080', 'bbox6': '#0000FF', 'bbox7': '#000000'\n",
        "    }\n",
        "    fig = px.scatter(\n",
        "        features_df.reset_index(),  # Reset index to make it available as a column\n",
        "        x='umap_x',\n",
        "        y='umap_y',\n",
        "        color='bbox_name',\n",
        "        title=f\"VGG Segmentation Type {seg_type} ({seg_description}) (α={alpha})\",\n",
        "        color_discrete_map=color_mapping,\n",
        "        hover_data=['index', 'bbox_name'],  # Show index and bbox in hover\n",
        "        labels={'color': 'BBox'}\n",
        "    )\n",
        "\n",
        "    # Use pandas merge for batch annotations\n",
        "    # Add cross markers for fixed samples\n",
        "    fixed_samples_df = pd.DataFrame(fixed_samples)\n",
        "    merged_df = features_df.reset_index().merge(fixed_samples_df, on=['Var1', 'bbox_name'])\n",
        "\n",
        "    # Add X markers\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=merged_df['umap_x'],\n",
        "            y=merged_df['umap_y'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                symbol='x',\n",
        "                color='black',\n",
        "                size=10,\n",
        "                line=dict(width=2)\n",
        "            ),\n",
        "            name='Selected Samples',\n",
        "            hoverinfo='none'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add annotations\n",
        "    for _, row in merged_df.iterrows():\n",
        "        fig.add_annotation(\n",
        "            x=row['umap_x'],\n",
        "            y=row['umap_y'],\n",
        "            text=str(row['id']),\n",
        "            showarrow=True,\n",
        "            font=dict(color='black', size=30),\n",
        "            arrowhead=2,\n",
        "            arrowsize=1,\n",
        "            arrowcolor='black',\n",
        "            ax=20,\n",
        "            ay=-30,\n",
        "            axref='pixel',\n",
        "            ayref='pixel',\n",
        "            xshift=10,\n",
        "            yshift=10,\n",
        "            bordercolor='white',\n",
        "            borderwidth=1\n",
        "        )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def extract_features(model, dataset, args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=32,\n",
        "        num_workers=8,  # Increase number of workers for faster data loading\n",
        "        collate_fn=lambda b: (\n",
        "            torch.stack([item[0] for item in b]),  # Pixel values\n",
        "            [item[1] for item in b],               # Synapse info\n",
        "            [item[2] for item in b]                # Bbox names\n",
        "        )\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    metadata = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            pixels, info, names = batch\n",
        "            inputs = pixels.permute(0, 2, 1, 3, 4).to(device)  # Reshape for 3D convolution\n",
        "\n",
        "            batch_features = model.features(inputs)\n",
        "            pooled_features = nn.AdaptiveAvgPool3d((1, 1, 1))(batch_features)\n",
        "\n",
        "            # Flatten and convert to numpy immediately\n",
        "            pooled_features = pooled_features.view(pooled_features.size(0), -1).cpu().numpy()\n",
        "            features.append(pooled_features)  # Collecting features\n",
        "\n",
        "            metadata.extend(zip(names, info))\n",
        "\n",
        "    # Combine all batch features\n",
        "    features = np.concatenate(features, axis=0)\n",
        "\n",
        "    # Create metadata DataFrame\n",
        "    metadata_df = pd.DataFrame([\n",
        "        {\"bbox\": name, **info.to_dict()}\n",
        "        for name, info in metadata\n",
        "    ])\n",
        "\n",
        "    # Create feature columns\n",
        "    feature_columns = [f'feat_{i+1}' for i in range(features.shape[1])]\n",
        "    features_df = pd.DataFrame(features, columns=feature_columns)\n",
        "\n",
        "    # Combine with metadata\n",
        "    combined_df = pd.concat([metadata_df, features_df], axis=1)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "args = parse_args()\n",
        "args.bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
        "# args.bbox_name=['bbox4']\n",
        "\n",
        "# Load volumes\n",
        "vol_data_dict = {}\n",
        "for bbox_name in args.bbox_name:\n",
        "    raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "        bbox_name=bbox_name,\n",
        "        raw_base_dir=args.raw_base_dir,\n",
        "        seg_base_dir=args.seg_base_dir,\n",
        "        add_mask_base_dir=args.add_mask_base_dir\n",
        "    )\n",
        "    if raw_vol is not None:\n",
        "        vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "\n",
        "# Load synapse data\n",
        "syn_df = pd.concat([\n",
        "    pd.read_excel(os.path.join(args.excel_file, f\"{bbox}.xlsx\")).assign(bbox_name=bbox)\n",
        "    for bbox in args.bbox_name if os.path.exists(os.path.join(args.excel_file, f\"{bbox}.xlsx\"))\n",
        "])\n",
        "\n",
        "# Initialize model\n",
        "processor = Synapse3DProcessor(size=args.size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Bk2ZowxMzF"
      },
      "source": [
        "## Run (sepearate each insetead of all in pdf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def extract_and_save_features(model, dataset, args, seg_type, alpha, output_dir):\n",
        "    # Extract features from the dataset\n",
        "    features_df = extract_features(model, dataset, args)\n",
        "\n",
        "    # Prepare the filename for CSV\n",
        "    csv_filename = f\"features_seg{seg_type}_alpha{str(alpha).replace('.', '_')}.csv\"\n",
        "    csv_filepath = os.path.join(output_dir, csv_filename)\n",
        "\n",
        "    # Save the features to CSV\n",
        "    features_df.to_csv(csv_filepath, index=False)\n",
        "    print(f\"Features for SegType {seg_type} and Alpha {alpha} saved to {csv_filepath}\")\n",
        "\n",
        "\n",
        "    # Copy the CSV file to the target directory on Google Drive\n",
        "    os.makedirs('/content/drive/MyDrive/csv10', exist_ok=True)\n",
        "    shutil.copy(csv_filepath, '/content/drive/MyDrive/csv10')\n",
        "    print(f\"CSV file copied to Google Drive directory: {'/content/drive/MyDrive/csv10'}\")\n",
        "\n",
        "    return csv_filepath\n"
      ],
      "metadata": {
        "id": "ehqnOHvr1Mln"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "class SynapseDataset2(Dataset):\n",
        "    def __init__(self, vol_data_dict: dict, synapse_df: pd.DataFrame, processor,\n",
        "                 segmentation_type: int, subvol_size: int = 80, num_frames: int = 16,\n",
        "                 alpha: float = 0.3, fixed_samples=None):\n",
        "        self.vol_data_dict = vol_data_dict\n",
        "\n",
        "        # Filter the synapse_df to include only fixed samples\n",
        "        if fixed_samples:\n",
        "            # Merge fixed_samples with synapse_df to only keep rows that are in fixed_samples\n",
        "            fixed_samples_df = pd.DataFrame(fixed_samples)\n",
        "            self.synapse_df = synapse_df.merge(fixed_samples_df, on=['Var1', 'bbox_name'], how='inner')\n",
        "        else:\n",
        "            self.synapse_df = synapse_df.reset_index(drop=True)\n",
        "\n",
        "        self.processor = processor\n",
        "        self.segmentation_type = segmentation_type\n",
        "        self.subvol_size = subvol_size\n",
        "        self.num_frames = num_frames\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.synapse_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        syn_info = self.synapse_df.iloc[idx]\n",
        "        bbox_name = syn_info['bbox_name']\n",
        "        raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
        "        if raw_vol is None:\n",
        "            return torch.zeros((self.num_frames, 1, self.subvol_size, self.subvol_size), dtype=torch.float32), syn_info, bbox_name\n",
        "\n",
        "        central_coord = (int(syn_info['central_coord_1']), int(syn_info['central_coord_2']), int(syn_info['central_coord_3']))\n",
        "        side1_coord = (int(syn_info['side_1_coord_1']), int(syn_info['side_1_coord_2']), int(syn_info['side_1_coord_3']))\n",
        "        side2_coord = (int(syn_info['side_2_coord_1']), int(syn_info['side_2_coord_2']), int(syn_info['side_2_coord_3']))\n",
        "\n",
        "        overlaid_cube = create_segmented_cube(\n",
        "            raw_vol=raw_vol,\n",
        "            seg_vol=seg_vol,\n",
        "            add_mask_vol=add_mask_vol,\n",
        "            central_coord=central_coord,\n",
        "            side1_coord=side1_coord,\n",
        "            side2_coord=side2_coord,\n",
        "            segmentation_type=self.segmentation_type,\n",
        "            subvolume_size=self.subvol_size,\n",
        "            alpha=self.alpha,\n",
        "            bbox_name=bbox_name,  # Pass bbox_name here\n",
        "        )\n",
        "        frames = [overlaid_cube[..., z] for z in range(overlaid_cube.shape[3])]\n",
        "        if len(frames) < self.num_frames:\n",
        "            frames += [frames[-1]] * (self.num_frames - len(frames))\n",
        "        elif len(frames) > self.num_frames:\n",
        "            indices = np.linspace(0, len(frames)-1, self.num_frames, dtype=int)\n",
        "            frames = [frames[i] for i in indices]\n",
        "\n",
        "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
        "        return inputs[\"pixel_values\"].squeeze(0).float(), syn_info, bbox_name\n",
        "\n",
        "    # Segmentation type descriptions\n",
        "seg_type_descriptions = {\n",
        "    0: \"Raw data\",\n",
        "    1: \"Presynapse\",\n",
        "    2: \"Postsynapse\",\n",
        "    3: \"Both sides\",\n",
        "    4: \"Vesicles + Cleft (closest only)\",\n",
        "    5: \"(closest vesicles/cleft + sides)\",\n",
        "    6: \"Vesicle cloud (closest)\",\n",
        "    7: \"Cleft (closest)\",\n",
        "    8: \"Mitochondria (closest)\",\n",
        "    9: \"Vesicle + Cleft\",\n",
        "    10: \"Cleft + Pre\"\n",
        "}\n",
        "\n",
        "def run_full_analysis(args, vol_data_dict, syn_df, processor, model):\n",
        "    output_dir = args.csv_output_dir  # Directory to save CSVs\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Generate images for each seg_type and alpha\n",
        "    for seg_type in(9,1,10):  # Assuming seg_type 0 and 1\n",
        "        for alpha in [1,0.5]:\n",
        "            print(f\"\\nProcessing segmentation_type={seg_type}, alpha={alpha}\")\n",
        "\n",
        "            # Create dataset for the current seg_type and alpha\n",
        "            current_dataset = SynapseDataset(\n",
        "                vol_data_dict=vol_data_dict,\n",
        "                synapse_df=syn_df,\n",
        "                processor=processor,\n",
        "                segmentation_type=seg_type,\n",
        "                subvol_size=args.subvol_size,\n",
        "                num_frames=args.num_frames,\n",
        "                alpha=alpha\n",
        "            )\n",
        "\n",
        "            # Extract features and save to CSV\n",
        "            csv_filepath = extract_and_save_features(model, current_dataset, args, seg_type, alpha, output_dir)\n",
        "\n",
        "            # Load features from the CSV file (for remaining operations)\n",
        "            features_df = pd.read_csv(csv_filepath)\n",
        "\n",
        "            # Create main figure with layout\n",
        "            fig = plt.figure(figsize=(20, 12))\n",
        "            gs = fig.add_gridspec(1, 2, width_ratios=[4, 6])\n",
        "\n",
        "            # Left panel: Image grid (adjust rows/cols if needed)\n",
        "            left_gs = gs[0].subgridspec(4, 3)  # 4 rows, 3 cols for 12 images\n",
        "            axes = left_gs.subplots()\n",
        "            fixed_dataset =SynapseDataset2(\n",
        "                vol_data_dict=vol_data_dict,\n",
        "                synapse_df=syn_df,\n",
        "                processor=processor,\n",
        "                segmentation_type=seg_type,\n",
        "                subvol_size=args.subvol_size,\n",
        "                num_frames=args.num_frames,\n",
        "                alpha=alpha,\n",
        "                fixed_samples=fixed_samples  # Pass fixed_samples here\n",
        "            )\n",
        "            seg_description = seg_type_descriptions.get(seg_type, \"Unknown segmentation type\")\n",
        "            # Plot sample images\n",
        "            var1_bbox_to_index = {(syn_info[\"Var1\"], bbox): idx\n",
        "                                    for idx, (_, syn_info, bbox) in enumerate(fixed_dataset)}\n",
        "\n",
        "            for ax, sample in zip(axes.flat, fixed_samples):\n",
        "                key = (sample[\"Var1\"], sample[\"bbox_name\"])\n",
        "                if key not in var1_bbox_to_index:\n",
        "                    ax.axis('off')\n",
        "                    continue\n",
        "                idx = var1_bbox_to_index[key]\n",
        "                pixel_values, syn_info, bbox_name = fixed_dataset[idx]\n",
        "                original_vol = pixel_values.numpy().transpose(1, 0, 2, 3)\n",
        "                z = sample[\"slice_number\"]\n",
        "                bb = sample[\"bbox_name\"]\n",
        "\n",
        "                # If the whole slice is gray, it might have the same pixel value across all of it.\n",
        "                # Normalize or adjust for proper visualization\n",
        "                img = original_vol[0, z]\n",
        "\n",
        "                # Ensure the image is within a visible range for imshow\n",
        "                img = np.clip(img, 0, 1)  # Clip the image values to [0, 1]\n",
        "\n",
        "                # Set the min and max for display to make sure it's visible\n",
        "                ax.imshow(img, cmap='gray', vmin=0, vmax=1)  # Adjust vmin and vmax for proper display\n",
        "                ax.set_title(f\"ID {sample['id']}: {bb}\", fontsize=20)\n",
        "                ax.axis('off')\n",
        "\n",
        "            # Right panel: UMAP\n",
        "            umap_ax = fig.add_subplot(gs[1])\n",
        "            umap_fig = create_plots(features_df, seg_type, alpha, fixed_samples)\n",
        "            img_bytes = umap_fig.to_image(format=\"png\", width=1200, height=900)\n",
        "            img = Image.open(io.BytesIO(img_bytes))\n",
        "            umap_ax.imshow(img)\n",
        "            umap_ax.set_title(f\"VGG Segmentation -UMAP- Type {seg_type} ({seg_description}) (α={alpha})\", fontsize=22)\n",
        "            umap_ax.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save as PNG\n",
        "            alpha_str = str(alpha).replace('.', '_')\n",
        "            filename = f\"seg{seg_type}_alpha{alpha_str}.png\"\n",
        "            fig.savefig(filename, bbox_inches='tight', dpi=300)\n",
        "            plt.close(fig)\n",
        "\n",
        "            # Copy image to target directory\n",
        "            target_dir = '/content/drive/MyDrive/analysis_images10'  # Adjust path as needed\n",
        "            os.makedirs(target_dir, exist_ok=True)\n",
        "            shutil.copy(filename, target_dir)\n",
        "            print(f\"Image {filename} copied to {target_dir}\")\n",
        "run_full_analysis(args, vol_data_dict, syn_df, processor, model)\n"
      ],
      "metadata": {
        "id": "70OZjrUKGqN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FinalWithCSV just fixed"
      ],
      "metadata": {
        "id": "xUzbBLct5jTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "class SynapseDataset(Dataset):\n",
        "    def __init__(self, vol_data_dict: dict, synapse_df: pd.DataFrame, processor,\n",
        "                 segmentation_type: int, subvol_size: int = 80, num_frames: int = 16,\n",
        "                 alpha: float = 0.3, fixed_samples=None):\n",
        "        self.vol_data_dict = vol_data_dict\n",
        "\n",
        "        # Filter the synapse_df to include only fixed samples\n",
        "        if fixed_samples:\n",
        "            # Merge fixed_samples with synapse_df to only keep rows that are in fixed_samples\n",
        "            fixed_samples_df = pd.DataFrame(fixed_samples)\n",
        "            self.synapse_df = synapse_df.merge(fixed_samples_df, on=['Var1', 'bbox_name'], how='inner')\n",
        "        else:\n",
        "            self.synapse_df = synapse_df.reset_index(drop=True)\n",
        "\n",
        "        self.processor = processor\n",
        "        self.segmentation_type = segmentation_type\n",
        "        self.subvol_size = subvol_size\n",
        "        self.num_frames = num_frames\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.synapse_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        syn_info = self.synapse_df.iloc[idx]\n",
        "        bbox_name = syn_info['bbox_name']\n",
        "        raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
        "        if raw_vol is None:\n",
        "            return torch.zeros((self.num_frames, 3, self.subvol_size, self.subvol_size), dtype=torch.float32), syn_info, bbox_name\n",
        "\n",
        "        central_coord = (int(syn_info['central_coord_1']), int(syn_info['central_coord_2']), int(syn_info['central_coord_3']))\n",
        "        side1_coord = (int(syn_info['side_1_coord_1']), int(syn_info['side_1_coord_2']), int(syn_info['side_1_coord_3']))\n",
        "        side2_coord = (int(syn_info['side_2_coord_1']), int(syn_info['side_2_coord_2']), int(syn_info['side_2_coord_3']))\n",
        "\n",
        "        overlaid_cube = create_segmented_cube(\n",
        "            raw_vol=raw_vol,\n",
        "            seg_vol=seg_vol,\n",
        "            add_mask_vol=add_mask_vol,\n",
        "            central_coord=central_coord,\n",
        "            side1_coord=side1_coord,\n",
        "            side2_coord=side2_coord,\n",
        "            segmentation_type=self.segmentation_type,\n",
        "            subvolume_size=self.subvol_size,\n",
        "            alpha=self.alpha,\n",
        "            bbox_name=bbox_name,  # Pass bbox_name here\n",
        "        )\n",
        "        frames = [overlaid_cube[..., z] for z in range(overlaid_cube.shape[3])]\n",
        "        if len(frames) < self.num_frames:\n",
        "            frames += [frames[-1]] * (self.num_frames - len(frames))\n",
        "        elif len(frames) > self.num_frames:\n",
        "            indices = np.linspace(0, len(frames)-1, self.num_frames, dtype=int)\n",
        "            frames = [frames[i] for i in indices]\n",
        "\n",
        "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
        "        return inputs[\"pixel_values\"].squeeze(0).float(), syn_info, bbox_name\n",
        "def run_full_analysis(args, vol_data_dict, syn_df, processor):\n",
        "    output_dir ='csv2' # Directory to save CSVs\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Generate images for each seg_type and alpha\n",
        "    for seg_type in(1,9,10,11):  # Assuming seg_type 0 and 1\n",
        "        for alpha in [1]:\n",
        "            print(f\"\\nProcessing segmentation_type={seg_type}, alpha={alpha}\")\n",
        "\n",
        "            # Create dataset for the current seg_type and alpha\n",
        "            current_dataset = SynapseDataset(\n",
        "                vol_data_dict=vol_data_dict,\n",
        "                synapse_df=syn_df,\n",
        "                processor=processor,\n",
        "                segmentation_type=seg_type,\n",
        "                subvol_size=args.subvol_size,\n",
        "                num_frames=args.num_frames,\n",
        "                alpha=alpha,\n",
        "                fixed_samples=fixed_samples  # Pass fixed_samples here\n",
        "            )\n",
        "\n",
        "            # Extract features and save to CSV\n",
        "            # csv_filepath = extract_and_save_features(model, current_dataset, args, seg_type, alpha, output_dir)\n",
        "            csv_filename = f\"/content/drive/MyDrive/csv/features_seg{seg_type}_alpha{str(alpha).replace('.', '_')}.csv\"\n",
        "\n",
        "            # Load features from the CSV file (for remaining operations)\n",
        "            features_df = pd.read_csv(csv_filename)\n",
        "\n",
        "            # Create main figure with layout\n",
        "            fig = plt.figure(figsize=(20, 12))\n",
        "            gs = fig.add_gridspec(1, 2, width_ratios=[4, 6])\n",
        "\n",
        "            # Left panel: Image grid (adjust rows/cols if needed)\n",
        "            left_gs = gs[0].subgridspec(4, 3)  # 4 rows, 3 cols for 12 images\n",
        "            axes = left_gs.subplots()\n",
        "\n",
        "            # Plot sample images\n",
        "            var1_bbox_to_index = {(syn_info[\"Var1\"], bbox): idx\n",
        "                                for idx, (_, syn_info, bbox) in enumerate(current_dataset)}\n",
        "\n",
        "            for ax, sample in zip(axes.flat, fixed_samples):\n",
        "                key = (sample[\"Var1\"], sample[\"bbox_name\"])\n",
        "                if key not in var1_bbox_to_index:\n",
        "                    ax.axis('off')\n",
        "                    continue\n",
        "                idx = var1_bbox_to_index[key]\n",
        "                pixel_values, syn_info, bbox_name = current_dataset[idx]\n",
        "                original_vol = pixel_values.numpy().transpose(1, 0, 2, 3)\n",
        "                z = sample[\"slice_number\"]\n",
        "                bb = sample[\"bbox_name\"]\n",
        "                ax.imshow(original_vol[0, z], cmap='gray')\n",
        "                ax.set_title(f\"ID {sample['id']}: {bb}\", fontsize=20)\n",
        "                ax.axis('off')\n",
        "\n",
        "            # Right panel: UMAP\n",
        "            umap_ax = fig.add_subplot(gs[1])\n",
        "            umap_fig = create_plots(features_df, seg_type, alpha, fixed_samples)\n",
        "            img_bytes = umap_fig.to_image(format=\"png\", width=1200, height=900)\n",
        "            img = Image.open(io.BytesIO(img_bytes))\n",
        "            umap_ax.imshow(img)\n",
        "            umap_ax.set_title(f\"UMAP Projection\\nSegType {seg_type}, Alpha {alpha}\", fontsize=22)\n",
        "            umap_ax.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save as PNG\n",
        "            alpha_str = str(alpha).replace('.', '_')\n",
        "            filename = f\"seg{seg_type}_alpha{alpha_str}.png\"\n",
        "            fig.savefig(filename, bbox_inches='tight', dpi=300)\n",
        "            plt.close(fig)\n",
        "\n",
        "            # Copy image to target directory\n",
        "            target_dir = '/content/drive/MyDrive/analysis_images7'  # Adjust path as needed\n",
        "            os.makedirs(target_dir, exist_ok=True)\n",
        "            shutil.copy(filename, target_dir)\n",
        "            print(f\"Image {filename} copied to {target_dir}\")\n",
        "run_full_analysis(args, vol_data_dict, syn_df, processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "Ixkduszp5MxO",
        "outputId": "eb065aec-a0bc-4373-ad9e-7bcba7383957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing segmentation_type=1, alpha=1\n",
            "bbox_num3\n",
            "bbox_num3\n",
            "bbox_num3\n",
            "bbox_num3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shutil' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1093ebe7e00c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image {filename} copied to {target_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mrun_full_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-1093ebe7e00c>\u001b[0m in \u001b[0;36mrun_full_analysis\u001b[0;34m(args, vol_data_dict, syn_df, processor)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mtarget_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/analysis_images7'\u001b[0m  \u001b[0;31m# Adjust path as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image {filename} copied to {target_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mrun_full_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FinalWithCSV"
      ],
      "metadata": {
        "id": "Z3qge84l5x-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# def run_full_analysis(args, vol_data_dict, syn_df, processor):\n",
        "#     output_dir ='csv2' # Directory to save CSVs\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#     # Generate images for each seg_type and alpha\n",
        "#     for seg_type in range(0,9):  # Assuming seg_type 0 and 1\n",
        "#         for alpha in [0.5,1]:\n",
        "#             print(f\"\\nProcessing segmentation_type={seg_type}, alpha={alpha}\")\n",
        "\n",
        "#             # Create dataset for the current seg_type and alpha\n",
        "#             current_dataset = SynapseDataset(\n",
        "#                 vol_data_dict=vol_data_dict,\n",
        "#                 synapse_df=syn_df,\n",
        "#                 processor=processor,\n",
        "#                 segmentation_type=seg_type,\n",
        "#                 subvol_size=args.subvol_size,\n",
        "#                 num_frames=args.num_frames,\n",
        "#                 alpha=alpha\n",
        "#             )\n",
        "\n",
        "#             # Extract features and save to CSV\n",
        "#             # csv_filepath = extract_and_save_features(model, current_dataset, args, seg_type, alpha, output_dir)\n",
        "#             csv_filename = f\"/content/drive/MyDrive/csv/features_seg{seg_type}_alpha{str(alpha).replace('.', '_')}.csv\"\n",
        "\n",
        "#             # Load features from the CSV file (for remaining operations)\n",
        "#             features_df = pd.read_csv(csv_filename)\n",
        "\n",
        "#             # Create main figure with layout\n",
        "#             fig = plt.figure(figsize=(20, 12))\n",
        "#             gs = fig.add_gridspec(1, 2, width_ratios=[4, 6])\n",
        "\n",
        "#             # Left panel: Image grid (adjust rows/cols if needed)\n",
        "#             left_gs = gs[0].subgridspec(4, 3)  # 4 rows, 3 cols for 12 images\n",
        "#             axes = left_gs.subplots()\n",
        "\n",
        "#             # Plot sample images\n",
        "#             var1_bbox_to_index = {(syn_info[\"Var1\"], bbox): idx\n",
        "#                                 for idx, (_, syn_info, bbox) in enumerate(current_dataset)}\n",
        "\n",
        "#             for ax, sample in zip(axes.flat, fixed_samples):\n",
        "#                 key = (sample[\"Var1\"], sample[\"bbox_name\"])\n",
        "#                 if key not in var1_bbox_to_index:\n",
        "#                     ax.axis('off')\n",
        "#                     continue\n",
        "#                 idx = var1_bbox_to_index[key]\n",
        "#                 pixel_values, syn_info, bbox_name = current_dataset[idx]\n",
        "#                 original_vol = pixel_values.numpy().transpose(1, 0, 2, 3)\n",
        "#                 z = sample[\"slice_number\"]\n",
        "#                 bb = sample[\"bbox_name\"]\n",
        "#                 ax.imshow(original_vol[0, z], cmap='gray')\n",
        "#                 ax.set_title(f\"ID {sample['id']}: {bb}\", fontsize=20)\n",
        "#                 ax.axis('off')\n",
        "\n",
        "#             # Right panel: UMAP\n",
        "#             umap_ax = fig.add_subplot(gs[1])\n",
        "#             umap_fig = create_plots(features_df, seg_type, alpha, fixed_samples)\n",
        "#             img_bytes = umap_fig.to_image(format=\"png\", width=1200, height=900)\n",
        "#             img = Image.open(io.BytesIO(img_bytes))\n",
        "#             umap_ax.imshow(img)\n",
        "#             umap_ax.set_title(f\"UMAP Projection\\nSegType {seg_type}, Alpha {alpha}\", fontsize=22)\n",
        "#             umap_ax.axis('off')\n",
        "\n",
        "#             plt.tight_layout()\n",
        "\n",
        "#             # Save as PNG\n",
        "#             alpha_str = str(alpha).replace('.', '_')\n",
        "#             filename = f\"seg{seg_type}_alpha{alpha_str}.png\"\n",
        "#             fig.savefig(filename, bbox_inches='tight', dpi=300)\n",
        "#             plt.close(fig)\n",
        "\n",
        "#             # Copy image to target directory\n",
        "#             target_dir = '/content/drive/MyDrive/analysis_images4'  # Adjust path as needed\n",
        "#             os.makedirs(target_dir, exist_ok=True)\n",
        "#             shutil.copy(filename, target_dir)\n",
        "#             print(f\"Image {filename} copied to {target_dir}\")\n",
        "# run_full_analysis(args, vol_data_dict, syn_df, processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gg8hPTmT5zxQ",
        "outputId": "4010757f-7b69-4352-eeb9-1d28d9fc8c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing segmentation_type=0, alpha=0.5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image seg0_alpha0_5.png copied to /content/drive/MyDrive/analysis_images4\n",
            "\n",
            "Processing segmentation_type=0, alpha=1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image seg0_alpha1.png copied to /content/drive/MyDrive/analysis_images4\n",
            "\n",
            "Processing segmentation_type=1, alpha=0.5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image seg1_alpha0_5.png copied to /content/drive/MyDrive/analysis_images4\n",
            "\n",
            "Processing segmentation_type=1, alpha=1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image seg1_alpha1.png copied to /content/drive/MyDrive/analysis_images4\n",
            "\n",
            "Processing segmentation_type=2, alpha=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image seg2_alpha0_5.png copied to /content/drive/MyDrive/analysis_images4\n",
            "\n",
            "Processing segmentation_type=2, alpha=1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-42f211a69e2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image {filename} copied to {target_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mrun_full_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-42f211a69e2b>\u001b[0m in \u001b[0;36mrun_full_analysis\u001b[0;34m(args, vol_data_dict, syn_df, processor)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Plot sample images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             var1_bbox_to_index = {(syn_info[\"Var1\"], bbox): idx\n\u001b[0m\u001b[1;32m     41\u001b[0m                                 for idx, (_, syn_info, bbox) in enumerate(current_dataset)}\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-42f211a69e2b>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Plot sample images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             var1_bbox_to_index = {(syn_info[\"Var1\"], bbox): idx\n\u001b[0m\u001b[1;32m     41\u001b[0m                                 for idx, (_, syn_info, bbox) in enumerate(current_dataset)}\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-32f564561147>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mside2_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'side_2_coord_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'side_2_coord_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'side_2_coord_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         overlaid_cube = create_segmented_cube(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mraw_vol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_vol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mseg_vol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_vol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-32f564561147>\u001b[0m in \u001b[0;36mcreate_segmented_cube\u001b[0;34m(raw_vol, seg_vol, add_mask_vol, central_coord, side1_coord, side2_coord, segmentation_type, subvolume_size, alpha, bbox_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# --- Determine pre-synapse side using filtered vesicles ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0moverlap_side1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_1_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvesicle_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0moverlap_side2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_2_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvesicle_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mpresynapse_side\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moverlap_side1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moverlap_side2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2314\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create sample gifs"
      ],
      "metadata": {
        "id": "j6KKdQrMFPK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gifs"
      ],
      "metadata": {
        "id": "YO6qPCL5T_1A"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbox_name=['bbox3']\n",
        "# bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Synapse Dataset\")\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='')\n",
        "    parser.add_argument('--bbox_name', type=str, default=['bbox4'], nargs='+')\n",
        "    parser.add_argument('--excel_file', type=str, default='')\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
        "    parser.add_argument('--size', type=tuple, default=(80, 80))\n",
        "    parser.add_argument('--subvol_size', type=int, default=80)\n",
        "    parser.add_argument('--num_frames', type=int, default=80)\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
        "    parser.add_argument('--alpha', type=float, default=0.7)\n",
        "    parser.add_argument('--segmentation_type', type=int, default=4, choices=range(0, 13),\n",
        "                        help='Type of segmentation overlay')\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "args = parse_args()\n",
        "# args.bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
        "args.bbox_name=bbox_name\n",
        "args.segmentation_type=5\n",
        "# Load volumes\n",
        "vol_data_dict = {}\n",
        "for bbox_name in args.bbox_name:\n",
        "    raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "        bbox_name=bbox_name,\n",
        "        raw_base_dir=args.raw_base_dir,\n",
        "        seg_base_dir=args.seg_base_dir,\n",
        "        add_mask_base_dir=args.add_mask_base_dir\n",
        "    )\n",
        "    if raw_vol is not None:\n",
        "        vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "\n",
        "# Load synapse data\n",
        "syn_df = pd.concat([\n",
        "    pd.read_excel(os.path.join(args.excel_file, f\"{bbox}.xlsx\")).assign(bbox_name=bbox)\n",
        "    for bbox in args.bbox_name if os.path.exists(os.path.join(args.excel_file, f\"{bbox}.xlsx\"))\n",
        "])\n",
        "\n",
        "# Initialize model\n",
        "processor = Synapse3DProcessor(size=args.size)\n",
        "\n",
        "\n",
        "            # Create dataset and features\n",
        "dataset = SynapseDataset(\n",
        "    vol_data_dict=vol_data_dict,\n",
        "    synapse_df=syn_df,\n",
        "    processor=processor,\n",
        "    segmentation_type=args.segmentation_type,\n",
        "    subvol_size=args.subvol_size,\n",
        "    num_frames=args.num_frames,\n",
        "    alpha=0.5\n",
        ")\n",
        "\n",
        "# Add unique IDs to fixed_samples\n",
        "fixed_samples = [\n",
        "    {\"id\": 1, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_004\", \"slice_number\": 25},\n",
        "    # {\"id\": 2, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_050\", \"slice_number\": 39},\n",
        "    {\"id\": 2, \"bbox_name\": \"bbox1\", \"Var1\": \"non_spine_synapse_006\", \"slice_number\": 40},\n",
        "    # bbox1__5_52.gif\n",
        "    {\"id\": 3, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-29_Vera_Broens_085\", \"slice_number\": 33},\n",
        "    {\"id\": 4, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-28_Cora_Wolter_031\", \"slice_number\": 43},\n",
        "    # bbox3__5_193\n",
        "    # {\"id\": 5, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_035\", \"slice_number\": 35},\n",
        "    {\"id\": 5, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_036\", \"slice_number\": 41},\n",
        "    {\"id\": 6, \"bbox_name\": \"bbox3\", \"Var1\": \"non_spine_synapse_018\", \"slice_number\": 41},\n",
        "    {\"id\": 7, \"bbox_name\": \"bbox4\", \"Var1\": \"explorative_2024-08-03_Ali_Karimi_022_5_238\", \"slice_number\": 56},\n",
        "    {\"id\": 8, \"bbox_name\": \"bbox5\", \"Var1\": \"non_spine_synapse_033\", \"slice_number\": 48},\n",
        "    {\"id\": 9, \"bbox_name\": \"bbox5\", \"Var1\": \"non_spine_synapse_045\", \"slice_number\": 40},\n",
        "    {\"id\": 10, \"bbox_name\": \"bbox6\", \"Var1\": \"spine_synapse_070\", \"slice_number\": 37},\n",
        "    {\"id\": 11, \"bbox_name\": \"bbox6\", \"Var1\": \"spine_synapse_021\", \"slice_number\": 30},\n",
        "    {\"id\": 12, \"bbox_name\": \"bbox7\", \"Var1\": \"non_spine_synapse_013\", \"slice_number\": 25},\n",
        "]\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import imageio\n",
        "    # {\"id\": 3, \"bbox_name\": \"bbox2\", \"Var1\": \"explorative_2024-08-29_Vera_Broens_085\", \"slice_number\": 33},\n",
        "\n",
        "# فرض بر این است که 'var1' و 'bboxnumber' قبلاً به طور صحیح تعریف شده‌اند\n",
        "var1 = 'non_spine_synapse_018'  # جایگزین با مقدار واقعی\n",
        "bboxnumber = 'bbox3'  # جایگزین با مقدار واقعی\n",
        "\n",
        "# فیلتر کردن داده‌ها بر اساس مقادیر var1 و bbox_name\n",
        "specific_sample = syn_df[(syn_df['Var1'] == var1) & (syn_df['bbox_name'] == bboxnumber)]\n",
        "\n",
        "# بررسی اینکه آیا نمونه‌ای پیدا شده است یا خیر\n",
        "if not specific_sample.empty:\n",
        "    found = False\n",
        "    for idx, (pixel_values, syn_info, bbox_name) in enumerate(dataset):\n",
        "        if bbox_name == bboxnumber and var1 == syn_info['Var1']:  # فرض بر این است که syn_info حاوی اطلاعات var1 است\n",
        "            print(f\"Found matching sample at index {idx}\")\n",
        "\n",
        "            denormalized_cube = pixel_values * torch.tensor([0.229]) + torch.tensor([0.485])  # دنوورمالیزه کردن\n",
        "            denormalized_cube = torch.clamp(denormalized_cube, 0, 1)  # محدود کردن مقادیر به بازه معتبر\n",
        "            frames = denormalized_cube.squeeze(1).numpy()  # تبدیل به آرایه NumPy\n",
        "            # frames = (frames * 255).astype(np.uint8)  # تبدیل به فرمت uint8\n",
        "            # frames = np.stack([frames, frames, frames], axis=-1)  # ساخت فریم‌های RGB\n",
        "            Gif_Name = f\"{bbox_name}_{var1}_{args.segmentation_type}_{idx}\"\n",
        "            output_gif_path = os.path.join(args.save_gifs_dir, f\"{Gif_Name}.gif\")\n",
        "            imageio.mimsave(output_gif_path, frames, fps=10)  # ذخیره به صورت GIF با 10 FPS\n",
        "\n",
        "            print(f\"GIF saved at {output_gif_path}\")\n",
        "            found = True\n",
        "            break  # زمانی که نمونه پیدا شد، حلقه تمام می‌شود\n",
        "\n",
        "    if not found:\n",
        "        print(f\"No matching sample found in dataset for Var1={var1} and bbox_name={bboxnumber}\")\n",
        "\n",
        "else:\n",
        "    print(f\"No sample found in syn_df with Var1={var1} and bbox_name={bboxnumber}\")\n"
      ],
      "metadata": {
        "id": "mC58V49nMDqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481012d7-623d-4ca7-8bd7-ed5649c6022c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found matching sample at index 52\n",
            "GIF saved at gifs/bbox3_non_spine_synapse_018_5_52.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "specific_sample"
      ],
      "metadata": {
        "id": "PW4zVecmtzOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcUulgOSIVAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering Section"
      ],
      "metadata": {
        "id": "2cXwGNTCNrES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cluster find_closest_samples_in_clusters and Plot TSNE"
      ],
      "metadata": {
        "id": "YefBuS0XLO7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
        "import imageio\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
        "\n",
        "\n",
        "bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Synapse Dataset\")\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='')\n",
        "    parser.add_argument('--bbox_name', type=str, default=['bbox4'], nargs='+')\n",
        "    parser.add_argument('--excel_file', type=str, default='')\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
        "    parser.add_argument('--size', type=tuple, default=(80, 80))\n",
        "    parser.add_argument('--subvol_size', type=int, default=80)\n",
        "    parser.add_argument('--num_frames', type=int, default=80)\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
        "    parser.add_argument('--alpha', type=float, default=0.5)\n",
        "    parser.add_argument('--segmentation_type', type=int, default=4, choices=range(0, 13),\n",
        "                        help='Type of segmentation overlay')\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "args = parse_args()\n",
        "# args.bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
        "args.bbox_name=bbox_name\n",
        "args.segmentation_type=5\n",
        "# Load volumes\n",
        "vol_data_dict = {}\n",
        "for bbox_name in args.bbox_name:\n",
        "    raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "        bbox_name=bbox_name,\n",
        "        raw_base_dir=args.raw_base_dir,\n",
        "        seg_base_dir=args.seg_base_dir,\n",
        "        add_mask_base_dir=args.add_mask_base_dir\n",
        "    )\n",
        "    if raw_vol is not None:\n",
        "        vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "\n",
        "# Load synapse data\n",
        "syn_df = pd.concat([\n",
        "    pd.read_excel(os.path.join(args.excel_file, f\"{bbox}.xlsx\")).assign(bbox_name=bbox)\n",
        "    for bbox in args.bbox_name if os.path.exists(os.path.join(args.excel_file, f\"{bbox}.xlsx\"))\n",
        "])\n",
        "\n",
        "# Initialize model\n",
        "processor = Synapse3DProcessor(size=args.size)\n",
        "\n",
        "\n",
        "            # Create dataset and features\n",
        "dataset = SynapseDataset(\n",
        "    vol_data_dict=vol_data_dict,\n",
        "    synapse_df=syn_df,\n",
        "    processor=processor,\n",
        "    segmentation_type=args.segmentation_type,\n",
        "    subvol_size=args.subvol_size,\n",
        "    num_frames=args.num_frames,\n",
        "    alpha=0.3\n",
        ")\n",
        "\n",
        "# Function to load features and perform clustering\n",
        "def load_and_cluster_features(csv_filepath, n_clusters=5):\n",
        "    features_df = pd.read_csv(csv_filepath)\n",
        "\n",
        "    # Extract feature columns (assuming features start with 'feat_')\n",
        "    feature_cols = [col for col in features_df.columns if col.startswith('feat_')]\n",
        "    features = features_df[feature_cols].values\n",
        "\n",
        "    # Perform KMeans clustering\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    features_df['cluster'] = kmeans.fit_predict(features)\n",
        "\n",
        "    return features_df, kmeans, feature_cols\n",
        "\n",
        "# Function to find the closest 2 samples within each cluster\n",
        "def find_closest_samples_in_clusters(features_df, feature_cols, n_samples=2):\n",
        "    closest_samples = []\n",
        "\n",
        "    # For each cluster, find the closest 2 samples\n",
        "    for cluster_id in np.unique(features_df['cluster']):\n",
        "        cluster_samples = features_df[features_df['cluster'] == cluster_id]\n",
        "        cluster_features = cluster_samples[feature_cols].values\n",
        "\n",
        "        # Compute pairwise distances and select the closest pairs\n",
        "        distances = pairwise_distances_argmin_min(cluster_features, cluster_features)\n",
        "\n",
        "        # Select the closest pairs (2 closest samples)\n",
        "        # We assume that distances[0] gives the indices of closest samples within the cluster\n",
        "        for i, sample_idx in enumerate(distances[0][:n_samples]):\n",
        "            closest_samples.append(cluster_samples.iloc[sample_idx])\n",
        "\n",
        "    return closest_samples\n",
        "\n",
        "# Function to get the center slice of a 3D synapse sample\n",
        "def get_center_slice(sample):\n",
        "    \"\"\"\n",
        "    Extract the center slice from a 3D sample.\n",
        "    Assumes the sample is a 3D numpy array.\n",
        "    \"\"\"\n",
        "    # Get the center slice (middle slice in z-direction)\n",
        "    center_slice = sample[sample.shape[0] // 2, :, :]\n",
        "    return center_slice\n",
        "\n",
        "# Function to plot 4 similar samples in a grid for each synapse\n",
        "def plot_synapse_samples(dataset, closest_samples_indices, title='Synapse Samples'):\n",
        "    \"\"\"\n",
        "    Plots 4 sample images of synapses in a grid layout.\n",
        "    `dataset` is the dataset containing synapse 3D data.\n",
        "    `closest_samples_indices` is a list of indices for the samples to plot.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))  # 1 row, 4 columns\n",
        "\n",
        "    for i, sample_idx in enumerate(closest_samples_indices):\n",
        "        # Retrieve the synapse data (3D volume) from the dataset\n",
        "        pixel_values, syn_info, bbox_name = dataset[sample_idx]  # Assuming dataset[index] gives 3D data\n",
        "\n",
        "        # Get the center slice of the sample\n",
        "        center_slice = get_center_slice(pixel_values)\n",
        "        center_slice=center_slice.squeeze()\n",
        "        # Plot the slice\n",
        "        axes[i].imshow(center_slice, cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Sample {i+1}\\n({syn_info[\"bbox_name\"]})')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Function to find 4 closest samples from each cluster\n",
        "def find_closest_samples_in_clusters(features_df, feature_cols, n_samples=4):\n",
        "    closest_samples_per_cluster = {}\n",
        "\n",
        "    # For each cluster, find the closest 4 samples based on feature similarity\n",
        "    for cluster_id in np.unique(features_df['cluster']):\n",
        "        cluster_samples = features_df[features_df['cluster'] == cluster_id]\n",
        "        cluster_features = cluster_samples[feature_cols].values\n",
        "\n",
        "        # Compute pairwise distances and select the closest pairs\n",
        "        distances = pairwise_distances_argmin_min(cluster_features, cluster_features)\n",
        "\n",
        "        # Select the closest samples (4 closest samples)\n",
        "        closest_samples = []\n",
        "        for i, sample_idx in enumerate(distances[0][:n_samples]):\n",
        "            closest_samples.append(cluster_samples.iloc[sample_idx])\n",
        "\n",
        "        # Store the closest samples for each cluster\n",
        "        closest_samples_per_cluster[cluster_id] = closest_samples\n",
        "\n",
        "    return closest_samples_per_cluster\n",
        "color_mapping = {\n",
        "    'bbox1': '#FF0000', 'bbox2': '#00FFFF', 'bbox3': '#FFA500',\n",
        "    'bbox4': '#800080', 'bbox5': '#808080', 'bbox6': '#0000FF', 'bbox7': '#000000'\n",
        "}\n",
        "\n",
        "# Function to reduce features to 2D or 3D using t-SNE\n",
        "def apply_tsne(features_df, feature_cols, n_components=2):\n",
        "    features = features_df[feature_cols].values\n",
        "    tsne = TSNE(n_components=n_components, random_state=42)\n",
        "    tsne_results = tsne.fit_transform(features)\n",
        "    return tsne_results\n",
        "\n",
        "# Function to plot 2D and 3D t-SNE\n",
        "def plot_tsne(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping):\n",
        "    # 2D Plot colored by `bbox_name`\n",
        "    fig_2d = px.scatter(\n",
        "        features_df,\n",
        "        x=tsne_results_2d[:, 0],\n",
        "        y=tsne_results_2d[:, 1],\n",
        "        color=features_df['bbox_name'],\n",
        "        color_discrete_map=color_mapping,\n",
        "        labels={'x': 't-SNE 1', 'y': 't-SNE 2'},\n",
        "        title='2D t-SNE colored by bbox_name'\n",
        "    )\n",
        "    fig_2d.update_traces(marker=dict(size=4))  # Set the size of points to 2\n",
        "\n",
        "    fig_2d.show()\n",
        "\n",
        "    # 2D Plot colored by `cluster`\n",
        "    fig_2d_cluster = px.scatter(\n",
        "        features_df,\n",
        "        x=tsne_results_2d[:, 0],\n",
        "        y=tsne_results_2d[:, 1],\n",
        "        color=kmeans.labels_.astype(str),  # Color by cluster number\n",
        "        labels={'x': 't-SNE 1', 'y': 't-SNE 2'},\n",
        "        title='2D t-SNE colored by cluster'\n",
        "    )\n",
        "    fig_2d_cluster.update_traces(marker=dict(size=4))  # Set the size of points to 2\n",
        "\n",
        "    fig_2d_cluster.show()\n",
        "\n",
        "csv_files = [\n",
        "    # 'features_seg0_alpha0_5.csv', 'features_seg0_alpha1.csv',\n",
        "    'features_seg1_alpha0_5.csv', 'features_seg1_alpha1.csv',\n",
        "    # 'features_seg2_alpha0_5.csv', 'features_seg2_alpha1.csv',\n",
        "    # 'features_seg3_alpha0_5.csv', 'features_seg3_alpha1.csv',\n",
        "    # 'features_seg4_alpha0_5.csv', 'features_seg4_alpha1.csv',\n",
        "    # 'features_seg5_alpha0_5.csv', 'features_seg5_alpha1.csv',\n",
        "    # 'features_seg6_alpha0_5.csv', 'features_seg6_alpha1.csv',\n",
        "    # 'features_seg7_alpha0_5.csv', 'features_seg7_alpha1.csv',\n",
        "    # 'features_seg8_alpha0_5.csv', 'features_seg8_alpha1.csv',\n",
        "    'features_seg9_alpha0_5.csv', 'features_seg9_alpha1.csv',\n",
        "    'features_seg10_alpha0_5.csv', 'features_seg10_alpha1.csv',\n",
        "]\n",
        "\n",
        "# csv_files = [\n",
        "#      'features_seg1_alpha1.csv',\n",
        "# ]\n",
        "# Add this near your other imports\n",
        "from pathlib import Path\n",
        "\n",
        "# Modify your processing loop\n",
        "for csv_file in csv_files:\n",
        "    csv_filepath = os.path.join('/content/drive/MyDrive/csv10', csv_file)\n",
        "\n",
        "    print(f\"Processing {csv_file}\")\n",
        "\n",
        "    # Create output directory for this iteration\n",
        "    iteration_name = Path(csv_file).stem  # Remove .csv extension\n",
        "    output_dir = Path(\"clustering_results_final\") / iteration_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Step 1: Load and cluster features\n",
        "    n_clusters = 10\n",
        "    features_df, kmeans, feature_cols = load_and_cluster_features(csv_filepath, n_clusters)\n",
        "\n",
        "    # Save clustered features\n",
        "    features_df.to_csv(output_dir / \"clustered_features.csv\", index=False)\n",
        "\n",
        "    # Step 2: Apply t-SNE\n",
        "    tsne_results_2d = apply_tsne(features_df, feature_cols, 2)\n",
        "    tsne_results_3d = apply_tsne(features_df, feature_cols, 3)\n",
        "\n",
        "    # Step 3: Modified plotting function to save images\n",
        "    def save_tsne_plots(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping, output_dir):\n",
        "        # 2D Plot colored by bbox_name\n",
        "        fig_2d = px.scatter(\n",
        "            features_df,\n",
        "            x=tsne_results_2d[:, 0],\n",
        "            y=tsne_results_2d[:, 1],\n",
        "            color=features_df['bbox_name'],\n",
        "            color_discrete_map=color_mapping,\n",
        "            title='2D t-SNE colored by bbox_name'\n",
        "        )\n",
        "        fig_2d.update_traces(marker=dict(size=4))  # Set the size of points to 2\n",
        "\n",
        "        fig_2d.write_image(output_dir / \"tsne_2d_bbox.png\")\n",
        "\n",
        "        # 2D Plot colored by cluster\n",
        "        fig_cluster = px.scatter(\n",
        "            features_df,\n",
        "            x=tsne_results_2d[:, 0],\n",
        "            y=tsne_results_2d[:, 1],\n",
        "            color=kmeans.labels_.astype(str),\n",
        "            title='2D t-SNE colored by cluster'\n",
        "        )\n",
        "        fig_cluster.update_traces(marker=dict(size=4))  # Set the size of points to 2\n",
        "\n",
        "        fig_cluster.write_image(output_dir / \"tsne_2d_cluster.png\")\n",
        "\n",
        "        # 3D Plot\n",
        "        if tsne_results_3d is not None:\n",
        "            fig_3d = px.scatter_3d(\n",
        "                features_df,\n",
        "                x=tsne_results_3d[:, 0],\n",
        "                y=tsne_results_3d[:, 1],\n",
        "                z=tsne_results_3d[:, 2],\n",
        "                color=kmeans.labels_.astype(str),\n",
        "                title='3D t-SNE'\n",
        "            )\n",
        "            fig_cluster.update_traces(marker=dict(size=2))  # Set the size of points to 2\n",
        "\n",
        "            fig_3d.write_html(output_dir / \"tsne_3d.html\")\n",
        "\n",
        "\n",
        "    save_tsne_plots(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping, output_dir)\n",
        "\n",
        "    # Step 4: Find and save closest samples\n",
        "    closest_samples_per_cluster = find_closest_samples_in_clusters(features_df, feature_cols, 4)\n",
        "\n",
        "    # Modified plotting function to save samples\n",
        "    def save_cluster_samples(dataset, closest_samples_per_cluster, output_dir):\n",
        "        for cluster_id, samples in closest_samples_per_cluster.items():\n",
        "            fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
        "            for i, sample in enumerate(samples):\n",
        "                pixel_values, syn_info, bbox_name = dataset[sample.name]\n",
        "                center_slice = pixel_values[pixel_values.shape[0] // 2, :, :].squeeze()\n",
        "                axes[i].imshow(center_slice, cmap='gray')\n",
        "                axes[i].axis('off')\n",
        "                axes[i].set_title(f'Sample {i+1}\\n({syn_info[\"bbox_name\"]})')\n",
        "            plt.suptitle(f'Cluster {cluster_id} Samples')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(output_dir / f'cluster_{cluster_id}_samples.png')\n",
        "            plt.close()\n",
        "\n",
        "    save_cluster_samples(dataset, closest_samples_per_cluster, output_dir)\n",
        "\n",
        "    print(f\"Saved results to {output_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZaChzcYBLP28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f684390-2a5a-496a-cd48-dfe428b93261"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing features_seg1_alpha0_5.csv\n",
            "Saved results to clustering_results_final/features_seg1_alpha0_5\n",
            "Processing features_seg1_alpha1.csv\n",
            "Saved results to clustering_results_final/features_seg1_alpha1\n",
            "Processing features_seg9_alpha0_5.csv\n",
            "Saved results to clustering_results_final/features_seg9_alpha0_5\n",
            "Processing features_seg9_alpha1.csv\n",
            "Saved results to clustering_results_final/features_seg9_alpha1\n",
            "Processing features_seg10_alpha0_5.csv\n",
            "Saved results to clustering_results_final/features_seg10_alpha0_5\n",
            "Processing features_seg10_alpha1.csv\n",
            "Saved results to clustering_results_final/features_seg10_alpha1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Oq8CS9YtM4uf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-r-NnsLkM7rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "!zip -r /content/clustering_results_final.zip /content/clustering_results_final\n",
        "\n",
        "# Copy image to target directory\n",
        "target_dir = '/content/drive/MyDrive/analysis_images10'  # Adjust path as needed\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "shutil.copy('/content/clustering_results_final.zip', target_dir)\n"
      ],
      "metadata": {
        "id": "iYJqi8KvZ2SB",
        "outputId": "23a39b16-0bba-4a40-945d-60f0c16b7168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/clustering_results_final/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/tsne_2d_bbox.png (deflated 8%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_5_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_9_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_2_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_4_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_1_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/tsne_3d.html (deflated 70%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/clustered_features.csv (deflated 76%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/tsne_2d_cluster.png (deflated 6%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_6_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_7_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_3_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_8_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha0_5/cluster_0_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/tsne_2d_bbox.png (deflated 8%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_5_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_9_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_2_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_4_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_1_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/tsne_3d.html (deflated 70%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/clustered_features.csv (deflated 78%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/tsne_2d_cluster.png (deflated 8%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_6_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_7_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_3_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_8_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha1/cluster_0_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/tsne_2d_bbox.png (deflated 7%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_5_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_9_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_2_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_4_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_1_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/tsne_3d.html (deflated 70%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/clustered_features.csv (deflated 78%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/tsne_2d_cluster.png (deflated 6%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_6_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_7_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_3_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_8_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha1/cluster_0_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/tsne_2d_bbox.png (deflated 6%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_5_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_9_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_2_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_4_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_1_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/tsne_3d.html (deflated 70%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/clustered_features.csv (deflated 77%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/tsne_2d_cluster.png (deflated 6%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_6_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_7_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_3_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_8_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg10_alpha0_5/cluster_0_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/tsne_2d_bbox.png (deflated 7%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_5_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_9_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_2_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_4_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_1_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/tsne_3d.html (deflated 70%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/clustered_features.csv (deflated 77%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/tsne_2d_cluster.png (deflated 6%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_6_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_7_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_3_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_8_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg9_alpha1/cluster_0_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/ (stored 0%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/tsne_2d_bbox.png (deflated 7%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_5_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_9_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_2_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_4_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_1_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/tsne_3d.html (deflated 70%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/clustered_features.csv (deflated 77%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/tsne_2d_cluster.png (deflated 7%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_6_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_7_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_3_samples.png (deflated 12%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_8_samples.png (deflated 11%)\n",
            "  adding: content/clustering_results_final/features_seg1_alpha0_5/cluster_0_samples.png (deflated 12%)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filename' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-bb95cf3d507c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/clustering_results_final.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image {filename} copied to {target_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze clusters mask sizes"
      ],
      "metadata": {
        "id": "geNTT398Nz-1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQC89qLfke4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze clusters mask sizes"
      ],
      "metadata": {
        "id": "UzPfbj3hkfDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ves_sizes.zip /content\n",
        "!unzip ves_sizes.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1RZbQfS5aGO",
        "outputId": "6dd5af5e-fd6f-4a4c-a2d6-0550cd9e7b83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ves_sizes.zip\n",
            "   creating: content/csv_outputs/\n",
            "  inflating: content/csv_outputs/bbox2.csv  \n",
            "  inflating: content/csv_outputs/features_seg10_alpha1.csv  \n",
            "  inflating: content/csv_outputs/bbox5.csv  \n",
            "  inflating: content/csv_outputs/bbox6.csv  \n",
            "  inflating: content/csv_outputs/bbox7.csv  \n",
            "  inflating: content/csv_outputs/bbox3.csv  \n",
            "  inflating: content/csv_outputs/bbox4.csv  \n",
            "  inflating: content/csv_outputs/features_seg9_alpha1.csv  \n",
            "  inflating: content/csv_outputs/features_seg1_alpha0_5.csv  \n",
            "  inflating: content/csv_outputs/bbox1.csv  \n",
            "  inflating: content/csv_outputs/features_seg1_alpha1.csv  \n",
            "  inflating: content/csv_outputs/features_seg10_alpha0_5.csv  \n",
            "  inflating: content/csv_outputs/features_seg9_alpha0_5.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ace_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb0X74rdUwnI",
        "outputId": "28fad2a6-257c-4cef-b085-f0310c300fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ace_tools\n",
            "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
            "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
            "Installing collected packages: ace_tools\n",
            "Successfully installed ace_tools-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (existing imports and code)\n",
        "\n",
        "def get_vesicle_label(bbox_name):\n",
        "    \"\"\"Determine vesicle label based on bbox name.\"\"\"\n",
        "    bbox_num = bbox_name.replace(\"bbox\", \"\").strip()\n",
        "    if bbox_num in {'2', '5'}:\n",
        "        return 3\n",
        "    elif bbox_num == '7':\n",
        "        return 2\n",
        "    elif bbox_num == '4':\n",
        "        return 2\n",
        "    elif bbox_num == '3':\n",
        "        return 7\n",
        "    else:  # For bbox1, 6, etc.\n",
        "        return 6\n",
        "\n",
        "def calculate_vesicle_cloud_size(row, vol_data_dict, subvol_size):\n",
        "    \"\"\"Calculate the vesicle cloud mask size for a given synapse row.\"\"\"\n",
        "    bbox_name = row['bbox_name']\n",
        "    if bbox_name not in vol_data_dict:\n",
        "        return 0  # Handle missing data\n",
        "\n",
        "    add_mask_vol = vol_data_dict[bbox_name][2]  # Get vesicle segmentation volume\n",
        "    vesicle_label = get_vesicle_label(bbox_name)\n",
        "\n",
        "    # Extract coordinates from the dataframe (x, y, z)\n",
        "    cx, cy, cz = (\n",
        "        int(row['central_coord_1']),\n",
        "        int(row['central_coord_2']),\n",
        "        int(row['central_coord_3'])\n",
        "    )\n",
        "\n",
        "    # Calculate subvolume bounds\n",
        "    half_size = subvol_size // 2\n",
        "    x_start = max(cx - half_size, 0)\n",
        "    x_end = min(cx + half_size, add_mask_vol.shape[2])\n",
        "    y_start = max(cy - half_size, 0)\n",
        "    y_end = min(cy + half_size, add_mask_vol.shape[1])\n",
        "    z_start = max(cz - half_size, 0)\n",
        "    z_end = min(cz + half_size, add_mask_vol.shape[0])\n",
        "\n",
        "    # Generate full vesicle mask and find closest component\n",
        "    vesicle_full_mask = (add_mask_vol == vesicle_label)\n",
        "    vesicle_mask = get_closest_component_mask(\n",
        "        vesicle_full_mask,\n",
        "        z_start, z_end,\n",
        "        y_start, y_end,\n",
        "        x_start, x_end,\n",
        "        (cx, cy, cz)\n",
        "    )\n",
        "\n",
        "    return np.sum(vesicle_mask)  # Total pixels in the vesicle cloud\n",
        "\n",
        "# After loading the synapse dataframe (syn_df), add the following:\n",
        "\n",
        "# Compute vesicle cloud size for each synapse\n",
        "print(\"Calculating vesicle cloud sizes...\")\n",
        "syn_df['vesicle_cloud_size'] = syn_df.apply(\n",
        "    lambda row: calculate_vesicle_cloud_size(row, vol_data_dict, args.subvol_size),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(args.csv_output_dir, exist_ok=True)\n",
        "\n",
        "# Save each bbox's dataframe with the new column\n",
        "for bbox in args.bbox_name:\n",
        "    bbox_df = syn_df[syn_df['bbox_name'] == bbox]\n",
        "    if not bbox_df.empty:\n",
        "        output_path = os.path.join(args.csv_output_dir, f\"{bbox}.csv\")\n",
        "        bbox_df.to_csv(output_path, index=False)\n",
        "        print(f\"Saved {output_path} with vesicle cloud sizes.\")\n",
        "\n",
        "# ... (remaining existing code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "F8IuBUnWN2Ku",
        "outputId": "b9d3fcaf-ec89-4951-91ab-3dbab179b192"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating vesicle cloud sizes...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-4072be6b2991>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Compute vesicle cloud size for each synapse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating vesicle cloud sizes...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m syn_df['vesicle_cloud_size'] = syn_df.apply(\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcalculate_vesicle_cloud_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubvol_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-4072be6b2991>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating vesicle cloud sizes...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m syn_df['vesicle_cloud_size'] = syn_df.apply(\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcalculate_vesicle_cloud_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubvol_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-76-4072be6b2991>\u001b[0m in \u001b[0;36mcalculate_vesicle_cloud_size\u001b[0;34m(row, vol_data_dict, subvol_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Generate full vesicle mask and find closest component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mvesicle_full_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madd_mask_vol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvesicle_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     vesicle_mask = get_closest_component_mask(\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mvesicle_full_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mz_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-3b17d81ba1f8>\u001b[0m in \u001b[0;36mget_closest_component_mask\u001b[0;34m(full_mask, z_start, z_end, y_start, y_end, x_start, x_end, target_coord)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosest_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mfiltered_sub_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabeled_sub_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclosest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mcombined_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mcombined_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_end\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_sub_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mzeros_like\u001b[0;34m(a, dtype, order, subok, shape)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# needed instead of a 0 to get same result as zeros for string dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: zip this folder /content/results2\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "!zip -r /content/ves_sizes.zip /content/csv_outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--j6-ZUByDqy",
        "outputId": "71ff1fd3-4bd4-4f1e-dd16-252844fac1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/csv_outputs/ (stored 0%)\n",
            "  adding: content/csv_outputs/bbox2.csv (deflated 73%)\n",
            "  adding: content/csv_outputs/features_seg10_alpha1.csv (deflated 81%)\n",
            "  adding: content/csv_outputs/bbox5.csv (deflated 67%)\n",
            "  adding: content/csv_outputs/bbox6.csv (deflated 67%)\n",
            "  adding: content/csv_outputs/bbox7.csv (deflated 68%)\n",
            "  adding: content/csv_outputs/bbox3.csv (deflated 68%)\n",
            "  adding: content/csv_outputs/bbox4.csv (deflated 72%)\n",
            "  adding: content/csv_outputs/features_seg9_alpha1.csv (deflated 81%)\n",
            "  adding: content/csv_outputs/features_seg1_alpha0_5.csv (deflated 82%)\n",
            "  adding: content/csv_outputs/bbox1.csv (deflated 68%)\n",
            "  adding: content/csv_outputs/features_seg1_alpha1.csv (deflated 81%)\n",
            "  adding: content/csv_outputs/features_seg10_alpha0_5.csv (deflated 82%)\n",
            "  adding: content/csv_outputs/features_seg9_alpha0_5.csv (deflated 80%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "\n",
        "# Load the clustered features\n",
        "features_path = \"/content/clustering_results_presynapse/features_seg1_alpha1/clustered_features.csv\"\n",
        "features_df = pd.read_csv(features_path)\n",
        "\n",
        "# Load all bbox CSVs with vesicle cloud sizes\n",
        "bbox_csvs = glob('/content/content/csv_outputs/bbox*.csv')\n",
        "vesicle_df = pd.concat([pd.read_csv(f) for f in bbox_csvs])\n",
        "\n",
        "# Merge features with vesicle sizes on unique identifiers\n",
        "# Ensure the merge keys match your data's columns\n",
        "merged_df = pd.merge(\n",
        "    features_df,\n",
        "    vesicle_df[['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3', 'vesicle_cloud_size']],\n",
        "    on=['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3']\n",
        ")\n",
        "\n",
        "# Calculate cluster statistics\n",
        "cluster_stats = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "    mean_size='mean',\n",
        "    median_size='median',\n",
        "    std_size='std',\n",
        "    count='count'\n",
        ")\n",
        "print(\"Cluster Statistics:\")\n",
        "print(cluster_stats)\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from umap import UMAP\n",
        "import statsmodels.api as sm\n",
        "import shap\n",
        "import os\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "# Ensure the folder to save the HTML file exists\n",
        "os.makedirs('output_html', exist_ok=True)\n",
        "\n",
        "# Merge datasets using composite key\n",
        "merged_df = pd.merge(\n",
        "    features_df,\n",
        "    vesicle_df[['bbox_name', 'central_coord_1', 'central_coord_2',\n",
        "                'central_coord_3', 'vesicle_cloud_size']],\n",
        "    on=['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Create meaningful size categories\n",
        "merged_df['size_category'] = pd.qcut(merged_df['vesicle_cloud_size'],\n",
        "                                    q=4,\n",
        "                                    labels=['Small', 'Medium', 'Large', 'X-Large'])\n",
        "\n",
        "# 2. Plotting and Table Generation\n",
        "# Box Plot\n",
        "fig_box = px.box(\n",
        "    merged_df,\n",
        "    x='cluster',\n",
        "    y='vesicle_cloud_size',\n",
        "    color='cluster',\n",
        "    points=\"all\",\n",
        "    hover_data=['bbox_name'],\n",
        "    title=\"Vesicle Cloud Size Distribution by Cluster\"\n",
        ")\n",
        "\n",
        "# Add mean markers\n",
        "means = merged_df.groupby('cluster')['vesicle_cloud_size'].mean()\n",
        "fig_box.add_trace(go.Scatter(\n",
        "    x=means.index,\n",
        "    y=means.values,\n",
        "    mode='markers',\n",
        "    marker=dict(color='black', size=10, symbol='x'),\n",
        "    name='Mean'\n",
        "))\n",
        "\n",
        "# Violin Plot\n",
        "fig_violin = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    fig_violin.add_trace(go.Violin(\n",
        "        x=merged_df[merged_df['cluster'] == cluster]['cluster'],\n",
        "        y=merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True\n",
        "    ))\n",
        "\n",
        "# Statistical Summary Table\n",
        "stats_df = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "    Mean=np.mean,\n",
        "    Median=np.median,\n",
        "    Std=np.std,\n",
        "    Min=np.min,\n",
        "    Max=np.max,\n",
        "    Count='count'\n",
        ").reset_index()\n",
        "\n",
        "fig_table = go.Figure(data=[go.Table(\n",
        "    header=dict(values=stats_df.columns.tolist()),\n",
        "    cells=dict(values=stats_df.values.T))\n",
        "])\n",
        "\n",
        "# Enhanced Violin Plot with Distribution Metrics\n",
        "fig_enhanced_violin = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    cluster_data = merged_df[merged_df['cluster'] == cluster]\n",
        "\n",
        "    # Add violin plot\n",
        "    fig_enhanced_violin.add_trace(go.Violin(\n",
        "        x=cluster_data['cluster'],\n",
        "        y=cluster_data['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True,\n",
        "        points=\"all\",\n",
        "        pointpos=0,\n",
        "        jitter=0.05\n",
        "    ))\n",
        "\n",
        "    # Add statistical annotations\n",
        "    stats_text = (f\"Mean: {cluster_data['vesicle_cloud_size'].mean():.1f}<br>\"\n",
        "                  f\"Median: {cluster_data['vesicle_cloud_size'].median():.1f}<br>\"\n",
        "                  f\"SD: {cluster_data['vesicle_cloud_size'].std():.1f}\")\n",
        "\n",
        "    fig_enhanced_violin.add_annotation(\n",
        "        x=cluster,\n",
        "        y=cluster_data['vesicle_cloud_size'].max() * 1.1,\n",
        "        text=stats_text,\n",
        "        showarrow=False,\n",
        "        font=dict(size=9)\n",
        "    )\n",
        "\n",
        "# Statistical Comparison Matrix\n",
        "clusters = sorted(merged_df['cluster'].unique())\n",
        "effect_size_matrix = np.zeros((len(clusters), len(clusters)))\n",
        "\n",
        "for i, cluster1 in enumerate(clusters):\n",
        "    for j, cluster2 in enumerate(clusters):\n",
        "        if i != j:\n",
        "            data1 = merged_df[merged_df['cluster'] == cluster1]['vesicle_cloud_size']\n",
        "            data2 = merged_df[merged_df['cluster'] == cluster2]['vesicle_cloud_size']\n",
        "            effect_size = (data1.mean() - data2.mean()) / np.sqrt((data1.std()**2 + data2.std()**2)/2)\n",
        "            effect_size_matrix[i, j] = effect_size\n",
        "\n",
        "# Create heatmap for effect sizes\n",
        "fig_effect_size = go.Figure(data=go.Heatmap(\n",
        "    z=effect_size_matrix,\n",
        "    x=clusters,\n",
        "    y=clusters,\n",
        "    colorscale='RdBu',\n",
        "    zmid=0,\n",
        "    colorbar=dict(title=\"Cohen's d\"),\n",
        "    hoverongaps=False\n",
        "))\n",
        "\n",
        "# Add annotations for effect sizes\n",
        "annotations = []\n",
        "for i, cluster1 in enumerate(clusters):\n",
        "    for j, cluster2 in enumerate(clusters):\n",
        "        annotations.append(\n",
        "            dict(\n",
        "                x=cluster2,\n",
        "                y=cluster1,\n",
        "                text=f\"{effect_size_matrix[i, j]:.2f}\",\n",
        "                showarrow=False,\n",
        "                font=dict(color='white' if abs(effect_size_matrix[i, j]) > 0.5 else 'black')\n",
        "            )\n",
        "        )\n",
        "\n",
        "fig_effect_size.update_layout(\n",
        "    title=\"Pairwise Effect Size Comparison (Cohen's d)\",\n",
        "    xaxis_title=\"Cluster\",\n",
        "    yaxis_title=\"Cluster\",\n",
        "    annotations=annotations,\n",
        "    width=800,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Cumulative Distribution Plot\n",
        "fig_cdf = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    cluster_data = merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size']\n",
        "    hist, bin_edges = np.histogram(cluster_data, bins=50, density=True)\n",
        "    cdf = np.cumsum(hist * np.diff(bin_edges))\n",
        "\n",
        "    fig_cdf.add_trace(go.Scatter(\n",
        "        x=bin_edges[1:],\n",
        "        y=cdf,\n",
        "        mode='lines',\n",
        "        name=f'Cluster {cluster}',\n",
        "        opacity=0.7\n",
        "    ))\n",
        "\n",
        "# Topological Manifold Learning with UMAP\n",
        "umap_3d = UMAP(n_components=3, random_state=42)\n",
        "features = merged_df.filter(regex='feat_').values\n",
        "projection_3d = umap_3d.fit_transform(features)\n",
        "\n",
        "fig_umap = px.scatter_3d(\n",
        "    merged_df,\n",
        "    x=projection_3d[:,0],\n",
        "    y=projection_3d[:,1],\n",
        "    z=projection_3d[:,2],\n",
        "    color='cluster',\n",
        "    size='vesicle_cloud_size',\n",
        "    hover_data=['size_category'],\n",
        "    title=\"3D Topological Manifold with Cluster & Size Projection\",\n",
        "    opacity=0.7\n",
        ")\n",
        "fig_umap.update_layout(width=1200, height=800)\n",
        "\n",
        "# Bayesian Hierarchical Modeling\n",
        "mixed_model = sm.MixedLM.from_formula(\n",
        "    'vesicle_cloud_size ~ cluster',\n",
        "    groups=merged_df['bbox_name'],\n",
        "    data=merged_df\n",
        ").fit()\n",
        "\n",
        "# Advanced Distribution Comparison (Kernel Density Estimation)\n",
        "fig_kde = go.Figure()\n",
        "for cluster in clusters:\n",
        "    data = merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size']\n",
        "    kernel = gaussian_kde(data)\n",
        "    x = np.linspace(data.min(), data.max(), 100)\n",
        "    fig_kde.add_trace(go.Scatter(\n",
        "        x=x,\n",
        "        y=kernel(x),\n",
        "        mode='lines',\n",
        "        name=f'Cluster {cluster}',\n",
        "        fill='tozeroy'\n",
        "    ))\n",
        "\n",
        "# 3. Write everything to an HTML file\n",
        "html_filename = \"output_html/analysis_results.html\"\n",
        "with open(html_filename, 'w') as f:\n",
        "    f.write(\"<html><body><h1>Analysis Results</h1><hr>\")\n",
        "    f.write(\"<h2>Vesicle Cloud Size Distribution by Cluster</h2>\")\n",
        "    f.write(fig_box.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Violin Plots of Vesicle Size Distributions per Cluster</h2>\")\n",
        "    f.write(fig_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Statistical Summary by Cluster</h2>\")\n",
        "    f.write(fig_table.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Enhanced Violin Plots with Distribution Metrics</h2>\")\n",
        "    f.write(fig_enhanced_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Pairwise Effect Size Comparison (Cohen's d)</h2>\")\n",
        "    f.write(fig_effect_size.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Cumulative Distribution Functions by Cluster</h2>\")\n",
        "    f.write(fig_cdf.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>3D Topological Manifold with Cluster & Size Projection</h2>\")\n",
        "    f.write(fig_umap.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Advanced Distribution Comparison (Kernel Density Estimation)</h2>\")\n",
        "    f.write(fig_kde.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Bayesian Hierarchical Modeling Summary</h2>\")\n",
        "    f.write(f\"<pre>{mixed_model.summary()}</pre>\")\n",
        "    f.write(\"<hr></body></html>\")\n",
        "\n",
        "print(f\"HTML file saved to {html_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5qm-T_n1iq-",
        "outputId": "3c8d90c5-29d5-42e2-c3d4-46ce988a0cfd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        17074.492063      15087.0  13275.508150     63\n",
            "1        25296.878788      19922.0  21165.778431     66\n",
            "2        19702.634615       9382.0  24112.898716     52\n",
            "3         5711.851852          9.0  12797.283524     27\n",
            "4        24744.236559      15368.0  25472.189837     93\n",
            "5        17633.608696      15602.5  15101.639561     46\n",
            "6        29630.687500      29620.0  20293.481207     32\n",
            "7        25294.890625      22859.0  19067.368575     64\n",
            "8        17438.551724      11867.0  16841.876593     29\n",
            "9        21758.216216      13183.0  20153.947448     37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "from umap import UMAP\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Base directory where the features are stored\n",
        "base_dir = '/content/clustering_results_final/'\n",
        "\n",
        "# Ensure the folder to save the HTML files exists\n",
        "os.makedirs('output_html', exist_ok=True)\n",
        "\n",
        "# Iterate over all combinations of seg and alpha\n",
        "segments = [1, 9, 10]\n",
        "alphas = ['0_5', 1]\n",
        "\n",
        "for seg in segments:\n",
        "    for alpha in alphas:\n",
        "        # Construct the path to the clustered features CSV file\n",
        "        features_path = os.path.join(base_dir, f\"features_seg{seg}_alpha{alpha}\", 'clustered_features.csv')\n",
        "\n",
        "        if os.path.exists(features_path):\n",
        "            print(f\"Processing file: {features_path}\")\n",
        "\n",
        "            # Load the clustered features for the current CSV file\n",
        "            features_df = pd.read_csv(features_path)\n",
        "\n",
        "            # Load all bbox CSVs with vesicle cloud sizes\n",
        "            bbox_csvs = glob('/content/content/csv_outputs/bbox*.csv')\n",
        "            vesicle_df = pd.concat([pd.read_csv(f) for f in bbox_csvs])\n",
        "\n",
        "            # Merge datasets using composite key\n",
        "            merged_df = pd.merge(\n",
        "                features_df,\n",
        "                vesicle_df[['bbox_name', 'central_coord_1', 'central_coord_2',\n",
        "                            'central_coord_3', 'vesicle_cloud_size']],\n",
        "                on=['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3'],\n",
        "                how='inner'\n",
        "            )\n",
        "\n",
        "            # Create meaningful size categories\n",
        "            merged_df['size_category'] = pd.qcut(merged_df['vesicle_cloud_size'],\n",
        "                                                q=4,\n",
        "                                                labels=['Small', 'Medium', 'Large', 'X-Large'])\n",
        "\n",
        "            # Cluster statistics\n",
        "            cluster_stats = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "                mean_size='mean',\n",
        "                median_size='median',\n",
        "                std_size='std',\n",
        "                count='count'\n",
        "            )\n",
        "            print(\"Cluster Statistics:\")\n",
        "            print(cluster_stats)\n",
        "\n",
        "            # Box Plot\n",
        "            fig_box = px.box(\n",
        "                merged_df,\n",
        "                x='cluster',\n",
        "                y='vesicle_cloud_size',\n",
        "                color='cluster',\n",
        "                points=\"all\",\n",
        "                hover_data=['bbox_name'],\n",
        "                title=f\"Vesicle Cloud Size Distribution by Cluster (seg{seg}_alpha{alpha})\"\n",
        "            )\n",
        "\n",
        "            # Violin Plot\n",
        "            fig_violin = go.Figure()\n",
        "            for cluster in sorted(merged_df['cluster'].unique()):\n",
        "                fig_violin.add_trace(go.Violin(\n",
        "                    x=merged_df[merged_df['cluster'] == cluster]['cluster'],\n",
        "                    y=merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size'],\n",
        "                    name=f'Cluster {cluster}',\n",
        "                    box_visible=True,\n",
        "                    meanline_visible=True\n",
        "                ))\n",
        "\n",
        "            # Statistical Summary Table\n",
        "            stats_df = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "                Mean=np.mean,\n",
        "                Median=np.median,\n",
        "                Std=np.std,\n",
        "                Min=np.min,\n",
        "                Max=np.max,\n",
        "                Count='count'\n",
        "            ).reset_index()\n",
        "\n",
        "            fig_table = go.Figure(data=[go.Table(\n",
        "                header=dict(values=stats_df.columns.tolist()),\n",
        "                cells=dict(values=stats_df.values.T))\n",
        "            ])\n",
        "\n",
        "            # Enhanced Violin Plot with Distribution Metrics\n",
        "            fig_enhanced_violin = go.Figure()\n",
        "            for cluster in sorted(merged_df['cluster'].unique()):\n",
        "                cluster_data = merged_df[merged_df['cluster'] == cluster]\n",
        "\n",
        "                # Add violin plot\n",
        "                fig_enhanced_violin.add_trace(go.Violin(\n",
        "                    x=cluster_data['cluster'],\n",
        "                    y=cluster_data['vesicle_cloud_size'],\n",
        "                    name=f'Cluster {cluster}',\n",
        "                    box_visible=True,\n",
        "                    meanline_visible=True,\n",
        "                    points=\"all\",\n",
        "                    pointpos=0,\n",
        "                    jitter=0.05\n",
        "                ))\n",
        "\n",
        "                # Add statistical annotations\n",
        "                stats_text = (f\"Mean: {cluster_data['vesicle_cloud_size'].mean():.1f}<br>\"\n",
        "                              f\"Median: {cluster_data['vesicle_cloud_size'].median():.1f}<br>\"\n",
        "                              f\"SD: {cluster_data['vesicle_cloud_size'].std():.1f}\")\n",
        "\n",
        "                fig_enhanced_violin.add_annotation(\n",
        "                    x=cluster,\n",
        "                    y=cluster_data['vesicle_cloud_size'].max() * 1.1,\n",
        "                    text=stats_text,\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=9)\n",
        "                )\n",
        "\n",
        "            # Statistical Comparison Matrix (Effect Size)\n",
        "            clusters = sorted(merged_df['cluster'].unique())\n",
        "            effect_size_matrix = np.zeros((len(clusters), len(clusters)))\n",
        "\n",
        "            for i, cluster1 in enumerate(clusters):\n",
        "                for j, cluster2 in enumerate(clusters):\n",
        "                    if i != j:\n",
        "                        data1 = merged_df[merged_df['cluster'] == cluster1]['vesicle_cloud_size']\n",
        "                        data2 = merged_df[merged_df['cluster'] == cluster2]['vesicle_cloud_size']\n",
        "                        effect_size = (data1.mean() - data2.mean()) / np.sqrt((data1.std()**2 + data2.std()**2)/2)\n",
        "                        effect_size_matrix[i, j] = effect_size\n",
        "\n",
        "            # Create heatmap for effect sizes\n",
        "            fig_effect_size = go.Figure(data=go.Heatmap(\n",
        "                z=effect_size_matrix,\n",
        "                x=clusters,\n",
        "                y=clusters,\n",
        "                colorscale='RdBu',\n",
        "                zmid=0,\n",
        "                colorbar=dict(title=\"Cohen's d\"),\n",
        "                hoverongaps=False\n",
        "            ))\n",
        "\n",
        "            # Add annotations for effect sizes\n",
        "            annotations = []\n",
        "            for i, cluster1 in enumerate(clusters):\n",
        "                for j, cluster2 in enumerate(clusters):\n",
        "                    annotations.append(\n",
        "                        dict(\n",
        "                            x=cluster2,\n",
        "                            y=cluster1,\n",
        "                            text=f\"{effect_size_matrix[i, j]:.2f}\",\n",
        "                            showarrow=False,\n",
        "                            font=dict(color='white' if abs(effect_size_matrix[i, j]) > 0.5 else 'black')\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            fig_effect_size.update_layout(\n",
        "                title=f\"Pairwise Effect Size Comparison (Cohen's d) (seg{seg}_alpha{alpha})\",\n",
        "                xaxis_title=\"Cluster\",\n",
        "                yaxis_title=\"Cluster\",\n",
        "                annotations=annotations,\n",
        "                width=800,\n",
        "                height=800\n",
        "            )\n",
        "\n",
        "            # 3D UMAP Projection\n",
        "            umap_3d = UMAP(n_components=3, random_state=42)\n",
        "            features = merged_df.filter(regex='feat_').values\n",
        "            projection_3d = umap_3d.fit_transform(features)\n",
        "\n",
        "            fig_umap = px.scatter_3d(\n",
        "                merged_df,\n",
        "                x=projection_3d[:,0],\n",
        "                y=projection_3d[:,1],\n",
        "                z=projection_3d[:,2],\n",
        "                color='cluster',\n",
        "                size='vesicle_cloud_size',\n",
        "                hover_data=['size_category'],\n",
        "                title=f\"3D Topological Manifold with Cluster & Size Projection (seg{seg}_alpha{alpha})\",\n",
        "                opacity=0.7\n",
        "            )\n",
        "            fig_umap.update_layout(width=1200, height=800)\n",
        "\n",
        "            # Save HTML for each combination of seg and alpha\n",
        "            html_filename = f\"output_html/seg{seg}_alpha{alpha}_analysis_results.html\"\n",
        "            with open(html_filename, 'w') as f:\n",
        "                f.write(\"<html><body><h1>Analysis Results</h1><hr>\")\n",
        "                f.write(f\"<h2>Vesicle Cloud Size Distribution by Cluster (seg{seg}_alpha{alpha})</h2>\")\n",
        "                f.write(fig_box.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "                f.write(\"<h2>Violin Plots of Vesicle Size Distributions per Cluster</h2>\")\n",
        "                f.write(fig_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "                f.write(\"<h2>Statistical Summary by Cluster</h2>\")\n",
        "                f.write(fig_table.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "                f.write(\"<h2>Enhanced Violin Plots with Distribution Metrics</h2>\")\n",
        "                f.write(fig_enhanced_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "                f.write(\"<h2>Pairwise Effect Size Comparison (Cohen's d)</h2>\")\n",
        "                f.write(fig_effect_size.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "                f.write(\"<h2>3D Topological Manifold with Cluster & Size Projection</h2>\")\n",
        "                f.write(fig_umap.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "                f.write(\"<hr></body></html>\")\n",
        "\n",
        "            print(f\"HTML file saved to {html_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSsutqAOa50M",
        "outputId": "31622d32-bacc-4c74-a4b7-fa31a7c68e8b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/clustering_results_final/features_seg1_alpha0_5/clustered_features.csv\n",
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        20533.380000      17601.5  16422.117295     50\n",
            "1        16862.692308      10172.0  15732.778725     52\n",
            "2        16280.977273       9232.0  17616.975996     44\n",
            "3        34797.782609      19641.5  34158.304532     46\n",
            "4        29108.237288      31346.0  21123.349318     59\n",
            "5        14994.816327      13885.0  10361.169475     98\n",
            "6        32576.750000      24048.5  29729.880462     20\n",
            "7        13963.017544       7899.0  15905.343274     57\n",
            "8        25676.900000      24512.5  19682.685851     20\n",
            "9        24536.476190      22285.0  20253.169844     63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/seg1_alpha0_5_analysis_results.html\n",
            "Processing file: /content/clustering_results_final/features_seg1_alpha1/clustered_features.csv\n",
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        15957.380952      14755.0  12705.915671     63\n",
            "1        34466.266667      35181.0  24175.974142     60\n",
            "2        27030.028571      21435.0  20246.307517     35\n",
            "3        27888.020408      27139.0  21305.578062     49\n",
            "4        15590.946429       8962.5  16722.763008     56\n",
            "5        14491.955556      10268.0  13525.606782     45\n",
            "6        27767.809524      26647.0  19721.404442     21\n",
            "7        16373.056180      13964.0  12743.100774     89\n",
            "8        28276.186441      17597.0  31320.143868     59\n",
            "9         9203.875000       4591.0  11119.986417     32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/seg1_alpha1_analysis_results.html\n",
            "Processing file: /content/clustering_results_final/features_seg9_alpha0_5/clustered_features.csv\n",
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        16050.235294      15729.0  11217.009827     51\n",
            "1        48083.225806      44467.0  35578.701698     31\n",
            "2        23322.779661      18221.0  20217.137788     59\n",
            "3        16094.114583      12360.5  14315.240023     96\n",
            "4        28502.900000      27423.0  19143.275222     30\n",
            "5        11833.372881       5147.0  16248.596537     59\n",
            "6        14952.773585      10492.0  15168.865986     53\n",
            "7        36995.058824      36540.5  23605.858624     34\n",
            "8        25483.375000      26389.0  26174.004016     16\n",
            "9        20908.637500      16909.0  15211.899723     80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/seg9_alpha0_5_analysis_results.html\n",
            "Processing file: /content/clustering_results_final/features_seg9_alpha1/clustered_features.csv\n",
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        21424.675000      21216.5  11770.148256     40\n",
            "1        35654.272727      38083.0  22273.160279     55\n",
            "2        17826.411765      16077.0  11159.065722     68\n",
            "3        10343.328571       8659.5   8978.514965     70\n",
            "4         6672.962963       5239.0   4880.989348     54\n",
            "5        24480.725490      22155.0  17443.333147     51\n",
            "6         6709.317460       5464.0   5189.638392     63\n",
            "7        65733.304348      58611.0  24348.487858     23\n",
            "8        39324.142857      38922.0  28339.470065     35\n",
            "9        24805.500000      22832.0  13093.200704     50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/seg9_alpha1_analysis_results.html\n",
            "Processing file: /content/clustering_results_final/features_seg10_alpha0_5/clustered_features.csv\n",
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        16456.946429      13329.5  15529.920634     56\n",
            "1        20015.340000      12212.5  18266.630852     50\n",
            "2        12463.870370       5770.5  16002.374534     54\n",
            "3        34996.916667      19315.5  36413.291342     36\n",
            "4        25073.615385      19937.0  19014.057112     39\n",
            "5        26909.156863      23512.0  22162.638737     51\n",
            "6        15769.666667      14753.0  10649.782233     87\n",
            "7        35444.484848      35293.0  25697.762224     33\n",
            "8        15540.911111      13183.0  14633.762643     45\n",
            "9        25305.672414      25000.0  19651.728428     58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/seg10_alpha0_5_analysis_results.html\n",
            "Processing file: /content/clustering_results_final/features_seg10_alpha1/clustered_features.csv\n",
            "Cluster Statistics:\n",
            "            mean_size  median_size      std_size  count\n",
            "cluster                                                \n",
            "0        16954.800000      15368.0  11242.141797     75\n",
            "1        35225.918919      19551.0  36147.943817     37\n",
            "2        14295.607843       7753.0  16017.795207     51\n",
            "3        19489.710526      10636.5  20064.846978     38\n",
            "4        32407.894737      30470.5  22239.350593     76\n",
            "5        18291.913043       9695.5  19926.317693     46\n",
            "6        28194.346154      27266.0  20501.160229     26\n",
            "7        17856.040000      13256.0  18507.432039     75\n",
            "8        14786.702703      14755.0   9617.299597     37\n",
            "9        19703.854167      17369.5  16842.649306     48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-82-d5a537227248>:83: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/seg10_alpha1_analysis_results.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: zip this folder /content/results2\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "!zip -r /content/output_html.zip /content/output_html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeNwC4Yfc8PY",
        "outputId": "27bbb7f9-59a2-42e4-d379-7cd62c865349"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/output_html/ (stored 0%)\n",
            "updating: content/output_html/seg10_alpha1_analysis_results.html (deflated 83%)\n",
            "updating: content/output_html/seg1_alpha1_analysis_results.html (deflated 83%)\n",
            "updating: content/output_html/seg9_alpha1_analysis_results.html (deflated 83%)\n",
            "updating: content/output_html/analysis_results.html (deflated 77%)\n",
            "  adding: content/output_html/seg9_alpha0_5_analysis_results.html (deflated 84%)\n",
            "  adding: content/output_html/seg1_alpha0_5_analysis_results.html (deflated 83%)\n",
            "  adding: content/output_html/seg10_alpha0_5_analysis_results.html (deflated 84%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from umap import UMAP\n",
        "import statsmodels.api as sm\n",
        "import shap\n",
        "import os\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "# Ensure the folder to save the HTML file exists\n",
        "os.makedirs('output_html', exist_ok=True)\n",
        "\n",
        "# # 1. Load and merge data with error handling\n",
        "# features_path = \"/content/results2/features_seg10_alpha1/clustered_features.csv\"\n",
        "# vesicle_dfs = [pd.read_csv(f) for f in glob('/content/csv_outputs/bbox*.csv')]\n",
        "# vesicle_df = pd.concat(vesicle_dfs)\n",
        "\n",
        "# Merge datasets using composite key\n",
        "merged_df = pd.merge(\n",
        "    features_df,\n",
        "    vesicle_df[['bbox_name', 'central_coord_1', 'central_coord_2',\n",
        "                'central_coord_3', 'vesicle_cloud_size']],\n",
        "    on=['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Create meaningful size categories\n",
        "merged_df['size_category'] = pd.qcut(merged_df['vesicle_cloud_size'],\n",
        "                                    q=4,\n",
        "                                    labels=['Small', 'Medium', 'Large', 'X-Large'])\n",
        "\n",
        "# 2. Plotting and Table Generation\n",
        "# Box Plot\n",
        "fig_box = px.box(\n",
        "    merged_df,\n",
        "    x='cluster',\n",
        "    y='vesicle_cloud_size',\n",
        "    color='cluster',\n",
        "    points=\"all\",\n",
        "    hover_data=['bbox_name'],\n",
        "    title=\"Vesicle Cloud Size Distribution by Cluster\"\n",
        ")\n",
        "\n",
        "# Add mean markers\n",
        "means = merged_df.groupby('cluster')['vesicle_cloud_size'].mean()\n",
        "fig_box.add_trace(go.Scatter(\n",
        "    x=means.index,\n",
        "    y=means.values,\n",
        "    mode='markers',\n",
        "    marker=dict(color='black', size=10, symbol='x'),\n",
        "    name='Mean'\n",
        "))\n",
        "\n",
        "# Violin Plot\n",
        "fig_violin = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    fig_violin.add_trace(go.Violin(\n",
        "        x=merged_df[merged_df['cluster'] == cluster]['cluster'],\n",
        "        y=merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True\n",
        "    ))\n",
        "\n",
        "# Statistical Summary Table\n",
        "stats_df = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "    Mean=np.mean,\n",
        "    Median=np.median,\n",
        "    Std=np.std,\n",
        "    Min=np.min,\n",
        "    Max=np.max,\n",
        "    Count='count'\n",
        ").reset_index()\n",
        "\n",
        "fig_table = go.Figure(data=[go.Table(\n",
        "    header=dict(values=stats_df.columns.tolist()),\n",
        "    cells=dict(values=stats_df.values.T))\n",
        "])\n",
        "\n",
        "# Enhanced Violin Plot with Distribution Metrics\n",
        "fig_enhanced_violin = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    cluster_data = merged_df[merged_df['cluster'] == cluster]\n",
        "\n",
        "    # Add violin plot\n",
        "    fig_enhanced_violin.add_trace(go.Violin(\n",
        "        x=cluster_data['cluster'],\n",
        "        y=cluster_data['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True,\n",
        "        points=\"all\",\n",
        "        pointpos=0,\n",
        "        jitter=0.05\n",
        "    ))\n",
        "\n",
        "    # Add statistical annotations\n",
        "    stats_text = (f\"Mean: {cluster_data['vesicle_cloud_size'].mean():.1f}<br>\"\n",
        "                  f\"Median: {cluster_data['vesicle_cloud_size'].median():.1f}<br>\"\n",
        "                  f\"SD: {cluster_data['vesicle_cloud_size'].std():.1f}\")\n",
        "\n",
        "    fig_enhanced_violin.add_annotation(\n",
        "        x=cluster,\n",
        "        y=cluster_data['vesicle_cloud_size'].max() * 1.1,\n",
        "        text=stats_text,\n",
        "        showarrow=False,\n",
        "        font=dict(size=9)\n",
        "    )\n",
        "\n",
        "# Statistical Comparison Matrix\n",
        "clusters = sorted(merged_df['cluster'].unique())\n",
        "effect_size_matrix = np.zeros((len(clusters), len(clusters)))\n",
        "\n",
        "for i, cluster1 in enumerate(clusters):\n",
        "    for j, cluster2 in enumerate(clusters):\n",
        "        if i != j:\n",
        "            data1 = merged_df[merged_df['cluster'] == cluster1]['vesicle_cloud_size']\n",
        "            data2 = merged_df[merged_df['cluster'] == cluster2]['vesicle_cloud_size']\n",
        "            effect_size = (data1.mean() - data2.mean()) / np.sqrt((data1.std()**2 + data2.std()**2)/2)\n",
        "            effect_size_matrix[i, j] = effect_size\n",
        "\n",
        "# Create heatmap for effect sizes\n",
        "fig_effect_size = go.Figure(data=go.Heatmap(\n",
        "    z=effect_size_matrix,\n",
        "    x=clusters,\n",
        "    y=clusters,\n",
        "    colorscale='RdBu',\n",
        "    zmid=0,\n",
        "    colorbar=dict(title=\"Cohen's d\"),\n",
        "    hoverongaps=False\n",
        "))\n",
        "\n",
        "# Add annotations for effect sizes\n",
        "annotations = []\n",
        "for i, cluster1 in enumerate(clusters):\n",
        "    for j, cluster2 in enumerate(clusters):\n",
        "        annotations.append(\n",
        "            dict(\n",
        "                x=cluster2,\n",
        "                y=cluster1,\n",
        "                text=f\"{effect_size_matrix[i, j]:.2f}\",\n",
        "                showarrow=False,\n",
        "                font=dict(color='white' if abs(effect_size_matrix[i, j]) > 0.5 else 'black')\n",
        "            )\n",
        "        )\n",
        "\n",
        "fig_effect_size.update_layout(\n",
        "    title=\"Pairwise Effect Size Comparison (Cohen's d)\",\n",
        "    xaxis_title=\"Cluster\",\n",
        "    yaxis_title=\"Cluster\",\n",
        "    annotations=annotations,\n",
        "    width=800,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Cumulative Distribution Plot\n",
        "fig_cdf = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    cluster_data = merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size']\n",
        "    hist, bin_edges = np.histogram(cluster_data, bins=50, density=True)\n",
        "    cdf = np.cumsum(hist * np.diff(bin_edges))\n",
        "\n",
        "    fig_cdf.add_trace(go.Scatter(\n",
        "        x=bin_edges[1:],\n",
        "        y=cdf,\n",
        "        mode='lines',\n",
        "        name=f'Cluster {cluster}',\n",
        "        opacity=0.7\n",
        "    ))\n",
        "\n",
        "# Topological Manifold Learning with UMAP\n",
        "umap_3d = UMAP(n_components=3, random_state=42)\n",
        "features = merged_df.filter(regex='feat_').values\n",
        "projection_3d = umap_3d.fit_transform(features)\n",
        "\n",
        "fig_umap = px.scatter_3d(\n",
        "    merged_df,\n",
        "    x=projection_3d[:,0],\n",
        "    y=projection_3d[:,1],\n",
        "    z=projection_3d[:,2],\n",
        "    color='cluster',\n",
        "    size='vesicle_cloud_size',\n",
        "    hover_data=['size_category'],\n",
        "    title=\"3D Topological Manifold with Cluster & Size Projection\",\n",
        "    opacity=0.7\n",
        ")\n",
        "fig_umap.update_layout(width=1200, height=800)\n",
        "\n",
        "# Bayesian Hierarchical Modeling\n",
        "mixed_model = sm.MixedLM.from_formula(\n",
        "    'vesicle_cloud_size ~ cluster',\n",
        "    groups=merged_df['bbox_name'],\n",
        "    data=merged_df\n",
        ").fit()\n",
        "\n",
        "# Advanced Distribution Comparison (Kernel Density Estimation)\n",
        "fig_kde = go.Figure()\n",
        "for cluster in clusters:\n",
        "    data = merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size']\n",
        "    kernel = gaussian_kde(data)\n",
        "    x = np.linspace(data.min(), data.max(), 100)\n",
        "    fig_kde.add_trace(go.Scatter(\n",
        "        x=x,\n",
        "        y=kernel(x),\n",
        "        mode='lines',\n",
        "        name=f'Cluster {cluster}',\n",
        "        fill='tozeroy'\n",
        "    ))\n",
        "\n",
        "# 3. Write everything to an HTML file\n",
        "html_filename = \"output_html/analysis_results.html\"\n",
        "with open(html_filename, 'w') as f:\n",
        "    f.write(\"<html><body><h1>Analysis Results</h1><hr>\")\n",
        "    f.write(\"<h2>Vesicle Cloud Size Distribution by Cluster</h2>\")\n",
        "    f.write(fig_box.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Violin Plots of Vesicle Size Distributions per Cluster</h2>\")\n",
        "    f.write(fig_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Statistical Summary by Cluster</h2>\")\n",
        "    f.write(fig_table.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Enhanced Violin Plots with Distribution Metrics</h2>\")\n",
        "    f.write(fig_enhanced_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Pairwise Effect Size Comparison (Cohen's d)</h2>\")\n",
        "    f.write(fig_effect_size.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Cumulative Distribution Functions by Cluster</h2>\")\n",
        "    f.write(fig_cdf.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>3D Topological Manifold with Cluster & Size Projection</h2>\")\n",
        "    f.write(fig_umap.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Advanced Distribution Comparison (Kernel Density Estimation)</h2>\")\n",
        "    f.write(fig_kde.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Bayesian Hierarchical Modeling Summary</h2>\")\n",
        "    f.write(f\"<pre>{mixed_model.summary()}</pre>\")\n",
        "    f.write(\"<hr></body></html>\")\n",
        "\n",
        "print(f\"HTML file saved to {html_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOsf2elWAiy1",
        "outputId": "4d460bd0-ff23-47b0-94fc-60387231e307"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-5bce03824d0c>:70: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7e643190db20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-15-5bce03824d0c>:70: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x7e6431356200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-15-5bce03824d0c>:70: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7e643190dc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-15-5bce03824d0c>:70: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7e643190d260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-15-5bce03824d0c>:70: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7e643190d120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/analysis_results.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra"
      ],
      "metadata": {
        "id": "1JmgNqj2yDbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load and merge data with error handling\n",
        "features_path = \"/content/results2/features_seg10_alpha1/clustered_features.csv\"\n",
        "vesicle_dfs = [pd.read_csv(f) for f in glob('/content/csv_outputs/bbox*.csv')]\n",
        "vesicle_df = pd.concat(vesicle_dfs)\n",
        "\n",
        "# Merge datasets using composite key\n",
        "merged_df = pd.merge(\n",
        "    features_df,\n",
        "    vesicle_df[['bbox_name', 'central_coord_1', 'central_coord_2',\n",
        "                'central_coord_3', 'vesicle_cloud_size']],\n",
        "    on=['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Create meaningful size categories\n",
        "merged_df['size_category'] = pd.qcut(merged_df['vesicle_cloud_size'],\n",
        "                                    q=4,\n",
        "                                    labels=['Small', 'Medium', 'Large', 'X-Large'])\n",
        "\n",
        "fig = px.box(\n",
        "    merged_df,\n",
        "    x='cluster',\n",
        "    y='vesicle_cloud_size',\n",
        "    color='cluster',\n",
        "    points=\"all\",\n",
        "    hover_data=['bbox_name'],\n",
        "    title=\"Vesicle Cloud Size Distribution by Cluster\"\n",
        ")\n",
        "\n",
        "# Add mean markers\n",
        "means = merged_df.groupby('cluster')['vesicle_cloud_size'].mean()\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=means.index,\n",
        "    y=means.values,\n",
        "    mode='markers',\n",
        "    marker=dict(color='black', size=10, symbol='x'),\n",
        "    name='Mean'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Cluster\",\n",
        "    yaxis_title=\"Vesicle Cloud Size (voxels)\",\n",
        "    width=1200,\n",
        "    height=600\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# 5. Violin Plot with Distribution Comparison\n",
        "fig = go.Figure()\n",
        "\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    fig.add_trace(go.Violin(\n",
        "        x=merged_df[merged_df['cluster'] == cluster]['cluster'],\n",
        "        y=merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Violin Plots of Vesicle Size Distributions per Cluster\",\n",
        "    xaxis_title=\"Cluster\",\n",
        "    yaxis_title=\"Vesicle Cloud Size\",\n",
        "    width=1200,\n",
        "    height=600\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# 6. Statistical Summary Table\n",
        "stats_df = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "    Mean=np.mean,\n",
        "    Median=np.median,\n",
        "    Std=np.std,\n",
        "    Min=np.min,\n",
        "    Max=np.max,\n",
        "    Count='count'\n",
        ").reset_index()\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=stats_df.columns.tolist()),\n",
        "    cells=dict(values=stats_df.values.T))\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Statistical Summary by Cluster\",\n",
        "    width=1000,\n",
        "    height=400\n",
        ")\n",
        "fig.show()\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# 2. Enhanced Violin Plot with Distribution Metrics\n",
        "fig = go.Figure()\n",
        "\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    cluster_data = merged_df[merged_df['cluster'] == cluster]\n",
        "\n",
        "    # Add violin plot\n",
        "    fig.add_trace(go.Violin(\n",
        "        x=cluster_data['cluster'],\n",
        "        y=cluster_data['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True,\n",
        "        points=\"all\",\n",
        "        pointpos=0,\n",
        "        jitter=0.05\n",
        "    ))\n",
        "\n",
        "    # Add statistical annotations\n",
        "    stats_text = (f\"Mean: {cluster_data['vesicle_cloud_size'].mean():.1f}<br>\"\n",
        "                  f\"Median: {cluster_data['vesicle_cloud_size'].median():.1f}<br>\"\n",
        "                  f\"SD: {cluster_data['vesicle_cloud_size'].std():.1f}\")\n",
        "\n",
        "    fig.add_annotation(\n",
        "        x=cluster,\n",
        "        y=cluster_data['vesicle_cloud_size'].max() * 1.1,\n",
        "        text=stats_text,\n",
        "        showarrow=False,\n",
        "        font=dict(size=9)\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Violin Plots with Distribution Metrics\",\n",
        "    xaxis_title=\"Cluster\",\n",
        "    yaxis_title=\"Vesicle Cloud Size\",\n",
        "    width=1400,\n",
        "    height=800\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# 3. Statistical Comparison Matrix\n",
        "# Calculate pairwise effect sizes (Cohen's d)\n",
        "clusters = sorted(merged_df['cluster'].unique())\n",
        "effect_size_matrix = np.zeros((len(clusters), len(clusters)))\n",
        "\n",
        "for i, cluster1 in enumerate(clusters):\n",
        "    for j, cluster2 in enumerate(clusters):\n",
        "        if i != j:\n",
        "            data1 = merged_df[merged_df['cluster'] == cluster1]['vesicle_cloud_size']\n",
        "            data2 = merged_df[merged_df['cluster'] == cluster2]['vesicle_cloud_size']\n",
        "            effect_size = (data1.mean() - data2.mean()) / np.sqrt((data1.std()**2 + data2.std()**2)/2)\n",
        "            effect_size_matrix[i, j] = effect_size\n",
        "\n",
        "# Create heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "    z=effect_size_matrix,\n",
        "    x=clusters,\n",
        "    y=clusters,\n",
        "    colorscale='RdBu',\n",
        "    zmid=0,\n",
        "    colorbar=dict(title=\"Cohen's d\"),\n",
        "    hoverongaps=False\n",
        "))\n",
        "\n",
        "# Add annotations\n",
        "annotations = []\n",
        "for i, cluster1 in enumerate(clusters):\n",
        "    for j, cluster2 in enumerate(clusters):\n",
        "        annotations.append(\n",
        "            dict(\n",
        "                x=cluster2,\n",
        "                y=cluster1,\n",
        "                text=f\"{effect_size_matrix[i, j]:.2f}\",\n",
        "                showarrow=False,\n",
        "                font=dict(color='white' if abs(effect_size_matrix[i, j]) > 0.5 else 'black')\n",
        "            )\n",
        "        )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Pairwise Effect Size Comparison (Cohen's d)\",\n",
        "    xaxis_title=\"Cluster\",\n",
        "    yaxis_title=\"Cluster\",\n",
        "    annotations=annotations,\n",
        "    width=800,\n",
        "    height=800\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# 5. Cumulative Distribution Plot\n",
        "fig = go.Figure()\n",
        "\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    cluster_data = merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size']\n",
        "    hist, bin_edges = np.histogram(cluster_data, bins=50, density=True)\n",
        "    cdf = np.cumsum(hist * np.diff(bin_edges))\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=bin_edges[1:],\n",
        "        y=cdf,\n",
        "        mode='lines',\n",
        "        name=f'Cluster {cluster}',\n",
        "        opacity=0.7\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Cumulative Distribution Functions by Cluster\",\n",
        "    xaxis_title=\"Vesicle Cloud Size\",\n",
        "    yaxis_title=\"Cumulative Probability\",\n",
        "    width=1200,\n",
        "    height=600\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from umap import UMAP\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import partial_dependence\n",
        "from scipy.stats import mannwhitneyu, kruskal\n",
        "import statsmodels.api as sm\n",
        "import shap\n",
        "\n",
        "# 1. Topological Manifold Learning with UMAP\n",
        "umap_3d = UMAP(n_components=3, random_state=42)\n",
        "features = merged_df.filter(regex='feat_').values\n",
        "projection_3d = umap_3d.fit_transform(features)\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    merged_df,\n",
        "    x=projection_3d[:,0],\n",
        "    y=projection_3d[:,1],\n",
        "    z=projection_3d[:,2],\n",
        "    color='cluster',\n",
        "    size='vesicle_cloud_size',\n",
        "    hover_data=['size_category'],\n",
        "    title=\"3D Topological Manifold with Cluster & Size Projection\",\n",
        "    opacity=0.7\n",
        ")\n",
        "fig.update_layout(width=1200, height=800)\n",
        "fig.show()\n",
        "\n",
        "# 2. Bayesian Hierarchical Modeling\n",
        "mixed_model = sm.MixedLM.from_formula(\n",
        "    'vesicle_cloud_size ~ cluster',\n",
        "    groups=merged_df['bbox_name'],\n",
        "    data=merged_df\n",
        ").fit()\n",
        "print(mixed_model.summary())\n",
        "\n",
        "# 7. Advanced Distribution Comparison\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "fig = go.Figure()\n",
        "for cluster in clusters:\n",
        "    data = merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size']\n",
        "    kernel = gaussian_kde(data)\n",
        "    x = np.linspace(data.min(), data.max(), 100)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x,\n",
        "        y=kernel(x),\n",
        "        mode='lines',\n",
        "        name=f'Cluster {cluster}',\n",
        "        fill='tozeroy'\n",
        "    ))\n",
        "fig.update_layout(\n",
        "    title=\"Probability Density Functions by Cluster\",\n",
        "    xaxis_title=\"Vesicle Cloud Size\",\n",
        "    yaxis_title=\"Density\",\n",
        "    width=1200,\n",
        "    height=600\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyedmGZPy_jm",
        "outputId": "a7b1dca7-bd98-4b96-c618-e53417a86f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-93daf56bf282>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7942639edb20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-73-93daf56bf282>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x794247c26200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-73-93daf56bf282>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7942639edc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-73-93daf56bf282>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7942639ed260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-73-93daf56bf282>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7942639ed120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/analysis_results.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly pandas numpy umap-learn statsmodels scikit-learn shap scipy kaleido pdfkit\n",
        "!sudo apt-get install wkhtmltopdf  # Linux\n",
        "# brew install wkhtmltopdf         # Mac"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_FzeV-U8prY",
        "outputId": "65991ffc-eafd-45f6-967b-62fcdf1e0e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.7)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Collecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.61.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
            "Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: pdfkit\n",
            "Successfully installed pdfkit-1.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  avahi-daemon bind9-host bind9-libs geoclue-2.0 glib-networking\n",
            "  glib-networking-common glib-networking-services gsettings-desktop-schemas\n",
            "  iio-sensor-proxy libavahi-core7 libavahi-glib1 libdaemon0 libevdev2\n",
            "  libfontenc1 libgudev-1.0-0 libhyphen0 libinput-bin libinput10\n",
            "  libjson-glib-1.0-0 libjson-glib-1.0-common liblmdb0 libmaxminddb0\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxfont2 libxkbcommon-x11-0\n",
            "  libxkbfile1 modemmanager qt5-gtk-platformtheme qttranslations5-l10n\n",
            "  session-migration systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data\n",
            "  wpasupplicant x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xnest\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  avahi-autoipd mmdb-bin gnome-shell | notification-daemon avahi-autoipd\n",
            "  | zeroconf qt5-image-formats-plugins qtwayland5 qt5-qmltooling-plugins comgt\n",
            "  wvdial wpagui libengine-pkcs11-openssl\n",
            "The following NEW packages will be installed:\n",
            "  avahi-daemon bind9-host bind9-libs geoclue-2.0 glib-networking\n",
            "  glib-networking-common glib-networking-services gsettings-desktop-schemas\n",
            "  iio-sensor-proxy libavahi-core7 libavahi-glib1 libdaemon0 libevdev2\n",
            "  libfontenc1 libgudev-1.0-0 libhyphen0 libinput-bin libinput10\n",
            "  libjson-glib-1.0-0 libjson-glib-1.0-common liblmdb0 libmaxminddb0\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxfont2 libxkbcommon-x11-0\n",
            "  libxkbfile1 modemmanager qt5-gtk-platformtheme qttranslations5-l10n\n",
            "  session-migration systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data\n",
            "  wkhtmltopdf wpasupplicant x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xnest xserver-common\n",
            "0 upgraded, 80 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 44.5 MB of archives.\n",
            "After this operation, 156 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-core7 amd64 0.8-5ubuntu5.2 [90.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdaemon0 amd64 0.14-7.1ubuntu3 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblmdb0 amd64 0.9.24-1build2 [47.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmaxminddb0 amd64 1.5.2-1build2 [24.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 bind9-libs amd64 1:9.18.30-0ubuntu0.22.04.2 [1,259 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 bind9-host amd64 1:9.18.30-0ubuntu0.22.04.2 [52.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 avahi-daemon amd64 0.8-5ubuntu5.2 [69.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5positioning5 amd64 5.15.3+dfsg-3 [223 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qml5 amd64 5.15.3+dfsg-1 [1,472 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlmodels5 amd64 5.15.3+dfsg-1 [205 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quick5 amd64 5.15.3+dfsg-1 [1,748 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5sensors5 amd64 5.15.3-1 [123 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webchannel5 amd64 5.15.3-1 [62.9 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webkit5 amd64 5.212.0~alpha4-15ubuntu1 [12.8 MB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmm-glib0 amd64 1.20.0-1~ubuntu22.04.4 [262 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.1 [4,070 B]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.1 [288 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 geoclue-2.0 amd64 2.5.7-3ubuntu3 [111 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 iio-sensor-proxy amd64 3.3-0ubuntu6 [34.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-glib4 amd64 1.28.0-1~ubuntu20.04.2 [192 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-proxy amd64 1.28.0-1~ubuntu20.04.2 [6,160 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnss-mdns amd64 0.15.1-1ubuntu1 [27.0 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-glib5 amd64 1.32.0-1ubuntu0.22.04.1 [772 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-proxy amd64 1.32.0-1ubuntu0.22.04.1 [6,072 B]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 modemmanager amd64 1.20.0-1~ubuntu22.04.4 [1,094 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 wpasupplicant amd64 2:2.10-6ubuntu2.1 [1,482 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xnest amd64 2:21.1.4-2ubuntu1.7~22.04.12 [712 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch-data all 20191128-4 [33.2 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch amd64 2.6.1-3ubuntu2 [46.0 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/universe amd64 wkhtmltopdf amd64 0.12.6-2 [173 kB]\n",
            "Fetched 44.5 MB in 6s (7,193 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 80.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libavahi-core7:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libavahi-core7_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libdaemon0:amd64.\n",
            "Preparing to unpack .../01-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\n",
            "Unpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../02-liblmdb0_0.9.24-1build2_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.24-1build2) ...\n",
            "Selecting previously unselected package libmaxminddb0:amd64.\n",
            "Preparing to unpack .../03-libmaxminddb0_1.5.2-1build2_amd64.deb ...\n",
            "Unpacking libmaxminddb0:amd64 (1.5.2-1build2) ...\n",
            "Selecting previously unselected package bind9-libs:amd64.\n",
            "Preparing to unpack .../04-bind9-libs_1%3a9.18.30-0ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking bind9-libs:amd64 (1:9.18.30-0ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package bind9-host.\n",
            "Preparing to unpack .../05-bind9-host_1%3a9.18.30-0ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking bind9-host (1:9.18.30-0ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package avahi-daemon.\n",
            "Preparing to unpack .../06-avahi-daemon_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "Preparing to unpack .../07-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../08-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../09-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../10-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../11-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../12-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../13-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../14-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../15-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../16-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../17-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../18-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../19-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../20-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../21-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../22-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../23-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../24-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../25-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../26-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../27-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../28-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../29-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../30-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libqt5positioning5:amd64.\n",
            "Preparing to unpack .../31-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\n",
            "Unpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Selecting previously unselected package libqt5printsupport5:amd64.\n",
            "Preparing to unpack .../32-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5qml5:amd64.\n",
            "Preparing to unpack .../33-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5qmlmodels5:amd64.\n",
            "Preparing to unpack .../34-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5quick5:amd64.\n",
            "Preparing to unpack .../35-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5sensors5:amd64.\n",
            "Preparing to unpack .../36-libqt5sensors5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5webchannel5:amd64.\n",
            "Preparing to unpack .../37-libqt5webchannel5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../38-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package libqt5webkit5:amd64.\n",
            "Preparing to unpack .../39-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../40-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libavahi-glib1:amd64.\n",
            "Preparing to unpack .../41-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../42-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../43-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libmm-glib0:amd64.\n",
            "Preparing to unpack .../44-libmm-glib0_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../45-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../46-libproxy1v5_0.4.17-2_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../47-glib-networking-common_2.72.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../48-glib-networking-services_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.72.0-1) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../49-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../50-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../51-glib-networking_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.72.0-1) ...\n",
            "Selecting previously unselected package libsoup2.4-common.\n",
            "Preparing to unpack .../52-libsoup2.4-common_2.74.2-3ubuntu0.1_all.deb ...\n",
            "Unpacking libsoup2.4-common (2.74.2-3ubuntu0.1) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../53-libsoup2.4-1_2.74.2-3ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.1) ...\n",
            "Selecting previously unselected package geoclue-2.0.\n",
            "Preparing to unpack .../54-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\n",
            "Unpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Selecting previously unselected package iio-sensor-proxy.\n",
            "Preparing to unpack .../55-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\n",
            "Unpacking iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../56-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libmbim-glib4:amd64.\n",
            "Preparing to unpack .../57-libmbim-glib4_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libmbim-proxy.\n",
            "Preparing to unpack .../58-libmbim-proxy_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libnl-genl-3-200:amd64.\n",
            "Preparing to unpack .../59-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\n",
            "Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Selecting previously unselected package libnss-mdns:amd64.\n",
            "Preparing to unpack .../60-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libqmi-glib5:amd64.\n",
            "Preparing to unpack .../61-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libqmi-proxy.\n",
            "Preparing to unpack .../62-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../63-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../64-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../65-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package modemmanager.\n",
            "Preparing to unpack .../66-modemmanager_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../67-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../68-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../69-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package wpasupplicant.\n",
            "Preparing to unpack .../70-wpasupplicant_2%3a2.10-6ubuntu2.1_amd64.deb ...\n",
            "Unpacking wpasupplicant (2:2.10-6ubuntu2.1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../71-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../72-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../73-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../74-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../75-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xnest.\n",
            "Preparing to unpack .../76-xnest_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xnest (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package usb-modeswitch-data.\n",
            "Preparing to unpack .../77-usb-modeswitch-data_20191128-4_all.deb ...\n",
            "Unpacking usb-modeswitch-data (20191128-4) ...\n",
            "Selecting previously unselected package usb-modeswitch.\n",
            "Preparing to unpack .../78-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Selecting previously unselected package wkhtmltopdf.\n",
            "Preparing to unpack .../79-wkhtmltopdf_0.12.6-2_amd64.deb ...\n",
            "Unpacking wkhtmltopdf (0.12.6-2) ...\n",
            "Setting up liblmdb0:amd64 (0.9.24-1build2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up libmaxminddb0:amd64 (1.5.2-1build2) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up usb-modeswitch-data (20191128-4) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libsoup2.4-common (2.74.2-3ubuntu0.1) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Setting up usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up glib-networking-common (2.72.0-1) ...\n",
            "Setting up libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Setting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Setting up libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "First installation detected...\n",
            "Checking NSS setup...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up glib-networking-services (2.72.0-1) ...\n",
            "Setting up iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Setting up bind9-libs:amd64 (1:9.18.30-0ubuntu0.22.04.2) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Setting up libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up wpasupplicant (2:2.10-6ubuntu2.1) ...\n",
            "Created symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service → /lib/systemd/system/wpa_supplicant.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service → /lib/systemd/system/wpa_supplicant.service.\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up bind9-host (1:9.18.30-0ubuntu0.22.04.2) ...\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of force-reload.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service → /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service → /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket → /lib/systemd/system/avahi-daemon.socket.\n",
            "Setting up xnest (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Setting up modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service → /lib/systemd/system/ModemManager.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service → /lib/systemd/system/ModemManager.service.\n",
            "Setting up wkhtmltopdf (0.12.6-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Setting up glib-networking:amd64 (2.72.0-1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.1) ...\n",
            "Setting up geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from umap import UMAP\n",
        "import statsmodels.api as sm\n",
        "import shap\n",
        "import os\n",
        "\n",
        "# Ensure the folder to save the HTML file exists\n",
        "os.makedirs('output_html', exist_ok=True)\n",
        "\n",
        "# 1. Load and merge data with error handling\n",
        "features_path = \"/content/results2/features_seg10_alpha1/clustered_features.csv\"\n",
        "vesicle_dfs = [pd.read_csv(f) for f in glob('/content/csv_outputs/bbox*.csv')]\n",
        "vesicle_df = pd.concat(vesicle_dfs)\n",
        "\n",
        "# Merge datasets using composite key\n",
        "merged_df = pd.merge(\n",
        "    features_df,\n",
        "    vesicle_df[['bbox_name', 'central_coord_1', 'central_coord_2',\n",
        "                'central_coord_3', 'vesicle_cloud_size']],\n",
        "    on=['bbox_name', 'central_coord_1', 'central_coord_2', 'central_coord_3'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Create meaningful size categories\n",
        "merged_df['size_category'] = pd.qcut(merged_df['vesicle_cloud_size'],\n",
        "                                    q=4,\n",
        "                                    labels=['Small', 'Medium', 'Large', 'X-Large'])\n",
        "\n",
        "# 2. Plotting and Table Generation\n",
        "# Box Plot\n",
        "fig_box = px.box(\n",
        "    merged_df,\n",
        "    x='cluster',\n",
        "    y='vesicle_cloud_size',\n",
        "    color='cluster',\n",
        "    points=\"all\",\n",
        "    hover_data=['bbox_name'],\n",
        "    title=\"Vesicle Cloud Size Distribution by Cluster\"\n",
        ")\n",
        "\n",
        "# Add mean markers\n",
        "means = merged_df.groupby('cluster')['vesicle_cloud_size'].mean()\n",
        "fig_box.add_trace(go.Scatter(\n",
        "    x=means.index,\n",
        "    y=means.values,\n",
        "    mode='markers',\n",
        "    marker=dict(color='black', size=10, symbol='x'),\n",
        "    name='Mean'\n",
        "))\n",
        "\n",
        "# Violin Plot\n",
        "fig_violin = go.Figure()\n",
        "for cluster in sorted(merged_df['cluster'].unique()):\n",
        "    fig_violin.add_trace(go.Violin(\n",
        "        x=merged_df[merged_df['cluster'] == cluster]['cluster'],\n",
        "        y=merged_df[merged_df['cluster'] == cluster]['vesicle_cloud_size'],\n",
        "        name=f'Cluster {cluster}',\n",
        "        box_visible=True,\n",
        "        meanline_visible=True\n",
        "    ))\n",
        "\n",
        "# Statistical Summary Table\n",
        "stats_df = merged_df.groupby('cluster')['vesicle_cloud_size'].agg(\n",
        "    Mean=np.mean,\n",
        "    Median=np.median,\n",
        "    Std=np.std,\n",
        "    Min=np.min,\n",
        "    Max=np.max,\n",
        "    Count='count'\n",
        ").reset_index()\n",
        "\n",
        "fig_table = go.Figure(data=[go.Table(\n",
        "    header=dict(values=stats_df.columns.tolist()),\n",
        "    cells=dict(values=stats_df.values.T))\n",
        "])\n",
        "\n",
        "# 3. Write everything to an HTML file\n",
        "html_filename = \"output_html/analysis_results.html\"\n",
        "with open(html_filename, 'w') as f:\n",
        "    f.write(\"<html><body><h1>Analysis Results</h1><hr>\")\n",
        "    f.write(\"<h2>Vesicle Cloud Size Distribution by Cluster</h2>\")\n",
        "    f.write(fig_box.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Violin Plots of Vesicle Size Distributions per Cluster</h2>\")\n",
        "    f.write(fig_violin.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<h2>Statistical Summary by Cluster</h2>\")\n",
        "    f.write(fig_table.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "    f.write(\"<hr></body></html>\")\n",
        "\n",
        "print(f\"HTML file saved to {html_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmAJqiR95I5w",
        "outputId": "79479946-a56e-4b99-96b8-36621a770648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file saved to output_html/analysis_results.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-8105108bff1b>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function mean at 0x7942639edb20> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "\n",
            "<ipython-input-72-8105108bff1b>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function median at 0x794247c26200> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
            "\n",
            "<ipython-input-72-8105108bff1b>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function std at 0x7942639edc60> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
            "\n",
            "<ipython-input-72-8105108bff1b>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function min at 0x7942639ed260> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "\n",
            "<ipython-input-72-8105108bff1b>:69: FutureWarning:\n",
            "\n",
            "The provided callable <function max at 0x7942639ed120> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install causalimpact"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxTCqlmJ6lt8",
        "outputId": "2304ac0b-0e6c-495e-87eb-498b4e7c9590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting causalimpact\n",
            "  Downloading causalimpact-0.2.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from causalimpact) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from causalimpact) (1.26.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from causalimpact) (0.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from causalimpact) (3.10.0)\n",
            "Requirement already satisfied: pymc in /usr/local/lib/python3.11/dist-packages (from causalimpact) (5.20.1)\n",
            "Requirement already satisfied: pytensor in /usr/local/lib/python3.11/dist-packages (from causalimpact) (2.27.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causalimpact) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->causalimpact) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->causalimpact) (2025.1)\n",
            "Requirement already satisfied: arviz>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (0.20.0)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (5.5.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (3.1.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (13.9.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pymc->causalimpact) (4.12.2)\n",
            "Requirement already satisfied: setuptools>=59.0.0 in /usr/local/lib/python3.11/dist-packages (from pytensor->causalimpact) (75.1.0)\n",
            "Requirement already satisfied: filelock>=3.15 in /usr/local/lib/python3.11/dist-packages (from pytensor->causalimpact) (3.17.0)\n",
            "Requirement already satisfied: etuples in /usr/local/lib/python3.11/dist-packages (from pytensor->causalimpact) (0.3.9)\n",
            "Requirement already satisfied: logical-unification in /usr/local/lib/python3.11/dist-packages (from pytensor->causalimpact) (0.4.6)\n",
            "Requirement already satisfied: miniKanren in /usr/local/lib/python3.11/dist-packages (from pytensor->causalimpact) (1.0.3)\n",
            "Requirement already satisfied: cons in /usr/local/lib/python3.11/dist-packages (from pytensor->causalimpact) (0.4.6)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->causalimpact) (1.0.1)\n",
            "Requirement already satisfied: xarray>=2022.6.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc->causalimpact) (2025.1.2)\n",
            "Requirement already satisfied: h5netcdf>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc->causalimpact) (1.5.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.3 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc->causalimpact) (0.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->causalimpact) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->pymc->causalimpact) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->pymc->causalimpact) (2.18.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from logical-unification->pytensor->causalimpact) (0.12.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from logical-unification->pytensor->causalimpact) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf>=1.0.2->arviz>=0.13.0->pymc->causalimpact) (3.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->pymc->causalimpact) (0.1.2)\n",
            "Downloading causalimpact-0.2.6-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: causalimpact\n",
            "Successfully installed causalimpact-0.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSt1vOoa6TS2",
        "outputId": "1da483fb-b450-41ef-f96a-4e00998a172f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.4.2.min.js\"></script>                <div id=\"2c2de7be-57d5-4f46-a785-a5433cab2132\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2c2de7be-57d5-4f46-a785-a5433cab2132\")) {                    Plotly.newPlot(                        \"2c2de7be-57d5-4f46-a785-a5433cab2132\",                        [{\"customdata\":[[\"Large\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"X-Large\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Small\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"X-Large\"],[\"Medium\"],[\"Small\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"Small\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Large\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"Medium\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"Medium\"],[\"X-Large\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"Large\"],[\"Medium\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"X-Large\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"X-Large\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Medium\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Large\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"X-Large\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"Medium\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Large\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"Small\"],[\"Small\"],[\"Medium\"],[\"X-Large\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Medium\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Medium\"],[\"Small\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Medium\"],[\"Large\"],[\"Medium\"],[\"Medium\"],[\"X-Large\"],[\"Small\"],[\"Small\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"Medium\"],[\"X-Large\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"X-Large\"],[\"X-Large\"],[\"Medium\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Large\"],[\"Small\"],[\"Large\"],[\"Large\"]],\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>z=%{z}<br>vesicle_cloud_size=%{marker.size}<br>size_category=%{customdata[0]}<br>cluster=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[8,0,0,2,8,5,5,8,4,0,0,4,6,6,6,5,2,8,8,8,8,8,8,8,0,5,0,8,5,6,6,4,1,5,0,0,8,4,4,4,2,4,4,2,5,2,5,8,4,0,8,4,8,8,8,4,8,8,6,2,4,0,7,7,6,3,6,1,7,6,2,2,0,4,4,1,1,1,4,5,2,1,8,5,1,1,1,4,1,1,1,0,1,7,3,7,1,7,3,1,1,7,3,3,7,7,1,1,6,1,6,5,1,1,1,1,8,2,5,2,2,1,1,1,1,5,1,2,1,7,3,7,7,1,1,1,7,7,7,6,1,1,0,0,1,7,1,1,7,1,1,1,1,1,0,7,1,1,8,4,8,4,1,5,1,0,2,6,6,0,5,0,0,0,0,8,6,2,5,2,4,0,4,4,6,5,1,0,0,4,0,6,6,5,8,4,2,6,6,8,6,0,0,1,0,8,2,0,1,4,0,0,1,4,5,0,4,5,5,5,2,4,6,0,6,0,5,5,5,5,5,8,8,2,5,6,6,0,5,5,0,5,0,0,4,5,0,0,4,4,5,3,5,5,5,5,2,5,5,8,6,0,6,6,0,6,1,5,1,2,1,1,5,1,5,6,0,4,2,0,6,1,1,1,2,2,8,8,8,8,8,8,2,0,2,2,6,2,1,6,5,2,2,4,5,4,2,5,2,0,6,0,5,8,4,5,0,5,2,5,5,5,8,2,2,6,5,5,6,8,8,5,8,1,1,2,5,5,5,6,5,8,5,4,5,4,3,6,0,3,3,7,3,7,7,6,6,3,3,9,9,9,9,9,1,3,3,3,7,7,7,7,3,7,3,3,7,3,3,2,7,6,7,7,3,9,1,3,9,7,3,7,7,3,1,3,3,6,3,3,3,3,7,1,7,9,9,3,9,7,1,3,3,7,3,3,7,3,9,7,9,9,3,9,3,3,2,9,3,4,9,2,4,9,3,0,4,0,8,2,2,2,2,4,8,1,2,4,2,0,1,1,1,6,2,4,6,1,5,2,1,1,1,0,0,5,0,5,5,2,2,0,1,1,0,6,5,2,4,4,5,5,5,2,5,2,2,6,5,1,5,6,0,2,2,5,5,4,6,2,6,5,6,2,5,2,4,8,8],\"coloraxis\":\"coloraxis\",\"opacity\":0.7,\"size\":[18277,10860,11458,15016,5464,5714,8890,22378,13403,21587,17471,9,31419,734,4989,35293,28175,41347,26647,12657,7589,37166,15156,55,25639,7138,7205,8995,15022,15087,27255,9,10268,25860,29595,27139,57796,9,9,9,24591,12,12,73865,22155,24970,12117,10022,1,22522,27885,1,36316,10337,41962,4,46577,56857,4518,16189,16238,16189,4407,10492,7753,7500,7899,7029,12372,6440,6501,6932,1314,15500,32980,2932,9558,376,9,6470,37622,5302,32679,6648,8784,35732,14085,9,50658,1756,1926,2139,3162,54431,3487,39812,5230,15130,19487,7870,3067,7919,20569,4895,109,7935,4173,4440,2756,9558,3339,4973,19563,1,7882,23513,55011,57190,35915,42817,53363,9141,18072,9460,6164,3862,21741,11481,54528,9852,22739,15729,42534,14241,12955,17142,15491,43024,54236,3933,27822,32995,205,24573,7029,19756,376,41238,32791,4341,14085,6164,5302,14085,5831,29743,49899,19937,10205,9875,57185,28184,1,23158,20819,17239,14753,12653,2,1,60613,5909,12133,13806,11252,1,3741,20634,28760,3741,25409,11449,2,9016,18125,8817,1921,7791,7011,31346,17337,4664,37122,2,1,13706,1,39067,8940,12402,26086,22511,22511,76483,40720,15300,3426,24406,51550,6088,1,23959,55397,2,17989,11187,3,11896,13394,8502,32084,40160,26756,33295,26612,17411,31712,29284,4,217,1,52242,42761,44069,40642,22297,1,54602,23695,23831,29284,12431,1,27184,53785,1,57263,54828,26,16648,1,22285,1,53882,58611,60334,1,6730,38083,20469,34605,6396,13632,16568,8460,2,22647,42813,546,43423,9501,10690,14192,11867,29192,1,6525,4,45382,25336,32957,44217,1,46921,62315,379,52097,57102,48915,65814,59463,68669,63724,48214,30991,42081,22203,58122,5926,18537,10352,19925,16548,23512,15586,5726,1,33834,14755,12290,13166,13964,22701,25113,36496,13337,29483,29714,2347,43723,45235,51728,53168,17866,17170,12033,66383,68067,13183,57412,56361,50682,4108,1,54649,33733,35317,23744,40059,24307,27519,34447,4,4,19,5151,4444,7442,17700,4029,112082,101261,13846,98148,96845,3849,3377,13836,55566,96715,8728,9505,9259,3776,35819,39680,23573,66055,31692,85019,5048,11369,2099,11369,981,12332,2611,3307,5398,3665,44467,3382,19080,3,7104,59709,103643,94060,32614,19732,44278,7086,45877,19121,28146,19681,2588,24067,17472,19551,21435,39775,31761,34883,47799,53560,1195,2990,3726,4844,5269,7736,4085,1154,2588,38922,11768,2395,5147,11463,2526,15176,54396,47875,2313,4593,2697,1624,17597,1845,6111,3736,2556,4133,3472,4298,3041,6624,2760,3082,3082,6624,1278,2,12406,42483,8963,23017,5430,8136,15951,15368,1,15843,7433,25047,49796,52582,21952,29624,51115,20395,17492,19822,19822,20620,13965,3598,9833,13345,13528,12826,15814,13256,10123,39858,3494,1888,35337,35282,59696,20696,9640,45034,17058,36502,36907,46806,29567,22401,20206,39463,22317,30292,29477,88227,78243,6304,60097,62937,10846,15708,20217,24973,19922,19922,4621,31355,18221],\"sizemode\":\"area\",\"sizeref\":280.205,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"type\":\"scatter3d\",\"x\":[0.93279505,6.941106,4.9289274,5.791395,2.1156456,3.5746741,2.456492,1.0148442,1.8757324,6.950262,7.0620065,1.1006409,7.049171,7.546966,6.9165087,4.4098797,5.7681403,1.3593512,1.5117878,0.84195894,1.1371434,0.9402498,0.7612876,0.91016465,5.486231,2.7508879,6.7861824,2.8215055,3.7829106,6.962089,6.5192857,1.3180645,8.187197,3.7987726,5.3794813,5.414566,1.0031506,0.75440234,1.0587771,0.9857931,5.5481915,0.926816,0.9798739,5.117849,2.9527202,4.729484,3.5201979,1.182961,1.1009227,5.6189966,0.852054,0.87891656,1.1606543,2.1766331,0.9458326,0.8673242,1.0084678,1.0299412,6.947982,5.5414267,2.4534528,5.06453,7.577669,7.3140874,6.7594247,7.1021433,6.0128045,8.341518,7.749928,5.9843054,5.257583,4.9367175,6.8617773,0.7679396,0.8851279,7.7346225,8.293658,7.9076695,1.5820092,5.2718534,5.0155363,7.620814,4.477566,3.5653036,8.394932,8.17428,8.277784,1.4266288,7.996448,8.600536,8.422256,5.0461435,7.6142836,7.736144,7.4820747,7.757324,8.164303,7.7477365,7.8982115,7.80848,7.732416,7.432057,8.031326,8.10209,7.3319116,7.8814163,8.412314,8.102811,6.7218275,8.123139,6.3066816,2.4804513,7.8170977,7.656536,7.7580934,7.6560545,1.845828,2.036084,2.5236993,4.7796693,2.0376303,7.9774528,7.8667245,7.9395843,7.9157453,3.1633031,7.832944,4.6162047,8.239267,8.029795,7.866016,7.5596247,7.819512,8.0982275,8.115455,7.9347677,7.694472,7.1695366,7.7497215,6.9060564,7.696098,4.5757337,3.5934947,6.143353,8.166177,7.860961,7.7566123,8.01927,7.5813036,8.170197,8.2177,7.9755473,7.7179904,8.336797,6.887003,7.485952,8.225091,7.7019897,1.9116013,1.5767993,1.5587143,0.6988181,8.115058,3.9360492,8.068263,6.914507,5.8898897,6.2270417,7.0323853,6.685943,4.721866,5.6050367,5.6549964,5.4468083,5.8145914,2.4517698,5.652994,5.746982,2.9804206,5.523258,2.0358698,6.8343635,0.912873,2.0011528,5.3888965,3.8687074,8.045844,6.3025723,6.137222,1.9320426,6.468874,6.8176723,5.81985,1.6950756,2.8630154,1.8547152,6.300922,5.6288967,7.0930905,2.2907329,6.78304,6.399725,6.208279,7.7596884,6.686688,1.4121702,5.4991093,6.942481,4.8392615,1.8714736,4.919181,6.9445567,7.87035,0.8673218,4.895993,5.419033,0.77842396,4.740962,2.8490844,3.6735494,5.0328484,1.4753264,7.2340426,6.8704906,6.0985107,6.911726,2.5119288,4.716587,3.7024748,3.1648164,2.3948755,1.859041,0.9988861,4.3907824,2.0590236,5.976936,5.8948207,6.641737,3.105951,3.1478777,5.050311,1.9480102,6.338008,6.27034,0.731528,3.751676,5.445425,6.595558,1.1907992,1.2126985,3.6329372,7.1219506,3.4864058,3.471966,3.4585333,3.4422004,4.35938,3.4918292,4.0940156,1.6571878,6.700905,5.342808,7.0356154,7.0656953,5.787929,7.033104,7.9322257,2.4009645,8.225342,5.6714096,8.161669,8.112621,4.776771,8.438792,2.5217216,6.969295,7.9387608,1.2156125,4.916491,6.4503007,6.652947,7.5502796,7.6379976,7.591135,4.353139,4.6161823,0.9358935,1.8985324,1.8229579,1.8375552,1.6055403,1.9734367,4.4958425,5.6924424,0.92315793,5.5301943,6.8011026,4.687345,8.235072,5.5681677,2.2853122,4.850989,4.812828,2.412121,4.662572,0.89300466,4.936007,4.7814245,4.994176,8.007242,5.4922404,6.0680437,2.507249,2.5116007,1.1761323,2.5764701,5.035449,4.846797,5.79363,3.6661546,2.081187,4.6987934,2.333382,4.872557,4.889635,5.802345,2.5851357,3.1244092,5.76105,1.8995051,4.034114,3.7775476,1.0836735,8.101815,8.189336,2.7919614,2.7644825,2.4097497,3.1323023,6.7165117,3.6421947,2.1762965,3.169054,0.76141727,3.2001345,0.81108,8.095147,6.782233,5.84895,7.992288,7.4987426,7.8225536,7.40952,7.885741,7.916759,7.0399413,7.0716004,7.331417,7.676605,7.929035,7.809081,7.986705,7.9913197,7.7882514,8.511115,7.447963,7.8253946,7.725697,7.916138,7.3688807,7.7892795,7.457299,7.5559454,7.6914415,7.908793,7.9450746,7.7087655,7.5190735,8.004494,4.9184117,7.951498,6.892523,7.902559,7.871452,7.8250937,7.68143,7.9032817,7.632303,8.002967,7.9659295,7.844226,7.6315856,7.8800607,7.672989,8.440365,7.739703,7.8417583,6.8863106,7.993046,7.905101,8.164152,8.073452,7.6099925,8.611995,7.25857,8.024648,7.6696506,7.230591,7.7169952,7.9348865,8.607763,7.720269,7.903273,7.205315,7.774667,7.3387885,8.633285,6.9459195,8.041774,7.9676247,8.02513,7.965786,7.9339085,7.9975457,8.044473,7.640898,5.4029374,8.0959,7.9807367,0.9652002,7.9110026,4.5812726,2.2645233,7.712294,6.983703,6.697276,0.9497002,6.270019,2.0234966,5.757916,5.562674,6.10996,5.2956047,0.7971736,1.948076,7.5505114,4.737044,2.0984752,4.9783764,6.437597,7.614777,7.61294,7.6334767,6.3704667,5.6189766,4.9536996,6.20007,7.94315,3.3650894,4.5882263,8.512907,8.220429,8.452614,6.0973635,6.405328,3.0729902,6.6501846,3.7334948,3.3438866,6.2013655,6.000036,6.0383315,4.8039255,4.7409544,6.288548,5.486755,4.7330465,4.8227835,0.95806104,0.92131674,2.4937565,4.7706847,3.0500867,5.3265834,3.147753,4.714937,4.961105,5.709489,4.6178555,7.9595785,3.4486253,5.917456,6.9296737,5.4706383,4.994417,4.778173,4.7723703,0.9716977,5.5427575,5.341281,6.075304,4.508527,6.3371224,5.2270913,4.7050667,4.6353855,0.9643886,2.4348953,1.3341619],\"y\":[6.1701074,3.591443,4.9180765,2.3355372,5.152245,5.1465516,4.05342,6.1543484,4.135378,4.050778,3.5299373,3.1525621,3.272393,5.6137457,3.124482,4.344156,2.3299358,5.446922,5.148508,6.201845,6.012035,6.1908245,6.2093573,6.1717534,3.8242629,4.5981913,3.3326774,5.503375,5.236719,2.8824952,2.6595633,3.2714076,6.5513196,4.6949635,3.8795116,3.8209956,6.090877,2.949896,3.1548278,3.0721202,2.3886957,3.8146915,3.9705884,3.4568381,4.7835464,2.273316,4.659454,5.926897,3.2525759,3.8027074,6.2601867,3.0361776,6.0291147,5.351664,6.137321,3.1030054,6.1088448,6.1428237,2.9013386,2.4497445,4.6652293,4.6827636,4.416919,4.1373467,2.8357193,4.0553803,2.9706063,6.549069,4.6544867,2.5334115,2.0566697,1.9492162,3.0684311,3.6038733,3.7905638,5.620051,6.0062394,5.684746,3.418651,4.045612,3.286606,5.832756,4.1034265,3.9804006,6.306732,5.529492,5.822314,3.3459344,5.4757137,6.267954,6.377559,4.7603374,5.7455955,4.391442,3.490374,4.707999,6.0029836,5.0680437,3.01454,5.6114435,5.500529,4.419663,3.5389724,3.562616,4.2979994,4.288413,6.310749,6.045845,3.339614,6.178484,2.9838057,5.012298,5.561443,5.6075454,5.5445514,5.6304893,4.518779,4.3325453,5.4198303,3.235352,4.2957273,5.388334,5.4602427,5.3563895,5.646866,4.143238,5.7185903,4.336124,5.6325583,3.657983,3.3458843,4.915528,4.6061797,5.5675545,5.739975,5.7145486,4.9643154,4.134851,5.388237,3.839649,5.8049936,4.178718,3.9029877,2.7149408,5.6759443,3.8881245,5.5272584,5.7292566,4.5164337,5.511309,6.655339,5.8289423,5.967023,5.805418,4.150989,4.3404613,6.04812,5.788956,4.610005,3.4913802,5.331948,2.9333222,6.8102493,5.1326103,7.1057677,3.811608,2.4724221,2.9689085,3.2397473,4.268678,4.9907694,3.8190708,3.7863696,3.8817422,3.7119012,5.534323,3.0272954,2.3729725,4.3612185,2.8813972,4.222675,4.2566867,3.0727744,4.147196,3.312664,5.367258,7.0944185,4.3791637,2.786793,4.2553053,3.367788,2.9129255,2.9035776,3.4734662,5.4408937,4.1599617,2.6874888,2.8779438,3.3835404,5.279935,2.938307,2.8451836,2.8584487,6.618501,3.6435351,4.6045504,2.3124723,3.580136,5.0861063,4.1383643,4.79955,4.249299,6.2847323,3.0473294,4.84362,3.8314352,2.9669569,5.019312,4.306425,5.2177143,2.0396636,4.0556817,2.7937436,3.826335,2.906521,3.3626857,4.117459,4.9264164,5.0503173,4.065538,4.797937,5.527193,6.054091,3.5468643,4.517993,2.4171448,2.3725662,2.7335787,4.184274,4.092416,4.8367963,4.3289237,3.0984848,3.12499,2.9281013,4.7948074,4.6529574,4.3004565,3.1396506,4.1271877,4.586088,3.9999714,3.9009123,3.9376335,4.318675,4.2395897,3.2928472,3.9351573,5.161763,5.0732813,3.0083003,3.5711184,3.4940605,3.2436495,3.6407743,3.2962134,6.6298785,4.8319473,6.947239,2.4297566,7.1272955,7.167999,5.0256734,6.6681705,4.9802985,3.2116642,7.071107,3.195844,2.3311467,2.9500747,2.930522,5.7544136,5.6270366,5.6885858,3.3081698,3.1714232,6.231448,5.488553,4.732146,4.5796633,5.2349453,4.407255,3.2806482,3.680995,3.977511,2.9165,2.8488896,3.271023,7.1024175,3.0014307,4.332113,2.0765948,3.1971004,4.645287,4.8186884,3.659989,2.1713758,5.0102024,1.958081,7.033653,3.2350528,2.5659904,5.0093136,5.1768513,4.257629,4.672001,4.9313,5.050578,2.4726343,5.2823534,4.353829,5.05526,4.8448424,2.1087105,2.0854282,2.9532933,5.3571577,5.3314195,3.0818832,4.615818,3.4822264,5.2794886,6.023805,7.093728,6.9698296,4.8469973,5.1387963,4.8973775,5.3461204,3.017094,5.2377844,4.7747235,5.294359,2.9365904,4.8744373,3.6637974,3.2532072,2.88294,3.7094555,2.7946491,3.4155517,4.52044,3.5280888,3.7294936,3.5911822,3.9340553,3.847582,3.4078522,2.8040318,2.5346162,2.5307138,2.3779507,2.4012156,2.4645789,6.5236197,3.7922318,3.2601626,3.3661141,5.0065417,4.2586794,5.417776,4.1542635,3.4165227,4.4038215,2.9818501,2.812211,4.7809167,3.6191838,3.5598953,2.4030154,3.7273054,3.3331554,5.0508633,5.198132,3.1313643,2.6666627,5.3713374,3.9429538,2.515028,5.116787,3.7599146,4.12366,3.5763574,3.6981423,6.381844,4.0197396,3.2006142,3.8109636,3.4763014,3.4019768,3.6338875,3.6789432,4.55128,6.375018,4.3965435,2.5002801,2.5991757,3.6172316,2.5229685,4.697928,6.343769,3.2606518,3.0750608,3.9297755,2.7131133,3.501994,6.207261,3.3496706,2.3391614,3.7192938,2.3615084,2.422832,4.050522,2.7268424,2.950748,3.421016,2.1770105,2.2648036,2.5682728,3.6901228,2.3772254,2.4060214,4.034661,2.5133667,3.2686236,2.7681441,3.7415535,2.582848,4.629154,2.2144284,2.1254885,2.3779619,2.088626,2.9777343,5.2685847,5.812616,2.4939313,4.0741963,2.7691672,2.7444673,5.5526476,5.7391725,5.8528423,2.7612343,2.4446588,1.9947929,2.6808052,6.6606708,5.0833974,2.952037,6.7195625,7.038827,6.8732576,2.5900621,2.5466018,4.4844456,4.3411546,5.1366324,4.96359,2.4676826,2.3059525,2.3987136,4.8903637,5.0069575,2.9303515,3.1254117,4.652657,2.406032,3.955699,3.950503,5.3815575,5.021252,4.516693,3.2318232,4.933379,2.892577,2.8892047,2.9432552,5.0575824,6.6219587,5.026614,3.0132816,3.2769654,2.547939,2.7586071,4.868707,4.152234,3.8033254,3.1974723,3.2833178,2.8694196,4.5158525,2.7024996,3.3740046,4.6574664,4.2454257,3.1974695,5.2257385,4.474732],\"z\":[1.597115,1.4040985,0.56873894,2.3482664,0.28815967,0.0577909,-0.3711383,1.5885301,-0.38726866,1.5746673,1.7288362,-1.4364716,2.2467835,6.372893,1.7583683,0.28420895,1.2953401,1.0346291,0.82514125,1.6306762,1.44627,1.6261476,1.7499812,1.6364188,0.31702727,0.07667508,1.2561134,0.36233562,0.084540874,2.8127077,1.375774,-1.3587782,6.4108615,-0.008416452,0.29424304,0.35336155,1.5391297,-1.6887337,-1.3400147,-1.4688425,1.183232,-0.047498208,0.13055952,2.3347366,0.27907,2.033243,-0.14747806,1.3832407,-1.2838409,0.30408177,1.6879056,-1.5580541,1.4947087,0.95019984,1.5658317,-1.522944,1.5490892,1.5842917,2.8907042,1.5715631,0.2020678,0.28936672,6.655929,5.9640455,2.6286845,1.8860567,3.3282301,6.3896937,5.8994956,2.2747042,1.6272068,1.7076904,1.4252123,-0.081824765,-0.054339223,7.900694,7.050493,6.6017194,-1.3042057,0.27003697,0.7588003,7.655701,1.8520631,0.23581149,6.6171064,7.358638,7.3016543,-1.3807702,7.549993,6.6706147,6.641187,1.0155174,7.7989717,6.5487976,4.9762707,6.8368397,6.967032,6.4984784,5.9352536,7.8485394,7.93621,5.9167323,5.56516,5.641441,5.9877863,5.817622,6.564076,6.976906,3.9746192,6.49044,3.358315,0.4534994,7.7734885,7.93577,7.9062,7.905728,0.6775936,0.70042706,0.24506262,0.8462817,0.68533665,7.762842,7.8456793,7.8101344,6.7804055,0.1956968,7.673202,1.7504516,7.489009,6.165646,6.2549424,6.188255,6.613795,7.185719,7.047751,7.1809998,6.1985445,5.606114,6.421231,4.778627,7.755827,1.9907122,0.2965994,0.7872465,7.3736672,6.5156436,6.5070367,7.049634,6.7138677,7.4520125,6.276244,6.724056,7.623963,7.289115,1.6551368,6.0223145,6.9305315,7.7568607,0.6093366,-1.209289,0.9134055,-1.690185,6.2683306,0.20667592,5.908134,1.3358719,1.6651198,2.2870367,2.2562783,1.3333032,1.4094486,0.40873328,0.30310234,0.31889838,0.4110444,0.41505998,3.1750233,2.4315927,0.028070994,3.0119383,-0.4058562,1.5237156,-1.6072407,-0.4707545,2.5754836,0.41872066,5.909117,1.0757637,0.6343729,-0.35570174,0.88723344,2.7266145,3.2211504,-1.284876,0.48941913,-0.4428329,1.5286254,2.89143,2.0205834,0.8868841,1.5956713,0.9081355,0.6864587,6.8225374,1.0842228,0.4687243,1.9480305,1.3727806,1.2551413,-0.43675354,1.078024,1.6076782,6.382882,-1.5897367,0.27059957,0.33453143,-1.6756365,0.32672212,-0.17491254,-0.010745455,1.7926961,-0.22695503,3.3478208,1.2691077,3.2892046,4.0045414,-0.16090038,0.20558849,-0.074269064,0.10592724,0.4164369,0.97687477,1.475353,1.5230707,0.5330067,2.33983,2.36558,1.3314011,0.048683316,0.11762786,0.3259014,-0.35061106,0.8031753,0.8326804,-1.7122091,-0.13115135,0.8355517,1.324558,-1.4861832,0.05326864,-0.23665287,1.9585124,0.27853063,0.24156633,0.13058542,0.16227713,0.834783,0.23642842,0.25179663,0.6971597,1.975932,0.53108424,1.8083,2.3115413,0.43971995,1.9647204,6.680239,0.55042833,6.2415915,1.7614539,6.031086,5.992862,0.50672394,6.4901114,0.24628523,2.1951854,5.7320805,-1.4303313,2.0963202,1.3648039,1.7488211,6.9301395,6.865708,6.7379208,1.0717609,0.9944256,1.6202368,0.8700265,0.74343914,0.7315405,0.8463036,0.7618561,0.97788554,0.37141985,0.15795758,3.0714395,2.0910125,0.82993764,6.1008134,3.0504916,-0.32964396,1.9123994,0.8611405,0.35215622,0.09732054,-0.27489227,2.0475223,1.3407221,1.8635898,5.9335785,2.6291082,0.9181274,0.19670117,0.80225873,0.24124041,0.28635502,0.4792222,0.7867388,1.5333861,0.0623794,-0.41522965,1.327103,0.6342648,2.017297,1.9349922,2.3075016,0.24923854,0.40415668,2.3756967,0.66779286,0.96577185,0.18858786,1.4576297,5.9913073,6.1953616,0.8094337,0.26125535,0.21520685,0.3255711,1.6951413,0.35263205,0.58521515,0.35680926,-1.7044514,0.47484747,-0.12727465,5.463402,2.7048032,0.44124988,5.546421,5.349732,6.747092,5.215561,6.4719663,6.419895,4.82472,4.802267,4.789048,4.842099,5.069284,4.65832,4.8562746,4.886062,4.4856863,6.5651917,5.7711053,5.3750234,6.0854344,6.85731,5.7619233,6.4686346,6.0450068,5.8978667,6.5786133,5.7994733,5.737448,6.0218086,5.42883,6.119964,2.1937935,6.368954,4.1315355,7.7753057,7.8795342,6.0139494,4.696834,7.7275324,5.7063885,5.21053,7.8383336,5.680693,5.872874,6.4093986,5.5764456,6.6574473,5.612159,5.2607408,4.6424475,5.937225,5.9231043,5.5239644,5.5527673,5.8628745,6.633184,5.8513618,5.2029934,4.4775143,4.83362,4.399389,5.8497906,6.7141194,5.9872456,5.8825326,5.127558,4.940207,5.2325363,6.6645947,4.2854195,4.9217114,6.333104,4.9522033,5.015837,5.7595296,5.250569,5.419873,5.1395316,2.1067321,4.827834,5.1723285,-0.31240788,4.634209,1.8234634,-0.4091133,4.3668556,4.32239,1.2155352,-0.13221389,1.2195092,0.3912087,1.3435047,1.2953745,1.1725239,1.7285048,-1.6621801,0.72388536,7.5520635,2.159765,-0.5204007,2.395491,1.0763851,6.5798473,6.438384,7.6449695,2.4790154,2.4528747,1.6136196,1.6998614,6.6694336,0.22743286,1.6386417,6.4725113,6.137247,6.3700533,0.7486996,1.1806021,-0.20027351,1.3416364,0.048145793,0.44467515,1.1699089,1.1615536,1.0131642,1.365632,1.3699826,0.7214599,2.779712,1.4928546,2.1991618,0.114312105,0.14524952,0.24511807,1.1969677,-0.34443325,2.4040084,0.4753513,1.9963543,2.3619633,3.1302948,0.4100492,6.36513,0.1700656,3.342392,1.572581,1.1945641,1.4356716,1.475304,0.4904391,-0.09549715,2.4173944,2.382439,2.341324,1.2621604,1.7614453,2.356969,1.53408,1.8611115,-1.2423773,0.9404049,0.4176471]}],                        {\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"cluster\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"height\":800,\"legend\":{\"itemsizing\":\"constant\",\"tracegroupgap\":0},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"3D Topological Manifold with Cluster & Size Projection\"},\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2c2de7be-57d5-4f46-a785-a5433cab2132');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Mixed Linear Model Regression Results\n",
            "================================================================\n",
            "Model:            MixedLM Dependent Variable: vesicle_cloud_size\n",
            "No. Observations: 509     Method:             REML              \n",
            "No. Groups:       7       Scale:              407968894.3431    \n",
            "Min. group size:  40      Log-Likelihood:     -5756.4630        \n",
            "Max. group size:  100     Converged:          Yes               \n",
            "Mean group size:  72.7                                          \n",
            "----------------------------------------------------------------\n",
            "              Coef.     Std.Err.   z   P>|z|   [0.025    0.975] \n",
            "----------------------------------------------------------------\n",
            "Intercept     18147.877 2177.998 8.332 0.000 13879.079 22416.675\n",
            "cluster         895.848  342.206 2.618 0.009   225.136  1566.560\n",
            "Group Var  14877515.642  598.330                                \n",
            "================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.4.2.min.js\"></script>                <div id=\"c65e5658-7218-4556-8f70-f3bbda3d294f\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c65e5658-7218-4556-8f70-f3bbda3d294f\")) {                    Plotly.newPlot(                        \"c65e5658-7218-4556-8f70-f3bbda3d294f\",                        [{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 0\",\"type\":\"scatter\",\"x\":[1.0,579.4040404040404,1157.8080808080808,1736.2121212121212,2314.6161616161617,2893.0202020202023,3471.4242424242425,4049.8282828282827,4628.232323232323,5206.636363636364,5785.040404040405,6363.444444444444,6941.848484848485,7520.252525252526,8098.656565656565,8677.060606060606,9255.464646464647,9833.868686868687,10412.272727272728,10990.676767676769,11569.08080808081,12147.484848484848,12725.888888888889,13304.29292929293,13882.69696969697,14461.10101010101,15039.505050505051,15617.909090909092,16196.31313131313,16774.717171717173,17353.121212121212,17931.525252525254,18509.929292929293,19088.333333333332,19666.737373737375,20245.141414141413,20823.545454545456,21401.949494949495,21980.353535353537,22558.757575757576,23137.16161616162,23715.565656565657,24293.969696969696,24872.37373737374,25450.777777777777,26029.18181818182,26607.58585858586,27185.9898989899,27764.39393939394,28342.79797979798,28921.20202020202,29499.60606060606,30078.010101010103,30656.41414141414,31234.818181818184,31813.222222222223,32391.62626262626,32970.030303030304,33548.43434343435,34126.83838383838,34705.242424242424,35283.64646464647,35862.05050505051,36440.454545454544,37018.85858585859,37597.26262626263,38175.666666666664,38754.07070707071,39332.47474747475,39910.87878787879,40489.28282828283,41067.68686868687,41646.09090909091,42224.49494949495,42802.89898989899,43381.30303030303,43959.707070707074,44538.11111111111,45116.51515151515,45694.919191919194,46273.32323232324,46851.72727272727,47430.131313131315,48008.53535353536,48586.93939393939,49165.343434343435,49743.74747474748,50322.15151515152,50900.555555555555,51478.9595959596,52057.36363636364,52635.767676767675,53214.17171717172,53792.57575757576,54370.9797979798,54949.38383838384,55527.78787878788,56106.19191919192,56684.59595959596,57263.0],\"y\":[0.000015551260666445904,0.000016716117325227943,0.000017883926888780322,0.000019046263319455328,0.000020194550229725237,0.000021320163918745584,0.000022414543203185208,0.00002346930752649361,0.00002447638406351187,0.00002542814335292148,0.000026317541503878757,0.000027138265394380704,0.00002788487569236343,0.0000285529411762482,0.000029139156883678615,0.000029641438214802966,0.00003005898334952624,0.000030392297238202723,0.00003064317196268076,0.000030814620352078165,0.000030910762238583436,0.000030936665479682336,0.0000308981466595563,0.0000308015390132613,0.00003065343740162301,0.000030460431935045642,0.000030228842968068205,0.000029964470574428924,0.00002967237122433721,0.000029356673232184757,0.00002902044068439979,0.000028665593099548082,0.000028292885160908966,0.000027901947669977094,0.00002749138759047883,0.0000270589418853467,0.000026601676985404213,0.000026116223340165567,0.000025599032728589007,0.000025046644950325263,0.000024455950227932352,0.000023824434129087287,0.000023150393016693012,0.00002243310986059553,0.000021672982567094414,0.00002087159964508171,0.000020031760860223392,0.0000191574433598718,0.000018253716421185163,0.00001732661034428353,0.000016382946971019815,0.000015430140781158595,0.000014475980459062462,0.000013528401226098014,0.000012595258116963173,0.000011684109786312977,0.000010802021428163378,9.95539405008492e-6,9.149825750324753e-6,8.39000888537343e-6,7.679665175007017e-6,7.021518956105162e-6,6.4173070458808156e-6,5.867822083652796e-6,5.372984853787941e-6,4.931940006262877e-6,4.543168827811778e-6,4.204612302877716e-6,3.913797649334246e-6,3.66796181055592e-6,3.4641660058912896e-6,3.299396341971696e-6,3.170646609424021e-6,3.0749806650241047e-6,3.0095731540874906e-6,2.9717286871412028e-6,2.9588808775892047e-6,2.96857380952384e-6,2.998429483351222e-6,3.0461055390961524e-6,3.1092480523488006e-6,3.1854444162743787e-6,3.2721812560567956e-6,3.3668119710222736e-6,3.466537876399344e-6,3.5684060443720252e-6,3.6693258583501322e-6,3.7661050443452243e-6,3.855504592159811e-6,3.934310603111775e-6,3.99941978705498e-6,4.047934172028043e-6,4.07725967633017e-6,4.08520260710519e-6,4.070057955211151e-6,4.030683590257513e-6,3.9665551261617625e-6,3.877797293867827e-6,3.7651890552501595e-6,3.6301413201929284e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 1\",\"type\":\"scatter\",\"x\":[1.0,1047.888888888889,2094.777777777778,3141.666666666667,4188.555555555556,5235.444444444444,6282.333333333334,7329.222222222223,8376.111111111111,9423.0,10469.888888888889,11516.777777777777,12563.666666666668,13610.555555555557,14657.444444444445,15704.333333333334,16751.222222222223,17798.111111111113,18845.0,19891.88888888889,20938.777777777777,21985.666666666668,23032.555555555555,24079.444444444445,25126.333333333336,26173.222222222223,27220.111111111113,28267.0,29313.88888888889,30360.777777777777,31407.666666666668,32454.555555555555,33501.444444444445,34548.333333333336,35595.222222222226,36642.11111111111,37689.0,38735.88888888889,39782.77777777778,40829.666666666664,41876.555555555555,42923.444444444445,43970.333333333336,45017.222222222226,46064.11111111111,47111.0,48157.88888888889,49204.77777777778,50251.66666666667,51298.555555555555,52345.444444444445,53392.333333333336,54439.222222222226,55486.11111111111,56533.0,57579.88888888889,58626.77777777778,59673.66666666667,60720.555555555555,61767.444444444445,62814.333333333336,63861.222222222226,64908.11111111111,65955.0,67001.88888888889,68048.77777777778,69095.66666666667,70142.55555555556,71189.44444444445,72236.33333333333,73283.22222222222,74330.11111111111,75377.0,76423.88888888889,77470.77777777778,78517.66666666667,79564.55555555556,80611.44444444445,81658.33333333333,82705.22222222222,83752.11111111111,84799.0,85845.88888888889,86892.77777777778,87939.66666666667,88986.55555555556,90033.44444444445,91080.33333333333,92127.22222222222,93174.11111111111,94221.0,95267.88888888889,96314.77777777778,97361.66666666667,98408.55555555556,99455.44444444445,100502.33333333334,101549.22222222222,102596.11111111111,103643.0],\"y\":[0.000019644499225807073,0.000021081500700926775,0.000022389780194117446,0.000023541182575583623,0.000024512419983307326,0.00002528594327523019,0.00002585044931053142,0.000026201009767923455,0.000026338841994603947,0.000026270772766331794,0.000026008468429407313,0.000025567517496871335,0.00002496645365029838,0.000024225799003630154,0.000023367191449301486,0.000022412638869520954,0.00002138392031657507,0.000020302133206488378,0.000019187368824694423,0.00001805848778745718,0.0000169329632099459,0.000015826761759810135,0.0000147542401339765,0.000013728044747756671,0.000012759013263956615,0.000011856085842897292,0.000011026239975189506,0.00001027446451900777,9.603786007669693e-6,9.015354147099038e-6,8.508585061414186e-6,8.081352019706685e-6,7.73020588907952e-6,7.450602936647722e-6,7.237116837644351e-6,7.083615126557632e-6,6.98338739650709e-6,6.929222188846872e-6,6.9134401265425846e-6,6.927900626908e-6,6.964006760745133e-6,7.01273614690816e-6,7.064724409610157e-6,7.110421624839445e-6,7.140332031108665e-6,7.145334425874298e-6,7.117066930723379e-6,7.04834721192474e-6,6.933589720181654e-6,6.769176606524103e-6,6.553739588826325e-6,6.288316309301926e-6,5.976355945418207e-6,5.623563604090492e-6,5.237589424271101e-6,4.827584204957899e-6,4.403656743300493e-6,3.976277299247845e-6,3.555675719558171e-6,3.1512815180781666e-6,2.7712471108699543e-6,2.4220855292245853e-6,2.1084417464141585e-6,1.8330038483400488e-6,1.596548132986236e-6,1.3981020142425323e-6,1.2352010933349578e-6,1.1042122669834616e-6,1.000693195156264e-6,9.197594890436735e-7,8.564340621654371e-7,8.05957609668316e-7,7.640445567510599e-7,7.27074528634715e-7,6.922150094207521e-7,6.57476026463512e-7,6.217021438876732e-7,5.84510562249404e-7,5.461865571481761e-7,5.075487821884035e-7,4.697971371885579e-7,4.343550864108283e-7,4.0271672245597633e-7,3.7630679707789107e-7,3.563596969279617e-7,3.4382122511566273e-7,3.3927528279742926e-7,3.42896245606607e-7,3.5442699177832785e-7,3.731820449934948e-7,3.9807495254822114e-7,4.2766861384259467e-7,4.602466280051239e-7,4.939027537592638e-7,5.266442998822476e-7,5.565038437986438e-7,5.816523578862039e-7,6.005059015598508e-7,6.118177855359511e-7,6.147487215850118e-7]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 2\",\"type\":\"scatter\",\"x\":[1.0,747.10101010101,1493.20202020202,2239.30303030303,2985.40404040404,3731.5050505050503,4477.60606060606,5223.707070707071,5969.80808080808,6715.90909090909,7462.010101010101,8208.111111111111,8954.21212121212,9700.31313131313,10446.414141414141,11192.51515151515,11938.61616161616,12684.717171717171,13430.81818181818,14176.91919191919,14923.020202020201,15669.12121212121,16415.222222222223,17161.32323232323,17907.42424242424,18653.52525252525,19399.62626262626,20145.727272727272,20891.828282828283,21637.92929292929,22384.0303030303,23130.13131313131,23876.23232323232,24622.333333333332,25368.434343434343,26114.535353535353,26860.63636363636,27606.73737373737,28352.83838383838,29098.939393939392,29845.040404040403,30591.141414141413,31337.24242424242,32083.34343434343,32829.444444444445,33575.54545454545,34321.64646464646,35067.74747474747,35813.84848484848,36559.94949494949,37306.0505050505,38052.15151515151,38798.25252525252,39544.35353535353,40290.454545454544,41036.555555555555,41782.656565656565,42528.757575757576,43274.85858585858,44020.95959595959,44767.0606060606,45513.16161616161,46259.26262626262,47005.36363636363,47751.46464646464,48497.56565656565,49243.666666666664,49989.767676767675,50735.868686868685,51481.969696969696,52228.07070707071,52974.17171717171,53720.27272727272,54466.37373737373,55212.47474747474,55958.57575757575,56704.67676767676,57450.777777777774,58196.878787878784,58942.979797979795,59689.080808080806,60435.181818181816,61181.28282828283,61927.38383838384,62673.48484848484,63419.58585858585,64165.68686868686,64911.78787878787,65657.88888888889,66403.9898989899,67150.0909090909,67896.19191919192,68642.29292929292,69388.39393939394,70134.49494949494,70880.59595959596,71626.69696969696,72372.79797979798,73118.89898989898,73865.0],\"y\":[0.000015789935123526984,0.000016500226215078927,0.000017157283562540743,0.000017755383205579897,0.00001828996665792368,0.000018757723306263933,0.000019156628020011017,0.00001948593390447852,0.000019746122428007704,0.000019938815249151893,0.00002006665382519948,0.0000201331541884424,0.000020142545059423978,0.00002009959769726636,0.00002000945558042826,0.000019877471222579287,0.0000197090562484284,0.000019509549399710824,0.000019284105542815285,0.000019037607139486114,0.000018774598143648005,0.000018499239003572193,0.000018215280454330977,0.000017926053123210645,0.000017634469649164164,0.000017343036013619516,0.000017053869044763257,0.00001676871752255444,0.00001648898489869821,0.000016215752274929944,0.000015949800881708553,0.00001569163380930325,0.000015441497124522615,0.000015199400740135825,0.000014965139492075505,0.00001473831484132886,0.000014518357485859903,0.00001430455098338103,0.000014096056290178463,0.000013891936952028976,0.00001369118456895438,0.000013492744112248738,0.000013295538702271133,0.000013098493548145943,0.00001290055888410248,0.00001270073188288713,0.000012498077653054659,0.000012291749504775575,0.000012081008675575046,0.000011865243630908985,0.000011643988894928552,0.000011416943137492252,0.000011183985969712906,0.000010945192616602285,0.000010700845381572929,0.000010451440634177671,0.000010197689975695828,9.940514294263194e-6,9.681029626775987e-6,9.42052409827244e-6,9.16042569449059e-6,8.902261208363662e-6,8.647607342371948e-6,8.398035593307954e-6,8.155053137732505e-6,7.920042420348274e-6,7.694202475637456e-6,7.478495148801122e-6,7.273599303759572e-6,7.0798758094526955e-6,6.897345594535634e-6,6.725682385303155e-6,6.564220937195305e-6,6.411980692094948e-6,6.2677039034446605e-6,6.1299064316319566e-6,5.996938681773665e-6,5.867053585065408e-6,5.7384781510309415e-6,5.609484964119691e-6,5.478460070625106e-6,5.343963990905799e-6,5.204783072307522e-6,5.059969032144893e-6,4.908865280225144e-6,4.7511194036457325e-6,4.586681988426135e-6,4.4157926909650455e-6,4.238955111657755e-6,4.056902526926259e-6,3.870556879634509e-6,3.6809835993953182e-6,3.4893448245930524e-6,3.2968534401341952e-6,3.104730052457523e-6,2.9141646275624274e-6,2.7262840550985056e-6,2.5421264100669436e-6,2.36262220030457e-6,2.1885824454876545e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 3\",\"type\":\"scatter\",\"x\":[981.0,2103.2323232323233,3225.4646464646466,4347.69696969697,5469.929292929293,6592.161616161617,7714.39393939394,8836.626262626263,9958.858585858587,11081.09090909091,12203.323232323233,13325.555555555557,14447.78787878788,15570.020202020203,16692.252525252527,17814.484848484848,18936.717171717173,20058.9494949495,21181.18181818182,22303.41414141414,23425.646464646466,24547.87878787879,25670.111111111113,26792.343434343435,27914.57575757576,29036.808080808085,30159.040404040406,31281.272727272728,32403.505050505053,33525.73737373738,34647.969696969696,35770.20202020202,36892.43434343435,38014.66666666667,39136.898989899,40259.131313131315,41381.36363636364,42503.595959595965,43625.82828282828,44748.06060606061,45870.29292929293,46992.52525252526,48114.75757575758,49236.9898989899,50359.222222222226,51481.45454545455,52603.68686868687,53725.919191919194,54848.15151515152,55970.383838383845,57092.61616161617,58214.84848484849,59337.08080808081,60459.31313131314,61581.545454545456,62703.77777777778,63826.010101010106,64948.24242424243,66070.47474747476,67192.70707070708,68314.93939393939,69437.17171717172,70559.40404040404,71681.63636363637,72803.8686868687,73926.10101010102,75048.33333333334,76170.56565656567,77292.797979798,78415.0303030303,79537.26262626263,80659.49494949495,81781.72727272728,82903.9595959596,84026.19191919193,85148.42424242425,86270.65656565657,87392.88888888889,88515.12121212122,89637.35353535354,90759.58585858587,91881.81818181819,93004.05050505052,94126.28282828284,95248.51515151517,96370.74747474748,97492.9797979798,98615.21212121213,99737.44444444445,100859.67676767678,101981.9090909091,103104.14141414143,104226.37373737374,105348.60606060606,106470.83838383839,107593.07070707071,108715.30303030304,109837.53535353536,110959.76767676769,112082.0],\"y\":[0.00001844118706962236,0.000019247968143638806,0.000019957684496016876,0.000020560941269707925,0.000021050578239810817,0.00002142178271587586,0.00002167210984538987,0.000021801417358197725,0.000021811726693359684,0.000021707025935629272,0.000021493031814340525,0.00002117692813078449,0.000020767096521159195,0.000020272852739637293,0.000019704198093273884,0.000019071591776481656,0.000018385746137503905,0.000017657443800676056,0.000016897373390326434,0.000016115979530311023,0.000015323322840616706,0.000014528946678877505,0.000013741749114756996,0.000012969860732432786,0.000012220530955195483,0.000011500027324570422,0.000010813553262908728,0.000010165190126260447,9.55786875943051e-6,8.99337436643687e-6,8.472386483138176e-6,7.994553438193094e-6,7.558598207267313e-6,7.162450296498066e-6,6.803396489596146e-6,6.478242145658923e-6,6.1834743421206984e-6,5.91541852665477e-6,5.67038139375547e-6,5.444774286264168e-6,5.235213342753297e-6,5.03859465264192e-6,4.852144634026258e-6,4.673447537121095e-6,4.500453269239154e-6,4.331469562491525e-6,4.165142847958839e-6,4.000432097138267e-6,3.8365794210158315e-6,3.6730804834822604e-6,3.509656904272289e-6,3.3462319091056435e-6,3.1829096283578374e-6,3.0199577248856456e-6,2.8577924946866363e-6,2.696965252577217e-6,2.538148687260927e-6,2.3821219257406336e-6,2.229753253053573e-6,2.0819797499665098e-6,1.9397834969068185e-6,1.8041644073191694e-6,1.6761101624913108e-6,1.5565640928930199e-6,1.4463921641890482e-6,1.3463504607059617e-6,1.2570547015312048e-6,1.1789533653746628e-6,1.112305935026867e-6,1.0571676006271633e-6,1.0133814882432902e-6,9.80579117686399e-7,9.58189358779918e-7,9.454556728077997e-7,9.414609259620565e-7,9.451585793194022e-7,9.554086326592042e-7,9.710163642060445e-7,9.907716980376901e-7,1.0134869706893767e-6,1.0380309726492929e-6,1.063357409603627e-6,1.0885263480240933e-6,1.1127177505776593e-6,1.1352368262061146e-6,1.1555115650313958e-6,1.1730834418598157e-6,1.1875927969813088e-6,1.1987607888518777e-6,1.206370022084922e-6,1.2102459647902122e-6,1.2102410801930109e-6,1.2062232274962439e-6,1.198069373685178e-6,1.1856650538751207e-6,1.1689093846161261e-6,1.147724836609416e-6,1.122070470402397e-6,1.091956979689331e-6,1.0574617045931651e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 4\",\"type\":\"scatter\",\"x\":[1.0,544.2727272727273,1087.5454545454545,1630.8181818181818,2174.090909090909,2717.363636363636,3260.6363636363635,3803.909090909091,4347.181818181818,4890.454545454545,5433.727272727272,5977.0,6520.272727272727,7063.545454545454,7606.818181818182,8150.090909090909,8693.363636363636,9236.636363636364,9779.90909090909,10323.181818181818,10866.454545454544,11409.727272727272,11953.0,12496.272727272726,13039.545454545454,13582.818181818182,14126.090909090908,14669.363636363636,15212.636363636364,15755.90909090909,16299.181818181818,16842.454545454544,17385.727272727272,17929.0,18472.272727272728,19015.545454545452,19558.81818181818,20102.090909090908,20645.363636363636,21188.636363636364,21731.90909090909,22275.181818181816,22818.454545454544,23361.727272727272,23905.0,24448.272727272728,24991.545454545452,25534.81818181818,26078.090909090908,26621.363636363636,27164.636363636364,27707.90909090909,28251.181818181816,28794.454545454544,29337.727272727272,29881.0,30424.272727272728,30967.545454545452,31510.81818181818,32054.090909090908,32597.363636363636,33140.63636363636,33683.90909090909,34227.181818181816,34770.454545454544,35313.72727272727,35857.0,36400.27272727273,36943.545454545456,37486.818181818184,38030.090909090904,38573.36363636363,39116.63636363636,39659.90909090909,40203.181818181816,40746.454545454544,41289.72727272727,41833.0,42376.27272727273,42919.545454545456,43462.81818181818,44006.090909090904,44549.36363636363,45092.63636363636,45635.90909090909,46179.181818181816,46722.454545454544,47265.72727272727,47809.0,48352.27272727273,48895.545454545456,49438.81818181818,49982.090909090904,50525.36363636363,51068.63636363636,51611.90909090909,52155.181818181816,52698.454545454544,53241.72727272727,53785.0],\"y\":[0.000034550087755142725,0.000035094723887273224,0.00003545934579129529,0.00003564275682162825,0.000035647143102190246,0.00003547794888200439,0.000035143651690534584,0.000034655448425391295,0.00003402686716443374,0.00003327332229910159,0.00003241163240495704,0.000031459521033306396,0.000030435120326073167,0.00002935649609063124,0.000028241210844485347,0.000027105938519385517,0.000025966141200377378,0.000024835814684005016,0.000023727305989792767,0.000022651202456370516,0.000021616288879879935,0.000020629566455298217,0.00001969632516817706,0.000018820259818226964,0.000018003619056226986,0.000017247376659393653,0.00001655141469855066,0.000015914709174525128,0.00001533551001104292,0.000014811508864325103,0.000014339989919290602,0.00001391796056727707,0.000013542260491356528,0.000013209649131951603,0.000012916872699746366,0.000012660712802491295,0.000012438019340961302,0.000012245730615586083,0.000012080883599485852,0.000011940617123545295,0.000011822170344380584,0.000011722878392088648,0.000011640166586731302,0.00001157154412984233,0.000011514597768314902,0.000011466985626966706,0.000011426431230692509,0.000011390717688498353,0.000011357682075518373,0.0000113252101982194,0.00001129123212630034,0.000011253719081706486,0.000011210682450371025,0.000011160175790166618,0.000011100300722047303,0.000011029217494755062,0.000010945160803857344,0.000010846461133340701,0.000010731571494363722,0.000010599098992354139,0.00001044784019792905,0.000010276818869115557,0.00001008532421067391,9.872947594623163e-6,9.639615530005614e-6,9.385616675030641e-6,9.11162083526304e-6,8.81868818036297e-6,8.50826732151495e-6,8.182181395930346e-6,7.842601871276444e-6,7.492010375740624e-6,7.133149442286513e-6,6.768963594241123e-6,6.4025326638606334e-6,6.036999602341071e-6,5.6754952925503296e-6,5.321063005964291e-6,4.976585151824525e-6,4.644714855138713e-6,4.327814682254707e-6,4.0279045241436525e-6,3.746620266942473e-6,3.4851844469967115e-6,3.2443896242187457e-6,3.0245947329928714e-6,2.8257342027039997e-6,2.647339196972556e-6,2.4885699164552636e-6,2.3482575569971604e-6,2.2249542231200643e-6,2.116988874191124e-6,2.02252723277486e-6,1.9396335149867043e-6,1.866331852108543e-6,1.8006653597661174e-6,1.740750971451113e-6,1.684828380256351e-6,1.6313017168855618e-6,1.578772921329007e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 5\",\"type\":\"scatter\",\"x\":[1.0,892.1717171717172,1783.3434343434344,2674.5151515151515,3565.686868686869,4456.858585858586,5348.030303030303,6239.20202020202,7130.373737373738,8021.545454545455,8912.717171717171,9803.888888888889,10695.060606060606,11586.232323232323,12477.40404040404,13368.575757575758,14259.747474747475,15150.919191919193,16042.09090909091,16933.262626262625,17824.434343434343,18715.60606060606,19606.777777777777,20497.949494949495,21389.121212121212,22280.29292929293,23171.464646464647,24062.636363636364,24953.80808080808,25844.9797979798,26736.151515151516,27627.323232323233,28518.49494949495,29409.666666666668,30300.838383838385,31192.010101010103,32083.18181818182,32974.35353535353,33865.52525252525,34756.69696969697,35647.868686868685,36539.0404040404,37430.21212121212,38321.38383838384,39212.555555555555,40103.72727272727,40994.89898989899,41886.07070707071,42777.242424242424,43668.41414141414,44559.58585858586,45450.757575757576,46341.92929292929,47233.10101010101,48124.27272727273,49015.444444444445,49906.61616161616,50797.78787878788,51688.9595959596,52580.131313131315,53471.30303030303,54362.47474747475,55253.64646464647,56144.818181818184,57035.9898989899,57927.16161616162,58818.333333333336,59709.50505050505,60600.67676767677,61491.84848484849,62383.020202020205,63274.19191919192,64165.36363636364,65056.53535353536,65947.70707070707,66838.87878787878,67730.0505050505,68621.22222222222,69512.39393939394,70403.56565656565,71294.73737373737,72185.90909090909,73077.0808080808,73968.25252525252,74859.42424242424,75750.59595959596,76641.76767676767,77532.93939393939,78424.11111111111,79315.28282828283,80206.45454545454,81097.62626262626,81988.79797979798,82879.9696969697,83771.14141414141,84662.31313131313,85553.48484848485,86444.65656565657,87335.82828282828,88227.0],\"y\":[0.000014144797885684062,0.00001499807225963581,0.00001580566046428088,0.000016559315814417995,0.000017252134149335768,0.00001787869832133883,0.000018435155843273015,0.000018919228929456314,0.00001933015992793851,0.00001966859851870008,0.00001993643986004693,0.00002013662497763991,0.000020272916036011413,0.000020349659689743785,0.000020371551502046696,0.000020343413498776247,0.000020269995381432415,0.000020155807863177534,0.00002000499414842168,0.00001982124289812548,0.000019607743272790528,0.000019367179993881442,0.000019101763981318877,0.00001881329216551027,0.00001850322866630724,0.00001817279876777161,0.000017823087035783727,0.000017455131507637934,0.0000170700070537651,0.000016668892644969386,0.00001625311918780807,0.000015824196626812962,0.00001538382096257467,0.000014933863523141594,0.000014476346110742075,0.000014013406432224477,0.000013547258471071604,0.000013080152189668628,0.000012614336233327405,0.000012152026255361309,0.000011695380236625701,0.000011246480887033474,0.000010807324040060584,0.000010379811014255209,9.965742316574143e-6,9.56680985892955e-6,9.184585064975187e-6,8.820500827969583e-6,8.475826171978824e-6,8.151633565870776e-6,7.848760020395467e-6,7.567764233423271e-6,7.3088830127881746e-6,7.07199089329924e-6,6.856567195048768e-6,6.661674699612127e-6,6.485953643004265e-6,6.32763387166896e-6,6.184566847525221e-6,6.054277815545235e-6,5.934036976962405e-6,5.820947066067313e-6,5.712043429315236e-6,5.604401659972375e-6,5.4952471357360165e-6,5.382060497902837e-6,5.262673223008463e-6,5.135347961475122e-6,4.998839210177967e-6,4.852431076273145e-6,4.695950285817147e-6,4.529754086920127e-6,4.354694183272012e-6,4.172059204326031e-6,3.983499380570775e-6,3.790937973251819e-6,3.596474559337066e-6,3.402285473454471e-6,3.210526565503348e-6,3.023242977695245e-6,2.8422899314120865e-6,2.6692676117623177e-6,2.5054722244120824e-6,2.351864255380844e-6,2.2090539651105695e-6,2.0773032570620954e-6,1.9565423261716888e-6,1.8463989426600805e-6,1.7462378712965957e-6,1.6552077565500736e-6,1.5722927966908209e-6,1.4963666516174671e-6,1.4262462425544813e-6,1.3607433707450033e-6,1.2987123768126074e-6,1.239092361662843e-6,1.1809427829562853e-6,1.123471526943468e-6,1.0660548390919482e-6,1.0082487865736625e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 6\",\"type\":\"scatter\",\"x\":[1.0,608.030303030303,1215.060606060606,1822.090909090909,2429.121212121212,3036.151515151515,3643.181818181818,4250.212121212121,4857.242424242424,5464.272727272727,6071.30303030303,6678.333333333333,7285.363636363636,7892.393939393939,8499.424242424242,9106.454545454544,9713.484848484848,10320.515151515152,10927.545454545454,11534.575757575756,12141.60606060606,12748.636363636364,13355.666666666666,13962.696969696968,14569.727272727272,15176.757575757576,15783.787878787878,16390.81818181818,16997.848484848484,17604.878787878788,18211.90909090909,18818.939393939392,19425.969696969696,20033.0,20640.030303030304,21247.060606060604,21854.090909090908,22461.121212121212,23068.151515151512,23675.181818181816,24282.21212121212,24889.242424242424,25496.272727272728,26103.30303030303,26710.333333333332,27317.363636363636,27924.393939393936,28531.42424242424,29138.454545454544,29745.484848484848,30352.515151515152,30959.545454545452,31566.575757575756,32173.60606060606,32780.63636363636,33387.666666666664,33994.69696969697,34601.72727272727,35208.757575757576,35815.78787878788,36422.81818181818,37029.84848484848,37636.878787878784,38243.90909090909,38850.93939393939,39457.969696969696,40065.0,40672.030303030304,41279.06060606061,41886.090909090904,42493.12121212121,43100.15151515151,43707.181818181816,44314.21212121212,44921.242424242424,45528.27272727273,46135.303030303025,46742.33333333333,47349.36363636363,47956.393939393936,48563.42424242424,49170.454545454544,49777.48484848485,50384.51515151515,50991.545454545456,51598.57575757575,52205.60606060606,52812.63636363636,53419.666666666664,54026.69696969697,54633.72727272727,55240.757575757576,55847.78787878787,56454.81818181818,57061.84848484848,57668.878787878784,58275.90909090909,58882.93939393939,59489.969696969696,60097.0],\"y\":[0.00002057265244913173,0.0000216497988521468,0.000022658495698648936,0.00002358802006778816,0.00002442923441956216,0.00002517481199842403,0.00002581939532272178,0.00002635968199008559,0.000026794435876357006,0.000027124425703598647,0.000027352296633109282,0.000027482383753625447,0.000027520478874847654,0.00002747356375160011,0.000027349523673391064,0.000027156855251811732,0.00002690438129108391,0.000026600983966554367,0.000026255365343357413,0.000025875841755211116,0.000025470175953690578,0.000025045448442360663,0.000024607967208494648,0.000024163213292944354,0.000023715818376195274,0.00002326956982745058,0.000022827438430010277,0.000022391624179770962,0.000021963616040327718,0.000021544262196316944,0.000021133848044034677,0.000020732179777912156,0.000020338671884251968,0.00001995243708794118,0.000019572377302884172,0.0000191972739415639,0.000018825875605980717,0.00001845698079737007,0.000018089512942749256,0.00001772258483716944,0.000017355549620820365,0.000016988035702931162,0.000016619963629181107,0.00001625154374856872,0.000015883254615997198,0.000015515803284213198,0.00001515006988735667,0.000014787040081861815,0.000014427729874329116,0.000014073108030027106,0.000013724021544680661,0.000013381129534218873,0.000013044850348297049,0.00001271532577876596,0.00001239240498493418,0.000012075649294045366,0.000011764357478581977,0.000011457609591378636,0.000011154326081482535,0.000010853337829829255,0.000010553462020773313,0.000010253578457373149,9.952701051984956e-6,9.65003975792124e-6,9.34504909587308e-6,9.037460583989483e-6,8.727297695365829e-6,8.414873322955635e-6,8.100771011898622e-6,7.785812316806882e-6,7.471013471683209e-6,7.157535066372679e-6,6.846628582149922e-6,6.539583460466789e-6,6.237677904739755e-6,5.9421359130186826e-6,5.654092195130166e-6,5.374565735583666e-6,5.104441915734937e-6,4.844462386893972e-6,4.59522135268156e-6,4.357166611800364e-6,4.1306036420179505e-6,3.915701156198668e-6,3.712496891757132e-6,3.520902848262204e-6,3.3407096961362652e-6,3.171590572497616e-6,3.0131048942891493e-6,2.8647031031163834e-6,2.7257333781366486e-6,2.5954513014637758e-6,2.473033244857741e-6,2.357593896204773e-6,2.24820790374986e-6,2.1439351388305875e-6,2.043848620423081e-6,1.9470637599510413e-6,1.8527673159566517e-6,1.760244325054963e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 7\",\"type\":\"scatter\",\"x\":[3.0,1025.8080808080808,2048.6161616161617,3071.4242424242425,4094.2323232323233,5117.040404040405,6139.848484848485,7162.656565656565,8185.464646464647,9208.272727272728,10231.08080808081,11253.888888888889,12276.69696969697,13299.505050505051,14322.31313131313,15345.121212121212,16367.929292929293,17390.737373737375,18413.545454545456,19436.353535353537,20459.16161616162,21481.969696969696,22504.777777777777,23527.58585858586,24550.39393939394,25573.20202020202,26596.010101010103,27618.818181818184,28641.62626262626,29664.434343434343,30687.242424242424,31710.050505050505,32732.858585858587,33755.666666666664,34778.47474747475,35801.28282828283,36824.09090909091,37846.89898989899,38869.707070707074,39892.51515151515,40915.32323232324,41938.131313131315,42960.93939393939,43983.74747474748,45006.555555555555,46029.36363636364,47052.17171717172,48074.9797979798,49097.78787878788,50120.59595959596,51143.40404040404,52166.21212121212,53189.020202020205,54211.82828282828,55234.63636363637,56257.444444444445,57280.25252525252,58303.06060606061,59325.868686868685,60348.67676767677,61371.48484848485,62394.29292929293,63417.10101010101,64439.909090909096,65462.71717171717,66485.52525252526,67508.33333333333,68531.14141414141,69553.9494949495,70576.75757575758,71599.56565656565,72622.37373737374,73645.18181818182,74667.9898989899,75690.79797979798,76713.60606060606,77736.41414141415,78759.22222222222,79782.0303030303,80804.83838383839,81827.64646464647,82850.45454545454,83873.26262626263,84896.07070707071,85918.87878787878,86941.68686868687,87964.49494949495,88987.30303030304,90010.11111111111,91032.9191919192,92055.72727272728,93078.53535353535,94101.34343434343,95124.15151515152,96146.9595959596,97169.76767676767,98192.57575757576,99215.38383838384,100238.19191919192,101261.0],\"y\":[0.000013066754561738511,0.000013680122798262198,0.000014258657373254174,0.000014796460749790634,0.00001528812484020215,0.000015728852014589722,0.000016114563593502063,0.000016441992222955715,0.000016708754988412337,0.000016913404715279592,0.000017055457604862692,0.00001713539613874994,0.000017154647019358384,0.00001711553476504436,0.000017021212409044745,0.00001687557152759804,0.000016683134511508627,0.000016448932568960757,0.00001617837338294552,0.000015877102628266346,0.00001555086367211275,0.000015205359737617945,0.000014846122608079529,0.000014478391603941378,0.000014107006094493512,0.00001373631423557197,0.000013370099980687218,0.00001301152972512682,0.00001266311924007731,0.000012326720864908254,0.000012003530276207044,0.000011694111564174759,0.000011398438838541218,0.000011115952170435908,0.00001084562536196176,0.000010586042825071082,0.000010335482744813186,0.000010092003694291456,9.85353195168495e-6,9.617946932913786e-6,9.383162384666795e-6,9.147201268235857e-6,8.90826259118533e-6,8.664778797743097e-6,8.415462696926805e-6,8.159343277720846e-6,7.895790122142438e-6,7.624526470115436e-6,7.345631306419051e-6,7.05953112271853e-6,6.7669822513574e-6,6.4690448681481655e-6,6.1670499161783206e-6,5.862560310352245e-6,5.557327843040822e-6,5.253247226112446e-6,4.95230867628567e-6,4.656550382814189e-6,4.368012093635916e-6,4.088690923798743e-6,3.820500334410263e-6,3.565233058223757e-6,3.324528566200925e-6,3.0998454849337354e-6,2.892439194388286e-6,2.703344665312254e-6,2.5333644413969343e-6,2.38306153758855e-6,2.2527569164322628e-6,2.1425311214531893e-6,2.052229591515346e-6,1.9814711527363143e-6,1.929659183477553e-6,1.8959949705748742e-6,1.8794928176354658e-6,1.878996524317107e-6,1.8931969237526577e-6,1.9206502380078204e-6,1.959797082870593e-6,2.0089820177854444e-6,2.066473589320729e-6,2.1304848530044962e-6,2.1991943756300787e-6,2.270767716537221e-6,2.343379361766172e-6,2.4152350408123468e-6,2.4845942950006404e-6,2.54979309370602e-6,2.6092662154107387e-6,2.6615690313885116e-6,2.7053982575365982e-6,2.739611181368108e-6,2.763242832693741e-6,2.7755205532804173e-6,2.775875436510509e-6,2.7639501546965266e-6,2.739602769111734e-6,2.702906223742557e-6,2.654143353983853e-6,2.593797389909984e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 8\",\"type\":\"scatter\",\"x\":[1.0,694.6161616161617,1388.2323232323233,2081.848484848485,2775.4646464646466,3469.0808080808083,4162.69696969697,4856.313131313132,5549.929292929293,6243.545454545455,6937.161616161617,7630.777777777778,8324.39393939394,9018.010101010103,9711.626262626263,10405.242424242424,11098.858585858587,11792.47474747475,12486.09090909091,13179.70707070707,13873.323232323233,14566.939393939396,15260.555555555557,15954.171717171717,16647.78787878788,17341.404040404042,18035.020202020205,18728.636363636364,19422.252525252527,20115.86868686869,20809.484848484848,21503.10101010101,22196.717171717173,22890.333333333336,23583.9494949495,24277.565656565657,24971.18181818182,25664.797979797982,26358.41414141414,27052.030303030304,27745.646464646466,28439.26262626263,29132.87878787879,29826.49494949495,30520.111111111113,31213.727272727276,31907.343434343435,32600.959595959597,33294.57575757576,33988.19191919192,34681.808080808085,35375.42424242425,36069.04040404041,36762.656565656565,37456.27272727273,38149.88888888889,38843.50505050505,39537.121212121216,40230.73737373738,40924.35353535354,41617.969696969696,42311.58585858586,43005.20202020202,43698.818181818184,44392.43434343435,45086.05050505051,45779.66666666667,46473.282828282834,47166.898989899,47860.51515151515,48554.131313131315,49247.74747474748,49941.36363636364,50634.9797979798,51328.595959595965,52022.21212121213,52715.82828282828,53409.444444444445,54103.06060606061,54796.67676767677,55490.29292929293,56183.909090909096,56877.52525252526,57571.14141414142,58264.75757575758,58958.37373737374,59651.9898989899,60345.606060606064,61039.222222222226,61732.83838383839,62426.45454545455,63120.070707070714,63813.68686868687,64507.30303030303,65200.919191919194,65894.53535353536,66588.15151515152,67281.76767676767,67975.38383838384,68669.0],\"y\":[0.000010125949314463741,0.000010627817574725572,0.000011119428608826268,0.000011597710386625388,0.00001205966390180367,0.000012502403517872819,0.000012923196403830584,0.000013319500358151114,0.000013688999330410566,0.000014029635972431678,0.000014339640586028224,0.000014617555882852259,0.000014862257033967692,0.000015072966562797713,0.000015249263724820994,0.00001539108812009847,0.000015498737399052233,0.000015572859045866186,0.000015614436354720382,0.000015624768848450134,0.000015605447523230934,0.000015558325432228382,0.00001548548424130558,0.000015389197496345935,0.000015271891430266717,0.000015136104204580188,0.000014984444522302029,0.000014819550563871601,0.000014644050184291355,0.000014460523267746052,0.000014271467066453508,0.000014079265255415763,0.000013886161317040522,0.000013694236733080807,0.000013505394310455215,0.000013321346807197902,0.000013143610860257725,0.000012973506053410239,0.000012812158806352415,0.000012660510620037988,0.00001251933008300152,0.000012389227932820285,0.000012270674379392945,0.000012164017835142238,0.000012069504163654287,0.000011987295554013013,0.000011917488153799815,0.000011860127649272334,0.000011815222065702801,0.00001178275117253457,0.000011762672014374652,0.000011754920246512476,0.000011759407128435201,0.000011776012215673145,0.000011804571983463647,0.000011844864808700111,0.000011896592922433418,0.000011959362116469196,0.000012032660136916865,0.00001211583481765369,0.000012208073090865038,0.000012308382054305325,0.000012415573271152847,0.000012528251425384904,0.00001264480835248288,0.00001276342331316271,0.00001288207018020023,0.000012998531971114308,0.000013110422890561382,0.000013215217755870754,0.000013310288378938382,0.000013392946180564923,0.000013460490032678191,0.000013510258072994603,0.000013539682027973974,0.000013546342424288721,0.00001352802297514473,0.000013482762401594153,0.00001340890199324585,0.000013305127326882467,0.000013170502741355027,0.000013004497405371167,0.000012807002101095297,0.000012578336168094898,0.000012319244394612976,0.000012030883990985904,0.000011714802117708502,0.000011372904753359096,0.00001100741796204681,0.000010620842845159727,0.000010215905629666163,9.795504449874168e-6,9.36265441950777e-6,8.920432567604805e-6,8.471924129514009e-6,8.020171550252114e-6,7.5681273808685216e-6,7.118612039933658e-6,6.674277183294247e-6,6.237575187418938e-6]},{\"fill\":\"tozeroy\",\"mode\":\"lines\",\"name\":\"Cluster 9\",\"type\":\"scatter\",\"x\":[1195.0,2159.848484848485,3124.69696969697,4089.5454545454545,5054.39393939394,6019.242424242424,6984.090909090909,7948.939393939394,8913.78787878788,9878.636363636364,10843.484848484848,11808.333333333334,12773.181818181818,13738.030303030304,14702.878787878788,15667.727272727274,16632.57575757576,17597.424242424244,18562.272727272728,19527.121212121212,20491.969696969696,21456.818181818184,22421.666666666668,23386.515151515152,24351.363636363636,25316.21212121212,26281.060606060608,27245.909090909092,28210.757575757576,29175.60606060606,30140.454545454548,31105.303030303032,32070.151515151516,33035.0,33999.84848484849,34964.69696969697,35929.545454545456,36894.39393939394,37859.242424242424,38824.09090909091,39788.93939393939,40753.78787878788,41718.63636363637,42683.48484848485,43648.333333333336,44613.181818181816,45578.030303030304,46542.87878787879,47507.72727272727,48472.57575757576,49437.42424242424,50402.27272727273,51367.121212121216,52331.969696969696,53296.818181818184,54261.66666666667,55226.51515151515,56191.36363636364,57156.21212121212,58121.06060606061,59085.909090909096,60050.757575757576,61015.606060606064,61980.454545454544,62945.30303030303,63910.15151515152,64875.0,65839.84848484848,66804.69696969698,67769.54545454546,68734.39393939394,69699.24242424243,70664.09090909091,71628.93939393939,72593.78787878789,73558.63636363637,74523.48484848485,75488.33333333333,76453.18181818182,77418.0303030303,78382.87878787878,79347.72727272728,80312.57575757576,81277.42424242424,82242.27272727274,83207.12121212122,84171.9696969697,85136.81818181819,86101.66666666667,87066.51515151515,88031.36363636363,88996.21212121213,89961.06060606061,90925.90909090909,91890.75757575758,92855.60606060606,93820.45454545454,94785.30303030304,95750.15151515152,96715.0],\"y\":[0.00001704738185956637,0.000017340020490953088,0.000017577334153325582,0.000017757419810391666,0.000017879012294956085,0.0000179415072380157,0.000017944971949162558,0.000017890143974419097,0.00001777841736950195,0.000017611817036233413,0.000017392961767288554,0.000017125016920103752,0.00001681163788590936,0.000016456905727062137,0.000016065256519242354,0.000015641406050478246,0.000015190271594056158,0.000014716892486758596,0.000014226351208990139,0.000013723696582383864,0.000013213870578145818,0.000012701640071692221,0.00001219153469304155,0.000011687791715565686,0.000011194308706006348,0.000010714604434008337,0.000010251788317333177,9.80853846626941e-6,9.387088193538164e-6,8.989220679122641e-6,8.616271326654563e-6,8.269137221746227e-6,7.948293004194013e-6,7.65381239534473e-6,7.3853945780845306e-6,7.142394607938377e-6,6.92385703697901e-6,6.728551954430824e-6,6.555012685485791e-6,6.401574439280882e-6,6.266413254645515e-6,6.147584654780005e-6,6.043061486512593e-6,5.950770483718183e-6,5.868627155920514e-6,5.794568660657393e-6,5.726584371037417e-6,5.662743897741392e-6,5.601222367654134e-6,5.540322799846752e-6,5.478495454521554e-6,5.4143540626978855e-6,5.3466888748293995e-6,5.274476496136718e-6,5.196886506028812e-6,5.113284889201567e-6,5.023234337240827e-6,4.926491511961307e-6,4.823001395159985e-6,4.712888883582206e-6,4.596447822100164e-6,4.474127701618771e-6,4.346518280161794e-6,4.214332414992257e-6,4.078387419519017e-6,3.939585280218395e-6,3.7988920850374305e-6,3.657317025068783e-6,3.5158913351960514e-6,3.3756475365999297e-6,3.237599334393814e-6,3.102722507334212e-6,2.971937103833767e-6,2.8460912298791126e-6,2.7259466805620038e-6,2.612166628534957e-6,2.505305540661342e-6,2.4058014493681963e-6,2.313970658685569e-6,2.230004917635801e-6,2.153971046471605e-6,2.085812955172121e-6,2.0253559494621178e-6,1.9723131782324253e-6,1.9262940383533545e-6,1.886814319156179e-6,1.853307839900538e-6,1.82513930985283e-6,1.8016181225876074e-6,1.782012784109897e-6,1.7655656685981699e-6,1.7515077960915268e-6,1.7390733332788053e-6,1.7275135315544466e-6,1.7161098354172778e-6,1.7041859187000641e-6,1.6911184354909425e-6,1.6763463062729424e-6,1.6593783969734335e-6,1.6397994883834808e-6]}],                        {\"height\":600,\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Probability Density Functions by Cluster\"},\"width\":1200,\"xaxis\":{\"title\":{\"text\":\"Vesicle Cloud Size\"}},\"yaxis\":{\"title\":{\"text\":\"Density\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c65e5658-7218-4556-8f70-f3bbda3d294f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cluseter3"
      ],
      "metadata": {
        "id": "5LlRHIY17JNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
        "import imageio\n",
        "import torch\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
        "bbox_name=['bbox1']\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Synapse Dataset\")\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='')\n",
        "    parser.add_argument('--bbox_name', type=str, default=['bbox4'], nargs='+')\n",
        "    parser.add_argument('--excel_file', type=str, default='')\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
        "    parser.add_argument('--size', type=tuple, default=(80, 80))\n",
        "    parser.add_argument('--subvol_size', type=int, default=80)\n",
        "    parser.add_argument('--num_frames', type=int, default=80)\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
        "    parser.add_argument('--alpha', type=float, default=0.5)\n",
        "    parser.add_argument('--segmentation_type', type=int, default=4, choices=range(0, 13),\n",
        "                        help='Type of segmentation overlay')\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "args = parse_args()\n",
        "# args.bbox_name=['bbox1','bbox2','bbox3','bbox4','bbox5','bbox6','bbox7',]\n",
        "args.bbox_name=bbox_name\n",
        "args.segmentation_type=5\n",
        "# Load volumes\n",
        "vol_data_dict = {}\n",
        "for bbox_name in args.bbox_name:\n",
        "    raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "        bbox_name=bbox_name,\n",
        "        raw_base_dir=args.raw_base_dir,\n",
        "        seg_base_dir=args.seg_base_dir,\n",
        "        add_mask_base_dir=args.add_mask_base_dir\n",
        "    )\n",
        "    if raw_vol is not None:\n",
        "        vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "\n",
        "# Load synapse data\n",
        "syn_df = pd.concat([\n",
        "    pd.read_excel(os.path.join(args.excel_file, f\"{bbox}.xlsx\")).assign(bbox_name=bbox)\n",
        "    for bbox in args.bbox_name if os.path.exists(os.path.join(args.excel_file, f\"{bbox}.xlsx\"))\n",
        "])\n",
        "\n",
        "# Initialize model\n",
        "processor = Synapse3DProcessor(size=args.size)\n",
        "\n",
        "\n",
        "            # Create dataset and features\n",
        "dataset = SynapseDataset(\n",
        "    vol_data_dict=vol_data_dict,\n",
        "    synapse_df=syn_df,\n",
        "    processor=processor,\n",
        "    segmentation_type=args.segmentation_type,\n",
        "    subvol_size=args.subvol_size,\n",
        "    num_frames=args.num_frames,\n",
        "    alpha=0.5\n",
        ")\n",
        "\n",
        "# Function to load features and perform clustering\n",
        "def load_and_cluster_features(csv_filepath, n_clusters=5):\n",
        "    features_df = pd.read_csv(csv_filepath)\n",
        "\n",
        "    # Extract feature columns (assuming features start with 'feat_')\n",
        "    feature_cols = [col for col in features_df.columns if col.startswith('feat_')]\n",
        "    features = features_df[feature_cols].values\n",
        "\n",
        "    # Perform KMeans clustering\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    features_df['cluster'] = kmeans.fit_predict(features)\n",
        "\n",
        "    return features_df, kmeans, feature_cols\n",
        "\n",
        "# Function to find the closest 2 samples within each cluster\n",
        "def find_closest_samples_in_clusters(features_df, feature_cols, n_samples=2):\n",
        "    closest_samples = []\n",
        "\n",
        "    # For each cluster, find the closest 2 samples\n",
        "    for cluster_id in np.unique(features_df['cluster']):\n",
        "        cluster_samples = features_df[features_df['cluster'] == cluster_id]\n",
        "        cluster_features = cluster_samples[feature_cols].values\n",
        "\n",
        "        # Compute pairwise distances and select the closest pairs\n",
        "        distances = pairwise_distances_argmin_min(cluster_features, cluster_features)\n",
        "\n",
        "        # Select the closest pairs (2 closest samples)\n",
        "        # We assume that distances[0] gives the indices of closest samples within the cluster\n",
        "        for i, sample_idx in enumerate(distances[0][:n_samples]):\n",
        "            closest_samples.append(cluster_samples.iloc[sample_idx])\n",
        "\n",
        "    return closest_samples\n",
        "\n",
        "# Function to get the center slice of a 3D synapse sample\n",
        "def get_center_slice(sample):\n",
        "    \"\"\"\n",
        "    Extract the center slice from a 3D sample.\n",
        "    Assumes the sample is a 3D numpy array.\n",
        "    \"\"\"\n",
        "    # Get the center slice (middle slice in z-direction)\n",
        "    center_slice = sample[sample.shape[0] // 2, :, :]\n",
        "    return center_slice\n",
        "\n",
        "# Function to plot 4 similar samples in a grid for each synapse\n",
        "def plot_synapse_samples(dataset, closest_samples_indices, title='Synapse Samples'):\n",
        "    \"\"\"\n",
        "    Plots 4 sample images of synapses in a grid layout.\n",
        "    `dataset` is the dataset containing synapse 3D data.\n",
        "    `closest_samples_indices` is a list of indices for the samples to plot.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))  # 1 row, 4 columns\n",
        "\n",
        "    for i, sample_idx in enumerate(closest_samples_indices):\n",
        "        # Retrieve the synapse data (3D volume) from the dataset\n",
        "        pixel_values, syn_info, bbox_name = dataset[sample_idx]  # Assuming dataset[index] gives 3D data\n",
        "\n",
        "        # Get the center slice of the sample\n",
        "        center_slice = get_center_slice(pixel_values)\n",
        "        center_slice=center_slice.squeeze()\n",
        "        # Plot the slice\n",
        "        axes[i].imshow(center_slice, cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Sample {i+1}\\n({syn_info[\"bbox_name\"]})')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Function to find 4 closest samples from each cluster\n",
        "def find_closest_samples_in_clusters(features_df, feature_cols, n_samples=4):\n",
        "    closest_samples_per_cluster = {}\n",
        "\n",
        "    # For each cluster, find the closest 4 samples based on feature similarity\n",
        "    for cluster_id in np.unique(features_df['cluster']):\n",
        "        cluster_samples = features_df[features_df['cluster'] == cluster_id]\n",
        "        cluster_features = cluster_samples[feature_cols].values\n",
        "\n",
        "        # Compute pairwise distances and select the closest pairs\n",
        "        distances = pairwise_distances_argmin_min(cluster_features, cluster_features)\n",
        "\n",
        "        # Select the closest samples (4 closest samples)\n",
        "        closest_samples = []\n",
        "        for i, sample_idx in enumerate(distances[0][:n_samples]):\n",
        "            closest_samples.append(cluster_samples.iloc[sample_idx])\n",
        "\n",
        "        # Store the closest samples for each cluster\n",
        "        closest_samples_per_cluster[cluster_id] = closest_samples\n",
        "\n",
        "    return closest_samples_per_cluster\n",
        "color_mapping = {\n",
        "    'bbox1': '#FF0000', 'bbox2': '#00FFFF', 'bbox3': '#FFA500',\n",
        "    'bbox4': '#800080', 'bbox5': '#808080', 'bbox6': '#0000FF', 'bbox7': '#000000'\n",
        "}\n",
        "\n",
        "# Function to reduce features to 2D or 3D using t-SNE\n",
        "def apply_tsne(features_df, feature_cols, n_components=2):\n",
        "    features = features_df[feature_cols].values\n",
        "    tsne = TSNE(n_components=n_components, random_state=42)\n",
        "    tsne_results = tsne.fit_transform(features)\n",
        "    return tsne_results\n",
        "\n",
        "# Function to plot 2D and 3D t-SNE\n",
        "def plot_tsne(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping):\n",
        "    # 2D Plot colored by `bbox_name`\n",
        "    fig_2d = px.scatter(\n",
        "        features_df,\n",
        "        x=tsne_results_2d[:, 0],\n",
        "        y=tsne_results_2d[:, 1],\n",
        "        color=features_df['bbox_name'],\n",
        "        color_discrete_map=color_mapping,\n",
        "        labels={'x': 't-SNE 1', 'y': 't-SNE 2'},\n",
        "        title='2D t-SNE colored by bbox_name'\n",
        "    )\n",
        "    fig_2d.update_traces(marker=dict(size=4))  # Set the size of points to 2\n",
        "\n",
        "    fig_2d.show()\n",
        "\n",
        "    # 2D Plot colored by `cluster`\n",
        "    fig_2d_cluster = px.scatter(\n",
        "        features_df,\n",
        "        x=tsne_results_2d[:, 0],\n",
        "        y=tsne_results_2d[:, 1],\n",
        "        color=kmeans.labels_.astype(str),  # Color by cluster number\n",
        "        labels={'x': 't-SNE 1', 'y': 't-SNE 2'},\n",
        "        title='2D t-SNE colored by cluster'\n",
        "    )\n",
        "    fig_2d_cluster.update_traces(marker=dict(size=4))  # Set the size of points to 2\n",
        "\n",
        "    fig_2d_cluster.show()\n",
        "\n",
        "csv_files = [\n",
        "    'features_seg0_alpha0_5.csv', 'features_seg0_alpha1.csv',\n",
        "    'features_seg1_alpha0_5.csv', 'features_seg1_alpha1.csv',\n",
        "    'features_seg2_alpha0_5.csv', 'features_seg2_alpha1.csv',\n",
        "    'features_seg3_alpha0_5.csv', 'features_seg3_alpha1.csv',\n",
        "    'features_seg4_alpha0_5.csv', 'features_seg4_alpha1.csv',\n",
        "    'features_seg5_alpha0_5.csv', 'features_seg5_alpha1.csv',\n",
        "    'features_seg6_alpha0_5.csv', 'features_seg6_alpha1.csv',\n",
        "    'features_seg7_alpha0_5.csv', 'features_seg7_alpha1.csv',\n",
        "    'features_seg8_alpha0_5.csv', 'features_seg8_alpha1.csv'\n",
        "]\n",
        "\n",
        "\n",
        "# Loop through each CSV file and perform the operations\n",
        "for csv_file in csv_files:\n",
        "    print(f\"Processing {csv_file}\")\n",
        "\n",
        "    # Step 1: Load and cluster features\n",
        "    n_clusters = 10  # You can adjust the number of clusters\n",
        "    features_df, kmeans, feature_cols = load_and_cluster_features(csv_file, n_clusters)\n",
        "\n",
        "    # Step 2: Apply t-SNE to reduce the dimensions to 2D and 3D\n",
        "    tsne_results_2d = apply_tsne(features_df, feature_cols, n_components=2)\n",
        "    # tsne_results_3d = apply_tsne(features_df, feature_cols, n_components=3)\n",
        "\n",
        "    # Step 3: Find closest samples within each cluster\n",
        "    closest_samples_per_cluster = find_closest_samples_in_clusters(features_df, feature_cols, n_samples=4)\n",
        "\n",
        "    # Step 4: Plot the t-SNE results (2D and 3D)\n",
        "    color_mapping = {f'bbox{i}': f'#{i:02x}00{255-i:02x}' for i in range(1, 11)}  # Example color mapping\n",
        "    plot_tsne(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping)\n",
        "\n",
        "    # Step 5: Plot the 4 closest samples for each cluster\n",
        "    for cluster_id, closest_samples in closest_samples_per_cluster.items():\n",
        "        print(f\"Cluster {cluster_id}:\")\n",
        "        # Retrieve the indices of the closest samples from the dataset\n",
        "        closest_sample_indices = [features_df.index.get_loc(sample.name) for sample in closest_samples]\n",
        "\n",
        "        # Plot the samples\n",
        "        plot_synapse_samples(dataset, closest_sample_indices, title=f\"Cluster {cluster_id} - Synapse Samples\")\n",
        "# # Step 1: Load and cluster features\n",
        "# csv_filepath = '/content/drive/MyDrive/csv/features_seg5_alpha0_5.csv'\n",
        "# n_clusters = 10  # Number of clusters you want\n",
        "# features_df, kmeans, feature_cols = load_and_cluster_features(csv_filepath, n_clusters)\n",
        "\n",
        "# # Step 2: Find closest samples within each cluster\n",
        "# closest_samples = find_closest_samples_in_clusters(features_df, feature_cols, n_samples=2)\n",
        "# save_gifs_dir = 'cgifs'  # Directory to save the GIFs\n",
        "\n",
        "# # Example feature columns (replace these with your actual feature columns)\n",
        "# feature_cols = [col for col in features_df.columns if col.startswith('feat_')]\n",
        "\n",
        "# # Step 1: Apply t-SNE to reduce the dimensions to 2D and 3D\n",
        "# tsne_results_2d = apply_tsne(features_df, feature_cols, n_components=2)\n",
        "# tsne_results_3d = apply_tsne(features_df, feature_cols, n_components=3)\n",
        "\n",
        "# # Step 2: Perform KMeans clustering\n",
        "# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "# features_df['cluster'] = kmeans.fit_predict(features_df[feature_cols])\n",
        "# # create_gif_from_samples(dataset, closest_samples, save_gifs_dir, features_df)\n",
        "\n",
        "# # Step 3: Plot the t-SNE results with both 2D and 3D colored by bbox_name and cluster\n",
        "# plot_tsne(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping)\n",
        "\n",
        "# closest_samples_per_cluster = find_closest_samples_in_clusters(features_df, feature_cols, n_samples=4)\n",
        "\n",
        "# # Step 5: Plot the 4 closest samples for each cluster\n",
        "# for cluster_id, closest_samples in closest_samples_per_cluster.items():\n",
        "#     print(f\"Cluster {cluster_id}:\")\n",
        "#     # Retrieve the indices of the closest samples from the dataset\n",
        "#     closest_sample_indices = [features_df.index.get_loc(sample.name) for sample in closest_samples]\n",
        "\n",
        "#     # Plot the samples\n",
        "#     plot_synapse_samples(dataset, closest_sample_indices, title=f\"Cluster {cluster_id} - Synapse Samples (Center Slices)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "2s9ueNZT7NGO",
        "outputId": "bfafab1f-445a-498f-c087-7c37f287c59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing features_seg0_alpha0_5.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'features_seg0_alpha0_5.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-bb63158b1588>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;31m# Step 1: Load and cluster features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# You can adjust the number of clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mfeatures_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_cluster_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Step 2: Apply t-SNE to reduce the dimensions to 2D and 3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-bb63158b1588>\u001b[0m in \u001b[0;36mload_and_cluster_features\u001b[0;34m(csv_filepath, n_clusters)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Function to load features and perform clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_cluster_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Extract feature columns (assuming features start with 'feat_')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features_seg0_alpha0_5.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gif per Cluster"
      ],
      "metadata": {
        "id": "irIiLedsf0dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import imageio\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Define the color mapping for bbox values\n",
        "color_mapping = {\n",
        "    'bbox1': '#FF0000', 'bbox2': '#00FFFF', 'bbox3': '#FFA500',\n",
        "    'bbox4': '#800080', 'bbox5': '#808080', 'bbox6': '#0000FF', 'bbox7': '#000000'\n",
        "}\n",
        "\n",
        "# Function to parse command-line arguments (for file paths and settings)\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Synapse Dataset\")\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='')\n",
        "    parser.add_argument('--bbox_name', type=str, default=['bbox4'], nargs='+')\n",
        "    parser.add_argument('--excel_file', type=str, default='')\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
        "    parser.add_argument('--size', type=tuple, default=(80, 80))\n",
        "    parser.add_argument('--subvol_size', type=int, default=80)\n",
        "    parser.add_argument('--num_frames', type=int, default=80)\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
        "    parser.add_argument('--alpha', type=float, default=0.5)\n",
        "    parser.add_argument('--segmentation_type', type=int, default=4, choices=range(0, 13))\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "# Load volumes and synapse data\n",
        "def load_volumes_and_synapse_data(args):\n",
        "    vol_data_dict = {}\n",
        "    for bbox_name in args.bbox_name:\n",
        "        raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "            bbox_name=bbox_name, raw_base_dir=args.raw_base_dir,\n",
        "            seg_base_dir=args.seg_base_dir, add_mask_base_dir=args.add_mask_base_dir)\n",
        "        if raw_vol is not None:\n",
        "            vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "\n",
        "    syn_df = pd.concat([\n",
        "        pd.read_excel(os.path.join(args.excel_file, f\"{bbox}.xlsx\")).assign(bbox_name=bbox)\n",
        "        for bbox in args.bbox_name if os.path.exists(os.path.join(args.excel_file, f\"{bbox}.xlsx\"))\n",
        "    ])\n",
        "\n",
        "    return vol_data_dict, syn_df\n",
        "\n",
        "# Function to reduce features to 2D or 3D using t-SNE\n",
        "def apply_tsne(features_df, feature_cols, n_components=2):\n",
        "    features = features_df[feature_cols].values\n",
        "    tsne = TSNE(n_components=n_components, random_state=42)\n",
        "    return tsne.fit_transform(features)\n",
        "\n",
        "# Function to perform KMeans clustering\n",
        "def perform_clustering(features_df, feature_cols, n_clusters=5):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    features_df['cluster'] = kmeans.fit_predict(features_df[feature_cols])\n",
        "    return kmeans\n",
        "\n",
        "# Function to find closest samples within each cluster\n",
        "def find_closest_samples_in_clusters(features_df, feature_cols, n_samples=4):\n",
        "    closest_samples = []\n",
        "    for cluster_id in np.unique(features_df['cluster']):\n",
        "        cluster_samples = features_df[features_df['cluster'] == cluster_id]\n",
        "        cluster_features = cluster_samples[feature_cols].values\n",
        "        distances = pairwise_distances_argmin_min(cluster_features, cluster_features)\n",
        "\n",
        "        for i, sample_idx in enumerate(distances[0][:n_samples]):\n",
        "            closest_samples.append(cluster_samples.iloc[sample_idx])\n",
        "\n",
        "    return closest_samples\n",
        "def create_gifs(dataset, samples, save_gifs_dir, features_df):\n",
        "    if not os.path.exists(save_gifs_dir):\n",
        "        os.makedirs(save_gifs_dir, exist_ok=True)\n",
        "\n",
        "    for sample in samples:\n",
        "        # Ensure correct access to sample index\n",
        "        sample_idx = sample.name  # Assuming sample.name corresponds to an index in features_df\n",
        "        if sample_idx not in features_df.index:\n",
        "            print(f\"Warning: Sample index {sample_idx} not found in features dataframe.\")\n",
        "            continue\n",
        "\n",
        "        # Access the sample data\n",
        "        pixel_values, syn_info, bbox_name = dataset[sample_idx]\n",
        "        cluster_id = features_df.loc[sample_idx, 'cluster']\n",
        "\n",
        "        # Denormalize the pixel values\n",
        "        denormalized_cube = pixel_values * torch.tensor([0.229]) + torch.tensor([0.485])\n",
        "        denormalized_cube = torch.clamp(denormalized_cube, 0, 1)\n",
        "        frames = denormalized_cube.squeeze(1).numpy().astype(np.uint8)\n",
        "        frames = np.stack([frames, frames, frames], axis=-1)\n",
        "\n",
        "        gif_name = f\"{bbox_name}_cluster{cluster_id}_{sample.name}\"\n",
        "        output_gif_path = os.path.join(save_gifs_dir, f\"{gif_name}.gif\")\n",
        "\n",
        "        # Save the GIF with 10 FPS\n",
        "        imageio.mimsave(output_gif_path, frames, fps=10)\n",
        "        print(f\"GIF saved at {output_gif_path}\")\n",
        "\n",
        "# Function to plot 2D and 3D UMAP results with color mapping\n",
        "def plot_umap(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping):\n",
        "    # Plot 2D UMAP colored by bbox_name\n",
        "    fig_2d = px.scatter(\n",
        "        features_df,\n",
        "        x=tsne_results_2d[:, 0],\n",
        "        y=tsne_results_2d[:, 1],\n",
        "        color=features_df['bbox_name'],\n",
        "        color_discrete_map=color_mapping,\n",
        "        labels={'x': 'UMAP 1', 'y': 'UMAP 2'},\n",
        "        title='2D UMAP colored by bbox_name'\n",
        "    )\n",
        "    fig_2d.show()\n",
        "\n",
        "    # Plot 2D UMAP colored by cluster\n",
        "    fig_2d_cluster = px.scatter(\n",
        "        features_df,\n",
        "        x=tsne_results_2d[:, 0],\n",
        "        y=tsne_results_2d[:, 1],\n",
        "        color=kmeans.labels_.astype(str),\n",
        "        labels={'x': 'UMAP 1', 'y': 'UMAP 2'},\n",
        "        title='2D UMAP colored by cluster'\n",
        "    )\n",
        "    fig_2d_cluster.show()\n",
        "\n",
        "    # Plot 3D UMAP colored by bbox_name\n",
        "    fig_3d = go.Figure(data=[go.Scatter3d(\n",
        "        x=tsne_results_3d[:, 0],\n",
        "        y=tsne_results_3d[:, 1],\n",
        "        z=tsne_results_3d[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color=features_df['bbox_name'].map(color_mapping), opacity=1.0)\n",
        "    )])\n",
        "    fig_3d.update_layout(\n",
        "        title=\"3D UMAP colored by bbox_name\",\n",
        "        scene=dict(xaxis_title=\"UMAP 1\", yaxis_title=\"UMAP 2\", zaxis_title=\"UMAP 3\")\n",
        "    )\n",
        "    fig_3d.show()\n",
        "\n",
        "    # Plot 3D UMAP colored by cluster\n",
        "    fig_3d_cluster = go.Figure(data=[go.Scatter3d(\n",
        "        x=tsne_results_3d[:, 0],\n",
        "        y=tsne_results_3d[:, 1],\n",
        "        z=tsne_results_3d[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color=kmeans.labels_, opacity=1.0)\n",
        "    )])\n",
        "    fig_3d_cluster.update_layout(\n",
        "        title=\"3D UMAP colored by cluster\",\n",
        "        scene=dict(xaxis_title=\"UMAP 1\", yaxis_title=\"UMAP 2\", zaxis_title=\"UMAP 3\")\n",
        "    )\n",
        "    fig_3d_cluster.show()\n",
        "\n",
        "# Example Usage\n",
        "args = parse_args()\n",
        "vol_data_dict, syn_df = load_volumes_and_synapse_data(args)\n",
        "\n",
        "# Initialize dataset\n",
        "dataset = SynapseDataset(vol_data_dict=vol_data_dict, synapse_df=syn_df, processor=Synapse3DProcessor(size=args.size),\n",
        "                         segmentation_type=args.segmentation_type, subvol_size=args.subvol_size, num_frames=args.num_frames, alpha=0.5)\n",
        "\n",
        "# Load and cluster features\n",
        "csv_filepath = '/content/drive/MyDrive/csv/features_seg5_alpha0_5.csv'\n",
        "features_df, kmeans, feature_cols = load_and_cluster_features(csv_filepath, n_clusters=20)\n",
        "\n",
        "# Apply t-SNE for dimensionality reduction\n",
        "tsne_results_2d = apply_tsne(features_df, feature_cols, n_components=2)\n",
        "tsne_results_3d = apply_tsne(features_df, feature_cols, n_components=3)\n",
        "\n",
        "# Find closest samples and create GIFs\n",
        "closest_samples = find_closest_samples_in_clusters(features_df, feature_cols, n_samples=4)\n",
        "save_gifs_dir = 'cgifs'\n",
        "create_gifs(dataset, closest_samples, save_gifs_dir, features_df)\n",
        "\n",
        "# Plot UMAP\n",
        "plot_umap(features_df, tsne_results_2d, tsne_results_3d, kmeans, color_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "e9ECE_LFe0S5",
        "outputId": "855d201f-15a2-4f4f-cf1c-d2a3ece3cf27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIF saved at cgifs/bbox4_cluster0_1.gif\n",
            "GIF saved at cgifs/bbox4_cluster0_2.gif\n",
            "GIF saved at cgifs/bbox4_cluster0_3.gif\n",
            "GIF saved at cgifs/bbox4_cluster0_12.gif\n",
            "GIF saved at cgifs/bbox4_cluster1_16.gif\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "single positional indexer is out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5fb727844b86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0mclosest_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_closest_samples_in_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0msave_gifs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cgifs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0mcreate_gifs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_gifs_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# Plot UMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5fb727844b86>\u001b[0m in \u001b[0;36mcreate_gifs\u001b[0;34m(dataset, samples, save_gifs_dir, features_df)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Access the sample data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mcluster_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-289592e08398>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0msyn_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynapse_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mbbox_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mraw_vol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_vol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_mask_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvol_data_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTeY2kcXfHRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "daa58lj6b7qc",
        "5Y--WYGnuD56",
        "lgZqP3RDTugT",
        "c-Bk2ZowxMzF",
        "Z3qge84l5x-f",
        "YefBuS0XLO7I",
        "irIiLedsf0dN"
      ],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}