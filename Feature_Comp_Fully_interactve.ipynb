{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alim98/MPI/blob/main/Feature_Comp_Fully_interactve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdxe3T8ql-of"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download"
      ],
      "metadata": {
        "id": "VLMtbhfvWAUU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7309ea5-26e6-4b8d-d1be-25e111092dce",
        "id": "kgz2qneNCAsD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-10 13:17:49--  https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.210.132, 2607:f8b0:400c:c0f::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.210.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1264688649 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘downloaded_file.zip’\n",
            "\n",
            "downloaded_file.zip 100%[===================>]   1.18G  57.6MB/s    in 18s     \n",
            "\n",
            "2025-01-10 13:18:07 (67.5 MB/s) - ‘downloaded_file.zip’ saved [1264688649/1264688649]\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h--2025-01-10 13:19:33--  https://drive.usercontent.google.com/download?id=1rOpINPMO5yqXycFFbJsqURRECwMiHUmP&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.210.132, 2607:f8b0:400c:c0f::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.210.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4443174 (4.2M) [application/octet-stream]\n",
            "Saving to: ‘ViT_all_features_merged.csv’\n",
            "\n",
            "ViT_all_features_me 100%[===================>]   4.24M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-01-10 13:19:36 (40.4 MB/s) - ‘ViT_all_features_merged.csv’ saved [4443174/4443174]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O downloaded_file.zip \"https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "!pip -q install umap-learn\n",
        "!unzip -q downloaded_file.zip\n",
        "!wget -O ViT_all_features_merged.csv \"https://drive.usercontent.google.com/download?id=1rOpINPMO5yqXycFFbJsqURRECwMiHUmP&export=download\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InterActive"
      ],
      "metadata": {
        "id": "RFklfBlXUbXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziI4pDx_Bpkj",
        "outputId": "1a168622-ffb3-4b8c-d588-38fe7edac2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (2.18.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.6)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.24.1)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install dash\n",
        "import dash"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tifffile as tiff\n",
        "import imageio.v2 as imageio  # Updated import to address DeprecationWarning\n",
        "from PIL import Image, ImageDraw, ImageFont  # For overlaying titles\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import tempfile\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html, Input, Output, State\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import umap\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Helper Function: Extract a Single Patch with Padding\n",
        "# -----------------------------------------------------------------------------------\n",
        "def extract_patch(slice_data, x_center, y_center, cube_size):\n",
        "    half_size = cube_size // 2\n",
        "\n",
        "    x_start = x_center - half_size\n",
        "    y_start = y_center - half_size\n",
        "    x_end = x_start + cube_size\n",
        "    y_end = y_start + cube_size\n",
        "\n",
        "    # Extract the patch; this might go out of bounds\n",
        "    patch = slice_data[y_start:y_end, x_start:x_end]\n",
        "\n",
        "    # Calculate padding if the patch goes out of image boundaries\n",
        "    pad_left = max(0, -x_start)\n",
        "    pad_top = max(0, -y_start)\n",
        "    pad_right = max(0, x_end - slice_data.shape[1])\n",
        "    pad_bottom = max(0, y_end - slice_data.shape[0])\n",
        "\n",
        "    if pad_left or pad_top or pad_right or pad_bottom:\n",
        "        patch = np.pad(\n",
        "            patch,\n",
        "            ((pad_top, pad_bottom), (pad_left, pad_right)),\n",
        "            mode='constant',\n",
        "            constant_values=0\n",
        "        )\n",
        "\n",
        "    # Ensure the patch is exactly (cube_size, cube_size)\n",
        "    patch = patch[:cube_size, :cube_size]\n",
        "\n",
        "    # In case the patch is still smaller due to extreme boundary conditions\n",
        "    if patch.shape[0] < cube_size or patch.shape[1] < cube_size:\n",
        "        patch = np.pad(\n",
        "            patch,\n",
        "            (\n",
        "                (0, cube_size - patch.shape[0]),\n",
        "                (0, cube_size - patch.shape[1])\n",
        "            ),\n",
        "            mode='constant',\n",
        "            constant_values=0\n",
        "        )\n",
        "        patch = patch[:cube_size, :cube_size]\n",
        "\n",
        "    # Final assertion to ensure patch size\n",
        "    assert patch.shape == (cube_size, cube_size), f\"Patch shape {patch.shape} is not ({cube_size}, {cube_size})\"\n",
        "\n",
        "    return patch\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Function: Extract Cube from Slices\n",
        "# -----------------------------------------------------------------------------------\n",
        "def extract_cube(folder_path, central_coords, cube_size=80):\n",
        "    x_center, y_center, z_center = central_coords\n",
        "    half_size = cube_size // 2\n",
        "    cube = []\n",
        "\n",
        "    # Load the central slice first to get image dimensions\n",
        "    central_slice_path = os.path.join(folder_path, f\"slice_{z_center}.tif\")\n",
        "    if not os.path.exists(central_slice_path):\n",
        "        raise FileNotFoundError(f\"Central slice {central_slice_path} does not exist.\")\n",
        "\n",
        "    central_slice = tiff.imread(central_slice_path)\n",
        "    img_height, img_width = central_slice.shape\n",
        "    print(f\"Central slice dimensions: {central_slice.shape}\")\n",
        "\n",
        "    for z in range(z_center - half_size, z_center + half_size):\n",
        "        slice_path = os.path.join(folder_path, f\"slice_{z}.tif\")\n",
        "        if os.path.exists(slice_path):\n",
        "            slice_data = tiff.imread(slice_path)\n",
        "            # Verify slice dimensions\n",
        "            if slice_data.shape != (img_height, img_width):\n",
        "                raise ValueError(f\"Slice {z} has inconsistent dimensions: {slice_data.shape}\")\n",
        "            # Extract the patch with proper padding\n",
        "            try:\n",
        "                patch = extract_patch(slice_data, x_center, y_center, cube_size)\n",
        "                cube.append(patch)\n",
        "                print(f\"Extracted patch from slice {z}\")\n",
        "            except AssertionError as ae:\n",
        "                print(f\"Assertion Error for slice {z}: {ae}\")\n",
        "                # Append a zero-filled patch to maintain consistency\n",
        "                cube.append(np.zeros((cube_size, cube_size)))\n",
        "        else:\n",
        "            # If the slice doesn't exist, append a zero-filled patch\n",
        "            print(f\"Slice {z} does not exist. Appending zero-filled patch.\")\n",
        "            cube.append(np.zeros((cube_size, cube_size)))\n",
        "\n",
        "    # Verify that all patches have the same shape\n",
        "    patch_shapes = [patch.shape for patch in cube]\n",
        "    if not all(shape == (cube_size, cube_size) for shape in patch_shapes):\n",
        "        raise ValueError(\"Not all patches have the shape (cube_size, cube_size).\")\n",
        "    else:\n",
        "        print(\"All patches have consistent shapes.\")\n",
        "\n",
        "    return np.stack(cube)\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Function: Create GIF with Titles Using Pillow for Consistent Frame Sizes\n",
        "# -----------------------------------------------------------------------------------\n",
        "def create_gif_with_titles(cube, output_path, var1, bbox_name, z_center):\n",
        "    frames = []\n",
        "    # Define fixed figure size and DPI\n",
        "    fig_size = (4, 4)  # inches\n",
        "    fig_dpi = 100       # dots per inch\n",
        "\n",
        "    # Define font for text overlay using Pillow\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 15)  # Adjust the font path and size as needed\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for i, slice_data in enumerate(cube):\n",
        "        fig, ax = plt.subplots(figsize=fig_size, dpi=fig_dpi)\n",
        "        ax.imshow(slice_data, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Save figure to a bytes buffer without title\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
        "        buf.seek(0)\n",
        "        frame = Image.open(buf).convert(\"RGBA\")\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Prepare the title\n",
        "        slice_number = z_center - (len(cube) // 2) + i\n",
        "        title = f\"Var1: {var1}, BBox: {bbox_name}, Slice: {slice_number}\"\n",
        "\n",
        "        # Overlay the title on the image using Pillow\n",
        "        draw = ImageDraw.Draw(frame)\n",
        "        text_position = (10, 10)  # Top-left corner; adjust as needed\n",
        "        draw.text(text_position, title, font=font, fill=(255, 255, 255, 255))  # White text\n",
        "\n",
        "        # Convert back to numpy array\n",
        "        frame_np = np.array(frame)\n",
        "        frames.append(frame_np)\n",
        "\n",
        "    # Verify all frames have the same shape\n",
        "    frame_shapes = [frame.shape for frame in frames]\n",
        "    first_shape = frame_shapes[0]\n",
        "    inconsistent = False\n",
        "    for idx, shape in enumerate(frame_shapes):\n",
        "        if shape != first_shape:\n",
        "            print(f\"Frame {idx} has shape {shape}, expected {first_shape}.\")\n",
        "            inconsistent = True\n",
        "    if inconsistent:\n",
        "        raise ValueError(\"Not all frames have the same shape.\")\n",
        "    else:\n",
        "        print(\"All frames have consistent shapes.\")\n",
        "\n",
        "    # Save the GIF using the updated imageio import\n",
        "    imageio.mimsave(output_path, frames, fps=5)\n",
        "    print(f\"GIF saved to {output_path}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Function: Process Features and Apply UMAP\n",
        "# -----------------------------------------------------------------------------------\n",
        "def process_features(df):\n",
        "    feature_cols = [c for c in df.columns if c.startswith('feat_')]\n",
        "    features = df[feature_cols].values\n",
        "    features_scaled = StandardScaler().fit_transform(features)\n",
        "    return features_scaled\n",
        "\n",
        "def reduce_to_umap(features_scaled):\n",
        "    umap_direct = umap.UMAP(n_components=2, random_state=42)\n",
        "    return umap_direct.fit_transform(features_scaled)\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Initialize Dash App\n",
        "# -----------------------------------------------------------------------------------\n",
        "app = Dash(__name__)\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Load Data\n",
        "# -----------------------------------------------------------------------------------\n",
        "file_path = 'ViT_all_features_merged.csv'  # Ensure this is the correct path\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"CSV file {file_path} does not exist.\")\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Add 'id' column for unique identification\n",
        "df.reset_index(inplace=True)\n",
        "df.rename(columns={'index': 'id'}, inplace=True)\n",
        "\n",
        "# Process Features and Apply UMAP\n",
        "features_scaled = process_features(df)\n",
        "umap_direct_result = reduce_to_umap(features_scaled)\n",
        "\n",
        "df['umap_1'] = umap_direct_result[:, 0]\n",
        "df['umap_2'] = umap_direct_result[:, 1]\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Dash Layout\n",
        "# -----------------------------------------------------------------------------------\n",
        "app.layout = html.Div([\n",
        "    dcc.Graph(\n",
        "        id='umap-plot',\n",
        "        figure=px.scatter(\n",
        "            df, x='umap_1', y='umap_2', color='bbox_name',\n",
        "            hover_data=['id', 'Var1', 'central_coord_1', 'central_coord_2', 'central_coord_3', 'bbox_name'],\n",
        "            title=\"ViT - Direct UMAP\"\n",
        "        )\n",
        "    ),\n",
        "    html.Button(\"Done\", id='done-button', n_clicks=0, style={'marginTop': 20}),\n",
        "    dcc.Download(id='download-gif'),\n",
        "    dcc.Download(id='download-log'),\n",
        "    html.Div(id='gif-output', style={'marginTop': 20}),\n",
        "    dcc.Store(id='log-store', data=[])  # Store to keep track of clicked data points\n",
        "])\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Callback to Generate GIF and Log Clicked Data\n",
        "# -----------------------------------------------------------------------------------\n",
        "@app.callback(\n",
        "    [\n",
        "        Output('gif-output', 'children'),\n",
        "        Output('download-gif', 'data'),\n",
        "        Output('log-store', 'data')\n",
        "    ],\n",
        "    [\n",
        "        Input('umap-plot', 'clickData')\n",
        "    ],\n",
        "    [\n",
        "        State('log-store', 'data')\n",
        "    ]\n",
        ")\n",
        "def generate_gif(click_data, existing_log):\n",
        "    if click_data:\n",
        "        try:\n",
        "            # Get clicked sample details\n",
        "            point = click_data['points'][0]\n",
        "            customdata = point['customdata']\n",
        "            id_ = customdata[0]\n",
        "            var1 = customdata[1]\n",
        "            central_x = int(customdata[2])\n",
        "            central_y = int(customdata[3])\n",
        "            central_z = int(customdata[4])\n",
        "            bbox_name = customdata[5]\n",
        "\n",
        "            central_coords = (central_x, central_y, central_z)\n",
        "\n",
        "            # Define folder path\n",
        "            folder_path = os.path.join('raw', bbox_name)  # Adjust this path if necessary\n",
        "            if not os.path.exists(folder_path):\n",
        "                return f\"Folder {folder_path} does not exist.\", None, existing_log\n",
        "\n",
        "            # Extract cube and generate GIF\n",
        "            cube = extract_cube(folder_path, central_coords)\n",
        "            gif_filename = f\"{var1}.gif\"\n",
        "            create_gif_with_titles(cube, gif_filename, var1, bbox_name, central_z)\n",
        "\n",
        "            # Update the log\n",
        "            log_entry = {\n",
        "                'id': id_,\n",
        "                'synapse_name': var1,\n",
        "                'central_coord_1': central_x,\n",
        "                'central_coord_2': central_y,\n",
        "                'central_coord_3': central_z,\n",
        "                'bbox_name': bbox_name,\n",
        "                'center_slice': central_z\n",
        "            }\n",
        "            updated_log = existing_log.copy()\n",
        "            updated_log.append(log_entry)\n",
        "\n",
        "            # Provide GIF for download\n",
        "            return f\"GIF generated: {gif_filename}\", dcc.send_file(gif_filename), updated_log\n",
        "        except Exception as e:\n",
        "            return f\"Error generating GIF: {str(e)}\", None, existing_log\n",
        "\n",
        "    return \"Click on a point to generate a GIF.\", None, existing_log\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Callback to Export Log as CSV\n",
        "# -----------------------------------------------------------------------------------\n",
        "@app.callback(\n",
        "    Output('download-log', 'data'),\n",
        "    [\n",
        "        Input('done-button', 'n_clicks')\n",
        "    ],\n",
        "    [\n",
        "        State('log-store', 'data')\n",
        "    ],\n",
        "    prevent_initial_call=True\n",
        ")\n",
        "def export_log(n_clicks, log_data):\n",
        "    if n_clicks > 0 and log_data:\n",
        "        # Convert log data to DataFrame\n",
        "        log_df = pd.DataFrame(log_data)\n",
        "\n",
        "        # Define the CSV file name\n",
        "        csv_filename = \"clicked_data_log.csv\"\n",
        "\n",
        "        # Return the CSV file for download\n",
        "        return dcc.send_data_frame(log_df.to_csv, csv_filename, index=False)\n",
        "\n",
        "    return None\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Run the Dash App\n",
        "# -----------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "aHOIHEt7UMsm",
        "outputId": "8c05a170-99fe-4fda-806c-d8c7452ad2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOus7yiGck-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Bp-X5vz9IpKeOPJmE7YjP97rB5kaFZ55",
      "authorship_tag": "ABX9TyPwUR18BkJstw9STIteezoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}