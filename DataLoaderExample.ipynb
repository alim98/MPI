{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM68aw++RbTB7b28S8yO/LM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alim98/MPI/blob/main/DataLoaderExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget -O downloaded_file.zip \"https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "\n",
        "# !pip -q install transformers scikit-learn matplotlib seaborn torch torchvision umap-learn openpyxl imageio\n",
        "\n",
        "\n",
        "!wget -O vesicle_cloud__syn_interface__mitochondria_annotation.zip \"https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
        "\n",
        "!unzip -q downloaded_file.zip\n",
        "!unzip -q vesicle_cloud__syn_interface__mitochondria_annotation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTfdGXpI_lbv",
        "outputId": "536b652d-8a5d-4c96-c403-8e51d5f73a0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 07:51:18--  https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.62.132, 2607:f8b0:4004:c07::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.62.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1264688649 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘downloaded_file.zip’\n",
            "\n",
            "downloaded_file.zip 100%[===================>]   1.18G  81.8MB/s    in 22s     \n",
            "\n",
            "2025-01-22 07:51:42 (55.0 MB/s) - ‘downloaded_file.zip’ saved [1264688649/1264688649]\n",
            "\n",
            "--2025-01-22 07:51:42--  https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.62.132, 2607:f8b0:4004:c07::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.62.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14246564 (14M) [application/octet-stream]\n",
            "Saving to: ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’\n",
            "\n",
            "vesicle_cloud__syn_ 100%[===================>]  13.59M  37.0MB/s    in 0.4s    \n",
            "\n",
            "2025-01-22 07:52:13 (37.0 MB/s) - ‘vesicle_cloud__syn_interface__mitochondria_annotation.zip’ saved [14246564/14246564]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import io\n",
        "import argparse\n",
        "import multiprocessing\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio.v3 as iio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "\n",
        "class SimpleVideoProcessor:\n",
        "    def __init__(self, size=(80, 80), mean=(0.485, 0.456, 0.406),\n",
        "                 std=(0.229, 0.224, 0.225)):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, frames, return_tensors=None):\n",
        "        processed_frames = [self.transform(frame) for frame in frames]\n",
        "        pixel_values = torch.stack(processed_frames)\n",
        "        if return_tensors == \"pt\":\n",
        "            return {\"pixel_values\": pixel_values}\n",
        "        else:\n",
        "            return pixel_values\n",
        "\n",
        "def load_volumes(bbox_name: str, raw_base_dir: str, seg_base_dir: str, add_mask_base_dir: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    raw_dir = os.path.join(raw_base_dir, bbox_name)\n",
        "    seg_dir = os.path.join(seg_base_dir, bbox_name)\n",
        "\n",
        "    if bbox_name.startswith(\"bbox\"):\n",
        "        bbox_num = bbox_name.replace(\"bbox\", \"\")\n",
        "        add_mask_dir = os.path.join(add_mask_base_dir, f\"bbox_{bbox_num}\")\n",
        "    else:\n",
        "        add_mask_dir = os.path.join(add_mask_base_dir, bbox_name)\n",
        "\n",
        "    raw_tif_files = sorted(glob.glob(os.path.join(raw_dir, 'slice_*.tif')))\n",
        "    seg_tif_files = sorted(glob.glob(os.path.join(seg_dir, 'slice_*.tif')))\n",
        "    add_mask_tif_files = sorted(glob.glob(os.path.join(add_mask_dir, 'slice_*.tif')))\n",
        "\n",
        "    if not (len(raw_tif_files) == len(seg_tif_files) == len(add_mask_tif_files)):\n",
        "        return None, None, None\n",
        "\n",
        "    try:\n",
        "        raw_vol = np.stack([iio.imread(f) for f in raw_tif_files], axis=0)\n",
        "        seg_vol = np.stack([iio.imread(f).astype(np.uint32) for f in seg_tif_files], axis=0)\n",
        "        add_mask_vol = np.stack([iio.imread(f).astype(np.uint32) for f in add_mask_tif_files], axis=0)\n",
        "        return raw_vol, seg_vol, add_mask_vol\n",
        "    except Exception as e:\n",
        "        return None, None, None\n",
        "\n",
        "def create_segmented_cube(\n",
        "    raw_vol: np.ndarray,\n",
        "    seg_vol: np.ndarray,\n",
        "    add_mask_vol: np.ndarray,\n",
        "    central_coord: Tuple[int, int, int],\n",
        "    side1_coord: Tuple[int, int, int],\n",
        "    side2_coord: Tuple[int, int, int],\n",
        "    segmentation_type: int,\n",
        "    subvolume_size: int = 80,\n",
        "    alpha: float = 0.3,\n",
        "    input_mask: bool = False  # New parameter\n",
        ") -> np.ndarray:\n",
        "    def create_segment_masks(segmentation_volume, s1_coord, s2_coord):\n",
        "        x1, y1, z1 = s1_coord\n",
        "        x2, y2, z2 = s2_coord\n",
        "        seg_id_1 = segmentation_volume[z1, y1, x1]\n",
        "        seg_id_2 = segmentation_volume[z2, y2, x2]\n",
        "\n",
        "        mask_1 = (segmentation_volume == seg_id_1) if seg_id_1 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
        "        mask_2 = (segmentation_volume == seg_id_2) if seg_id_2 != 0 else np.zeros_like(segmentation_volume, dtype=bool)\n",
        "        return mask_1, mask_2\n",
        "\n",
        "    mask_1_full, mask_2_full = create_segment_masks(seg_vol, side1_coord, side2_coord)\n",
        "    mask_3_full = (add_mask_vol > 0)\n",
        "\n",
        "    half_size = subvolume_size // 2\n",
        "    cx, cy, cz = central_coord\n",
        "    x_start, x_end = max(cx - half_size, 0), min(cx + half_size, raw_vol.shape[2])\n",
        "    y_start, y_end = max(cy - half_size, 0), min(cy + half_size, raw_vol.shape[1])\n",
        "    z_start, z_end = max(cz - half_size, 0), min(cz + half_size, raw_vol.shape[0])\n",
        "\n",
        "    sub_raw = raw_vol[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_mask_1 = mask_1_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_mask_2 = mask_2_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "    sub_mask_3 = mask_3_full[z_start:z_end, y_start:y_end, x_start:x_end]\n",
        "\n",
        "    pad_z = subvolume_size - sub_raw.shape[0]\n",
        "    pad_y = subvolume_size - sub_raw.shape[1]\n",
        "    pad_x = subvolume_size - sub_raw.shape[2]\n",
        "\n",
        "    if pad_z > 0 or pad_y > 0 or pad_x > 0:\n",
        "        sub_raw = np.pad(sub_raw, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=0)\n",
        "        sub_mask_1 = np.pad(sub_mask_1, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=False)\n",
        "        sub_mask_2 = np.pad(sub_mask_2, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=False)\n",
        "        sub_mask_3 = np.pad(sub_mask_3, ((0, pad_z), (0, pad_y), (0, pad_x)), mode='constant', constant_values=False)\n",
        "\n",
        "    sub_raw = sub_raw[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_mask_1 = sub_mask_1[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_mask_2 = sub_mask_2[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "    sub_mask_3 = sub_mask_3[:subvolume_size, :subvolume_size, :subvolume_size]\n",
        "\n",
        "    overlaid_cube = np.zeros((subvolume_size, subvolume_size, 3, subvolume_size), dtype=np.uint8)\n",
        "\n",
        "    for z in range(subvolume_size):\n",
        "        raw_slice = sub_raw[z].astype(np.float32)\n",
        "        mn, mx = raw_slice.min(), raw_slice.max()\n",
        "        if mx > mn:\n",
        "            raw_slice = (raw_slice - mn) / (mx - mn)\n",
        "        else:\n",
        "            raw_slice = raw_slice - mn\n",
        "\n",
        "        if input_mask:  # New masking logic\n",
        "            combined_mask = np.zeros_like(raw_slice, dtype=np.float32)\n",
        "            if segmentation_type in [1, 3, 5]:\n",
        "                combined_mask = np.logical_or(combined_mask, sub_mask_1[z])\n",
        "            if segmentation_type in [2, 3, 5]:\n",
        "                combined_mask = np.logical_or(combined_mask, sub_mask_2[z])\n",
        "            if segmentation_type in [4, 5]:\n",
        "                combined_mask = np.logical_or(combined_mask, sub_mask_3[z])\n",
        "\n",
        "            masked_raw = raw_slice * combined_mask\n",
        "            masked_rgb = np.stack([masked_raw]*3, axis=-1)\n",
        "            overlaid_image = (masked_rgb * 255).astype(np.uint8)\n",
        "        else:  # Original overlay logic\n",
        "            raw_rgb = np.stack([raw_slice]*3, axis=-1)\n",
        "            mask1_rgb = np.zeros_like(raw_rgb)\n",
        "            mask2_rgb = np.zeros_like(raw_rgb)\n",
        "            mask3_rgb = np.zeros_like(raw_rgb)\n",
        "\n",
        "            if segmentation_type in [1, 3, 5]:\n",
        "                mask1_rgb[sub_mask_1[z]] = [1, 0, 0]\n",
        "            if segmentation_type in [2, 3, 5]:\n",
        "                mask2_rgb[sub_mask_2[z]] = [0, 0, 1]\n",
        "            if segmentation_type in [4, 5]:\n",
        "                mask3_rgb[sub_mask_3[z]] = [0, 1, 0]\n",
        "\n",
        "            combined_masks = mask1_rgb + mask2_rgb + mask3_rgb\n",
        "            combined_masks = np.clip(combined_masks, 0, 1)\n",
        "            overlaid_image = (1 - alpha) * raw_rgb + alpha * combined_masks\n",
        "            overlaid_image = (np.clip(overlaid_image, 0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "        overlaid_cube[:, :, :, z] = overlaid_image\n",
        "\n",
        "    return overlaid_cube\n",
        "\n",
        "class VideoMAEDataset(Dataset):\n",
        "    def __init__(self, vol_data_dict: dict, synapse_df: pd.DataFrame, processor,\n",
        "                 segmentation_type: int, subvol_size: int = 80, num_frames: int = 16,\n",
        "                 alpha: float = 0.3, input_mask: bool = False):  # Added input_mask\n",
        "        self.vol_data_dict = vol_data_dict\n",
        "        self.synapse_df = synapse_df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.segmentation_type = segmentation_type\n",
        "        self.subvol_size = subvol_size\n",
        "        self.num_frames = num_frames\n",
        "        self.alpha = alpha\n",
        "        self.input_mask = input_mask  # Store input_mask flag\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.synapse_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        syn_info = self.synapse_df.iloc[idx]\n",
        "        bbox_name = syn_info['bbox_name']\n",
        "        raw_vol, seg_vol, add_mask_vol = self.vol_data_dict.get(bbox_name, (None, None, None))\n",
        "\n",
        "        if raw_vol is None:\n",
        "            return torch.zeros((self.num_frames, 3, self.subvol_size, self.subvol_size), dtype=torch.float32), syn_info, bbox_name\n",
        "\n",
        "        central_coord = (int(syn_info['central_coord_1']), int(syn_info['central_coord_2']), int(syn_info['central_coord_3']))\n",
        "        side1_coord = (int(syn_info['side_1_coord_1']), int(syn_info['side_1_coord_2']), int(syn_info['side_1_coord_3']))\n",
        "        side2_coord = (int(syn_info['side_2_coord_1']), int(syn_info['side_2_coord_2']), int(syn_info['side_2_coord_3']))\n",
        "\n",
        "        overlaid_cube = create_segmented_cube(\n",
        "            raw_vol=raw_vol,\n",
        "            seg_vol=seg_vol,\n",
        "            add_mask_vol=add_mask_vol,\n",
        "            central_coord=central_coord,\n",
        "            side1_coord=side1_coord,\n",
        "            side2_coord=side2_coord,\n",
        "            segmentation_type=self.segmentation_type,\n",
        "            subvolume_size=self.subvol_size,\n",
        "            alpha=self.alpha,\n",
        "            input_mask=self.input_mask  # Pass the flag\n",
        "        )\n",
        "\n",
        "        frames = [overlaid_cube[..., z] for z in range(overlaid_cube.shape[3])]\n",
        "        if len(frames) < self.num_frames:\n",
        "            frames += [frames[-1]] * (self.num_frames - len(frames))\n",
        "        elif len(frames) > self.num_frames:\n",
        "            indices = np.linspace(0, len(frames)-1, self.num_frames, dtype=int)\n",
        "            frames = [frames[i] for i in indices]\n",
        "\n",
        "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
        "        return inputs[\"pixel_values\"].squeeze(0).float(), syn_info, bbox_name\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"VideoMAE Pre-training Script with Segmented Videos and Additional Masks\")\n",
        "    parser.add_argument('--raw_base_dir', type=str, default='raw')\n",
        "    parser.add_argument('--seg_base_dir', type=str, default='seg')\n",
        "    parser.add_argument('--add_mask_base_dir', type=str, default='')\n",
        "    parser.add_argument('--bbox_name', type=str, default=['bbox1'], nargs='+')\n",
        "    parser.add_argument('--excel_file', type=str, default='')\n",
        "    parser.add_argument('--csv_output_dir', type=str, default='csv_outputs')\n",
        "    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints')\n",
        "    parser.add_argument('--log_dir', type=str, default='logs')\n",
        "    parser.add_argument('--size', type=tuple, default=(80,80))\n",
        "    parser.add_argument('--batch_size', type=int, default=2)\n",
        "    parser.add_argument('--num_epochs', type=int, default=5)\n",
        "    parser.add_argument('--learning_rate', type=float, default=1e-4)\n",
        "    parser.add_argument('--weight_decay', type=float, default=1e-2)\n",
        "    parser.add_argument('--subvol_size', type=int, default=80)\n",
        "    parser.add_argument('--num_frames', type=int, default=80)\n",
        "    parser.add_argument('--mask_ratio', type=float, default=0.75)\n",
        "    parser.add_argument('--patience', type=int, default=3)\n",
        "    parser.add_argument('--resume_checkpoint', type=str, default=None)\n",
        "    parser.add_argument('--save_gifs_dir', type=str, default='gifs')\n",
        "    parser.add_argument('--num_gifs', type=int, default=10)\n",
        "    parser.add_argument('--alpha', type=float, default=0.3)\n",
        "    parser.add_argument('--segmentation_type', type=int, default=5, choices=range(0, 6))\n",
        "    parser.add_argument('--input_mask', action='store_true', # Added argument\n",
        "                       help='Mask input image using segmentation_type regions')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "def main(args):\n",
        "    processor = SimpleVideoProcessor(size=(80, 80))\n",
        "    vol_data_dict = {}\n",
        "\n",
        "    for bbox_name in args.bbox_name:\n",
        "        raw_vol, seg_vol, add_mask_vol = load_volumes(\n",
        "            bbox_name=bbox_name,\n",
        "            raw_base_dir=args.raw_base_dir,\n",
        "            seg_base_dir=args.seg_base_dir,\n",
        "            add_mask_base_dir=args.add_mask_base_dir\n",
        "        )\n",
        "        if raw_vol is not None:\n",
        "            vol_data_dict[bbox_name] = (raw_vol, seg_vol, add_mask_vol)\n",
        "\n",
        "    synapse_dfs = []\n",
        "    for bbox_name in args.bbox_name:\n",
        "        excel_path = os.path.join(args.excel_file, f\"{bbox_name}.xlsx\")\n",
        "        if os.path.exists(excel_path):\n",
        "            df = pd.read_excel(excel_path)\n",
        "            df['bbox_name'] = bbox_name\n",
        "            synapse_dfs.append(df)\n",
        "\n",
        "    syn_df = pd.concat(synapse_dfs, ignore_index=True)\n",
        "    dataset = VideoMAEDataset(\n",
        "        vol_data_dict=vol_data_dict,\n",
        "        synapse_df=syn_df,\n",
        "        processor=processor,\n",
        "        segmentation_type=args.segmentation_type,\n",
        "        subvol_size=args.subvol_size,\n",
        "        num_frames=args.num_frames,\n",
        "        alpha=args.alpha,\n",
        "        input_mask=args.input_mask  # Pass the flag\n",
        "    )\n",
        "\n",
        "    cubes = []\n",
        "    syn_info_list = []\n",
        "    for idx in range(len(dataset)):\n",
        "        pixel_values, syn_info, _ = dataset[idx]\n",
        "        cubes.append(pixel_values)\n",
        "        syn_info_list.append(syn_info)\n",
        "\n",
        "    print(f\"Processed {len(cubes)} cubes successfully.\")\n",
        "    return cubes, pd.DataFrame(syn_info_list)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    cubes, sys_inf = main(args)\n",
        "    print(f\"Final output: {len(cubes)} cubes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGMArgULFxMs",
        "outputId": "25794091-2628-44bf-8def-4c28f0d87856"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 58 cubes successfully.\n",
            "Final output: 58 cubes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        # Data directories\n",
        "        self.raw_base_dir = 'raw'\n",
        "        self.seg_base_dir = 'seg'\n",
        "        self.add_mask_base_dir = ''\n",
        "        self.bbox_name = ['bbox1']\n",
        "        self.excel_file = ''\n",
        "\n",
        "        # Output directories\n",
        "        self.csv_output_dir = 'csv_outputs'\n",
        "        self.checkpoint_dir = 'checkpoints'\n",
        "        self.log_dir = 'logs'\n",
        "\n",
        "        # Training parameters\n",
        "        self.size = (80, 80)\n",
        "        self.batch_size = 2\n",
        "        self.num_epochs = 5\n",
        "        self.learning_rate = 1e-4\n",
        "        self.weight_decay = 1e-2\n",
        "        self.subvol_size = 80\n",
        "        self.num_frames = 80\n",
        "        self.mask_ratio = 0.75\n",
        "        self.patience = 3\n",
        "        self.resume_checkpoint = None\n",
        "\n",
        "        # GIF parameters\n",
        "        self.save_gifs_dir = 'gifs'\n",
        "        self.num_gifs = 10\n",
        "        self.alpha = 0.3\n",
        "        self.segmentation_type = 5\n",
        "        self.input_mask = True  # Set to True if you want masking\n",
        "\n",
        "# In your notebook cell:\n",
        "args = Args()  # Create config object\n",
        "args.input_mask = True  # Optionally override parameters\n",
        "args.bbox_name = ['bbox1']  # Example override\n",
        "\n",
        "# Run main program\n",
        "cubes, sys_inf = main(args)\n",
        "print(f\"Processed {len(cubes)} cubes successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKQBwk0BILVk",
        "outputId": "84f0c6c5-a068-4dfe-ff1d-8d70f164c5a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 58 cubes successfully.\n",
            "Processed 58 cubes successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "# After running main() and getting the cubes list\n",
        "cube = cubes[0]  # Select the first cube (adjust index as needed)\n",
        "\n",
        "# Define normalization parameters (must match what's used in SimpleVideoProcessor)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "\n",
        "# Denormalize the tensor\n",
        "denormalized_cube = cube * std + mean\n",
        "\n",
        "# Clamp values to valid [0,1] range and convert to numpy\n",
        "denormalized_cube = torch.clamp(denormalized_cube, 0, 1)\n",
        "frames = denormalized_cube.permute(0, 2, 3, 1).numpy()  # Change to (T, H, W, C)\n",
        "frames = (frames * 255).astype(np.uint8)  # Convert to 0-255\n",
        "\n",
        "imageio.mimsave('synapse_cube2.gif', frames, fps=10)\n",
        "\n",
        "print(\"GIF saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnTZGGVkG-N_",
        "outputId": "fd344190-24b9-4667-8db1-ee99e58a8c4f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIF saved successfully!\n"
          ]
        }
      ]
    }
  ]
}